{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    loss = 1 / (2 * N) * np.sum((y - tx.dot(w)) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(grid_w0.shape[0]):\n",
    "        for j in range(grid_w1.shape[0]):\n",
    "            losses[i, j] = compute_loss(y, tx, [grid_w0[i], grid_w1[j]])\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.428548387428222, w0*=73.57859531772576, w1*=13.545150501672254, execution time=3.589 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA14AAAITCAYAAAAXac30AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA0WtJREFUeJzs3XtcVHX+x/HXAAMKInlZRRKrvfzaDC3WWm+w0qaUpa5rZWVZtuXWeilRK02pKTC1Umx17WJtNytrU9uurpe8kZfKcMu2666bmpJtEQgoDHB+f3z9zpwzDDDAwFz4PB8PHgMzZ85852g2bz7f7+drMwzDQAghhBBCCCFEi4kI9ACEEEIIIYQQItxJ8BJCCCGEEEKIFibBSwghhBBCCCFamAQvIYQQQgghhGhhEryEEEIIIYQQooVJ8BJCCCGEEEKIFibBSwghhBBCCCFamAQvIYQQQgghhGhhEryEEEIIIYQQooVJ8BJCCCGEEEKIFhZSwWvbtm2MHDmSpKQkbDYbr776quXxCRMmYLPZLF8DBgywHFNRUcHUqVPp2rUrcXFxjBo1ikOHDrXiuxBCiLbnkUceoW/fvnTs2JGOHTsycOBA3n77bQCcTid33nknffr0IS4ujqSkJK677joOHz5sOYcv/34XFRUxfvx4EhISSEhIYPz48fz444+WYw4cOMDIkSOJi4uja9eu3HrrrVRWVrbo+xdCCCFCKniVlZVxzjnnsGzZsjqPufjiizly5Ijr66233rI8Pm3aNNauXcuqVavIz8+ntLSUESNGUF1d3dLDF0KINqtnz54sWLCADz74gA8++IDf/va3/O53v+OTTz6hvLycDz/8kOzsbD788EPWrFnDF198wahRoyzn8OXf73HjxrF3717WrVvHunXr2Lt3L+PHj3c9Xl1dzaWXXkpZWRn5+fmsWrWK1atXM2PGjFa7FkIIIdomm2EYRqAH0RQ2m421a9cyevRo130TJkzgxx9/rFUJ04qLi/nJT37Cc889x5VXXgnA4cOHSU5O5q233uKiiy5qhZELIYQA6Ny5Mw8++CA33nhjrcfef/99fv3rX/P111/Tq1cvn/79/vTTT+nduze7du2if//+AOzatYuBAwfy2WefceaZZ/L2228zYsQIDh48SFJSEgCrVq1iwoQJHD16lI4dO7beBRBCCNGmRAV6AP62ZcsWunXrximnnMKQIUOYN28e3bp1A2DPnj04nU4yMzNdxyclJZGSksKOHTvqDF4VFRVUVFS4fq6pqeGHH36gS5cu2Gy2ln1DQog2yTAMjh07RlJSEhERTZ+ccOLEiRabRmcYRq1/A2NiYoiJian3edXV1fztb3+jrKyMgQMHej2muLgYm83GKaecAvj27/fOnTtJSEhwhS6AAQMGkJCQwI4dOzjzzDPZuXMnKSkprtAFcNFFF1FRUcGePXu44IILGnsZgkZNTQ2HDx8mPj5e/t8khBCtyNf/Z4dV8Bo+fDhXXHEFp512Gvv37yc7O5vf/va37Nmzh5iYGAoLC4mOjqZTp06W53Xv3p3CwsI6zzt//nzuvffelh6+EELUcvDgQXr27Nmk5544cYKe7dvzvZ/HpHXo0IHS0lLLfffccw8Oh8Pr8R9//DEDBw7kxIkTdOjQgbVr19K7d+9ax504cYJZs2Yxbtw4VwXKl3+/CwsLXb9oM+vWrZvlmO7du1se79SpE9HR0fX+fyAU6AqgEEKIwGjo/9lhFbz09BOAlJQUzjvvPE477TTefPNNxowZU+fzvP3W1mz27NlMnz7d9XNxcTG9evXi4O+g4+3+GXtd3urz25Z9AQ9PckOrvl5jbXx3VMMHiTZv6ODXAj2EOt3IUz4dV15SxY3J24iPj2/ya1VWVvI9sAaIa/JZvCsDxpSWcvDgQcv0vPqqXWeeeSZ79+7lxx9/ZPXq1Vx//fVs3brVEr6cTidXXXUVNTU1LF++vMFxeP777e3f8qYcE4r03xXPPxNfOZ1O1q9fT2ZmJna73d/DaxPkGjafXMPmk2vYfI29hiUlJSQnJzf4/+ywCl6eevTowWmnncaXX34JQGJiIpWVlRQVFVl+a3r06FEGDRpU53nqmjrT8Xbo2MH/49ZeOyeT2JY7fS2PcjPB/J/n29vG+P/TowhLG/dey/DfrAn0MLx6lsncwmM+H++PMBBHy/2no7sU+iI6Opqf//znAJx33nm8//77PPzwwzz2mLoeTqeTsWPHsn//ft555x3LeX359zsxMZFvv/221ut+9913ripXYmIiu3fvtjxeVFSE0+msVQkLNfrvSmP+TMycTiexsbF07NhRPqw1kVzD5pNr2HxyDZuvqdewof9nh1RXw8b6/vvvOXjwID169ACgX79+2O12NmzY4DrmyJEj7Nu3r97gFQivnZPZ8EFtyNvb6q5YCuFNMP+deZSbAz2EoGAYhmv9rA5dX375JRs3bqRLly6WY33593vgwIEUFxfz3nvvuY7ZvXs3xcXFlmP27dvHkSNHXMesX7+emJgY+vXr12LvVQghhAipildpaSlfffWV6+f9+/ezd+9eOnfuTOfOnXE4HFx22WX06NGD//73v9x111107dqV3//+9wAkJCRw4403MmPGDLp06ULnzp2ZOXMmffr0YejQoYF6W0EhWD8IBvOHZxH83t42JmgrX23NXXfdxfDhw0lOTubYsWOsWrWKLVu2sG7dOqqqqrj88sv58MMPeeONN6iurnatt+rcuTPR0dE+/ft91llncfHFFzNx4kRXFe2Pf/wjI0aM4MwzzwQgMzOT3r17M378eB588EF++OEHZs6cycSJE6WjoRBCiBYVUsHrgw8+sHSc0uuurr/+eh555BE+/vhjnn32WX788Ud69OjBBRdcwEsvvWSZb5mXl0dUVBRjx47l+PHjXHjhhTz99NNERka2+vupS2tXuyR0iXAWrOHrUW5u1JTDUPftt98yfvx4jhw5QkJCAn379mXdunUMGzaM//73v7z2mlqXd+6551qet3nzZjIyMgDf/v1+/vnnufXWW13dD0eNGmXZ+zEyMpI333yTSZMmMXjwYNq3b8+4ceN46KGHWvYCCCGEaPNCKnhlZGRQ37Zj//jHPxo8R7t27Vi6dClLly7159CEn0noEv4k4SvwnnzyyTofO/300+v9t13z5d/vzp07s3LlynrP06tXL954440GX08IIYTwp7Be4xWKpNoloUu0DPl7JYQQQohAkuDVhknoEm1NMP79Csb/DoUQQgjhfxK8gkhb72QYjB+KRfgJxr9nEr6EEEKI8CfBq40Ktg96wfhhWIQv+fsmhBBCiNYmwStItGa1K9hClxCBEGzhS/67FEIIIcKbBC8RcMH2AVi0HcH2d0/ClxBCCBG+JHgFgbZc7Qq2D76i7ZG/g0IIIYRoDRK8RMDIB14RLILp72Kw/XJECCGEEP4hwSvA2mq1K5g+6AoRbILpv1UhhBBC+EdUoAcgWkcwfZCT0OUHDh/vEz57e9sYhv9mTaCHIYQQQogwJcErgNrivl0SunzgaOHnNfX8bUAwha8nuQF4J9DDEEIIIYSfSPBqA4Kl2iWhywtHkLymt/vaqGAKX0IIIYQIHxK8AqS1ql3BErrESY5AD6AOjjq+b6MkfAkhhBDC36S5hmgVbbra5TB9hQIHoTXeFtKm/84KIYQQYSg7Gzp0ULeBIMErANpatatNfoB1EB7hxUF4vI8mapN/d4UQQogwlZcHZWXqNhBkqqFoUW3ug6sj0ANoQY46vhdCCCGECAFZWSp0TZ8emNeX4NXK2lK1q82ELkegBxAADo/bMCbrvYQQQojwkJOjvgJFphoK0VQO2kTwqJeDNnEN2swvEYQQQgjRYiR4tSKpdoUJB20ibDSKg7C/JmH9d1oIIYQQLU6mGgq/C9sPqI5ADyAEODxuhRBCCCEEIBWvVtNWql0SugQQthWwsP37LZpl27ZtjBw5kqSkJGw2G6+++qrrMafTyZ133kmfPn2Ii4sjKSmJ6667jsOHD1vOUVFRwdSpU+natStxcXGMGjWKQ4cOtfI7EUII0ZIkeIWRQIeusOQgLANEq3EEegD+J+FLeCorK+Occ85h2bJltR4rLy/nww8/JDs7mw8//JA1a9bwxRdfMGrUKMtx06ZNY+3ataxatYr8/HxKS0sZMWIE1dXVrfU2hBCi7SouBsNo8ZeRqYatoLWqXYEWVh9IHYEeQBhxeNyGAel0KMyGDx/O8OHDvT6WkJDAhg0bLPctXbqUX//61xw4cIBevXpRXFzMk08+yXPPPcfQoUMBWLlyJcnJyWzcuJGLLrqoxd+DEEK0WcePQ0YGnH02PPYYxMW12EtJ8AoTga52SegSDXJ43ArRRhUXF2Oz2TjllFMA2LNnD06nk8xM9y/pkpKSSElJYceOHXUGr4qKCioqKlw/l5SUAGp6o9PpbPS49HOa8lyhyDVsPrmGzSfXsBEMg8hbbiFi716Mb76h6uhR6Nmz0dfQ1+MkeIlmC5vQ5Qj0ANoIB2FxraXqJZrixIkTzJo1i3HjxtGxY0cACgsLiY6OplOnTpZju3fvTmFhYZ3nmj9/Pvfee2+t+9evX09sbGyTx+hZoRONJ9ew+eQaNp9cw4ad9o9/cO6zz2JERLBj6lT+99FH8NFHrsd9vYbl5eU+HSfBq4W1xjTDQFe7woIj0ANoYxwetyFKwpdoDKfTyVVXXUVNTQ3Lly9v8HjDMLDZbHU+Pnv2bKZPn+76uaSkhOTkZDIzM12hrrHj27BhA8OGDcNutzf6+UKuoT/INWw+uYa+sX3wAZFPPglATU4Ov779dtdjjb2GesZBQyR4iWYJi2qXI9ADaMMcyPUXbYLT6WTs2LHs37+fd955xxKMEhMTqayspKioyFL1Onr0KIMGDarznDExMcTExNS63263N+vDVnOfL+Qa+oNcw+aTa1iP//0PrrwSKith9GgiZ88m0ssvuny9hr5eZ+lq2ILCvdoV8qHLgXzoDwaOQA+geUL+vwPR4nTo+vLLL9m4cSNdunSxPN6vXz/sdrtlSsuRI0fYt29fvcFLCCFEE1RXw7hxcPAg/OIX8PTTUM/sAn+SipdomxyBHoCwcHjchhiZcti2lZaW8tVXX7l+3r9/P3v37qVz584kJSVx+eWX8+GHH/LGG29QXV3tWrfVuXNnoqOjSUhI4MYbb2TGjBl06dKFzp07M3PmTPr06ePqciiEEMJP7r4bNmyA2FhYswYSElrtpSV4tRCpdgUxR6AHIOrkQP58RMj54IMPuOCCC1w/63VX119/PQ6Hg9deew2Ac8891/K8zZs3k5GRAUBeXh5RUVGMHTuW48ePc+GFF/L0008TGRnZKu9BCCHahNdeg/vvV9+vWAEpKa368hK8RKOFbOhyBHoAwicOQvLPSqpebVdGRgZGPRtv1veY1q5dO5YuXcrSpUv9OTQhhBDaV1/Bddep76dOVdMNW5ms8QpR0smwkRyBHoBoFEegB9A0IftLCSGEECKclZfDZZdBcTEMGgQPPRSQYUjwagGtMc0wUELyg6Uj0AMQTeII9ACEEEIIEfIMA265Re3P1a0bvPwyREcHZCgSvEKQVLsawRHoAYhmcQR6AI0Xkr+cEEIIIcLVo4/Cc89BZCS89BKcemrAhiLBy8+k2hVEHIEegPALByH3Zxly/60IIYQQ4WjXLrjtNvX9ggVwsqFRoEjwCjGBqnaF3AdJR6AHIPzOEegBCCGEECJkfPcdXHEFOJ1qfdeMGYEekQQvEYYcgR6AaDGOQA/AdyH3ywohhBAiXFRXw9VXw6FDcOaZ8NRTrbZJcn0kePlRS08zlGqXDxyBHoBocY5AD0AIIYQQLSE7Gzp0ULfNem52NmzaBHFxapPk+Hi/j7UpJHiJeknoEkHJEegB+Cak/vsRQgghAiwvD8rK1G1Tn/vFg3+H+fPVnX/9K/Tu7d9BNoMELz8J12pXyHAEegCi1TkCPQDfSPgSQgghfJOVpYpU06c37bl923/JM5zcJHnaNBg71q/jay4JXqJOIfOB0RHoAYiAcQR6AEIIIYTwl5wcKC1VW281dsphzqwy/vmzMbSrKIG0NO5p/0CTpy22FAleIrQ5Aj0AEXCOQA+gYSHzSwwhhBAiCDR6yqFhwB//CPv2QWIivPwyi/5sb/K0xZYiwcsPwnGaYUh8UHQEegBCCCGEEMLfGj3l8C9/gRdeUJskv/wy9OjRrGmLLUWClwhNjkAPQAQVR6AH0LCQ+GWGEEIIEQT0lMP77rPe77Xr4c6d7nT1wAOQnl7vOQJJgleQk2qXF45AD0AEJUegByCEEEIIf/IMWrWmIH77LVx+udok+YorVKksiEnwaqaWnmYoPDgCPQAR1ByBHkD9gv6XGkIIIUQQ8QxalumDVVVw1VVw+DD88pfw5JNBsUlyfSR4BTGpdnlwBHoAIiQ4Aj0AIYQQou1qzibInjzXaVmmD951F2zZol4siDZJro8Er2Z4q89vAz0Evwrq0CVEYzgCPYC6tdX/zubPn8/5559PfHw83bp1Y/To0Xz++eeWY0pLS5kyZQo9e/akffv2nHXWWTzyyCOWYyoqKpg6dSpdu3YlLi6OUaNGcejQIcsxRUVFjB8/noSEBBISEhg/fjw//vij5ZgDBw4wcuRI4uLi6Nq1K7feeiuVlZUt8t6FECIc1RWwmrMJsqc612mtXg0PPqi+f+opOOus5r9YK5DgJUKDI9ADECHHEegBCLOtW7cyefJkdu3axYYNG6iqqiIzM5OysjLXMVlZWaxbt46VK1fy6aefkpWVxdSpU/n73//uOmbatGmsXbuWVatWkZ+fT2lpKSNGjKC6utp1zLhx49i7dy/r1q1j3bp17N27l/Hjx7ser66u5tJLL6WsrIz8/HxWrVrF6tWrmTFjRutcDCGECAN1BSxv3QSbWgXz+rzPP4cbblDfz5ih1niFCAleQaq1pxkG9W/hHYEegBD+FdT/vbWQdevWMWHCBM4++2zOOeccnnrqKQ4cOMCePXtcx+zcuZPrr7+ejIwMTj/9dP74xz9yzjnn8MEHHwBQXFzMk08+yaJFixg6dCipqamsXLmSjz/+mI0bNwLw6aefsm7dOp544gkGDhzIwIEDWbFiBW+88YarwrZ+/Xr+9a9/sXLlSlJTUxk6dCiLFi1ixYoVlJSUtP7FEUKIEOQZsHRIgtpVqqZWwWo9r7QUxoyBY8fgN7+BBQua/T5akwQvEdwcgR6ACGmOQA+gbuESvkpKSixfFRUVPj2vuLgYgM6dO7vuS0tL47XXXuObb77BMAw2b97MF198wUUXXQTAnj17cDqdZGa6mxolJSWRkpLCjh07ABXeEhIS6N+/v+uYAQMGkJCQYDkmJSWFpKQk1zEXXXQRFRUVliAohBCibp7TAOsLV03dU8vyPMOAm26Cf/0LevSAl16CqKhmv4/WFFqjbSOk2nWSI9ADEGHBQZv/uzTgcuho9+85S5zAK5CcnGy5/5577sHhcNT7XMMwmD59OmlpaaSkpLju//Of/8zEiRPp2bMnUVFRRERE8MQTT5CWlgZAYWEh0dHRdOrUyXK+7t27U1hY6DqmW7dutV6zW7dulmO6d+9uebxTp05ER0e7jhFCCNE4WVkqdHkLVzk56stTdrZ6TlaW98ctz3v4z+6w9be/QWKiX8ffGiR4CSHCn4OgDF9vbxvD8N+sCfQwmuXgwYN07NjR9XNMTEyDz5kyZQofffQR+fn5lvv//Oc/s2vXLl577TVOO+00tm3bxqRJk+jRowdDhw6t83yGYWAztRC2eWkn3JRjhBBC+K6ucFUfc5Ws3ufm58PMmer7RYtg8OAmjzOQZKphGyfVLtFmOAI9gPDUsWNHy1dDwWvq1Km89tprbN68mZ49e7ruP378OHfddReLFy9m5MiR9O3blylTpnDllVfy0EMPAZCYmEhlZSVFRUWWcx49etRVwUpMTOTbb7+t9brfffed5RjPylZRURFOp7NWJUwIIUTL0VMJU1Prab5RWAhjx6p9u66+GqZObfVx+osEryATiL27go4j0AMQovUE7S8//MwwDKZMmcKaNWt45513OOOMMyyPO51OnE4nERHW/y1FRkZSU1MDQL9+/bDb7WzYsMH1+JEjR9i3bx+DBg0CYODAgRQXF/Pee++5jtm9ezfFxcWWY/bt28eRI0dcx6xfv56YmBj69evn3zcuhBCiTnqdWEFBHevDnE4Vuo4cgbPPhscfb9Qmyf7cU8wfJHi1YUH5gc8R6AGIsOYI9ADarsmTJ7Ny5UpeeOEF4uPjKSwspLCwkOPHjwOqcjZkyBBuv/12tmzZwv79+3n66ad59tln+f3vfw9AQkICN954IzNmzGDTpk0UFBRw7bXX0qdPH9dUxLPOOouLL76YiRMnsmvXLnbt2sXEiRMZMWIEZ555JgCZmZn07t2b8ePHU1BQwKZNm5g5cyYTJ060TJsUQgjROupsvjFrFmzfrjZHXr3a3TbRR/7cU8wfJHgFEal2CdEKHIEeQG1B+UsQP3vkkUcoLi4mIyODHj16uL5eeukl1zGrVq3i/PPP55prrqF3794sWLCAefPmccstt7iOycvLY/To0YwdO5bBgwcTGxvL66+/TmRkpOuY559/nj59+pCZmUlmZiZ9+/blueeecz0eGRnJm2++Sbt27Rg8eDBjx45l9OjRrimNQgghWpfXjZJffhkWL1bfP/00nPzlWWM0tZtiS5HmGm1UUH7QcwR6AEKIlmIYRoPHJCYm8tRTT9V7TLt27Vi6dClLly6t85jOnTuzcuXKes/Tq1cv3njjjQbHJIQQIgA+/RT+8Af1/R13qL27mqApDT9aklS8RHBwBHoAok1xBHoAQgghhDDT67Fy7jimglZZGVxwAcybF+ih+Y0EryAh0wyFaGWOQA/AKiir0EIIIUQrUeuxDFIW/wE++wySkuDFF0Nuk+T6SPBqg4LuA54j0AMQQgghhBCeWrMrYFYW3Bmdx++rX3Fvkuxli49g61TYGBK8gkCbrnY5Aj0A0aY5Aj0Aq6D7pYgQQog2rTW7AuYM28aC6jsAmBGRR/bbgwI+Jn+T4NXGyAc7ITw4Aj0AIYQQIjh52+C4KRWnBp9z+LDar6u6mlWR17C4cnKdwSrYOhU2hgQvETiOQA9AiOAjvxwRQggRLLxtcOxrxckctrw9Rz9+z11OuPJK+PZbSEnhixmPYbfbqKjwHvS8tp4PERK8Aqw1pxkG1Qc6R6AHIISJI9ADEEIIIYKXucrka8XJHLa8PUc//pMH74D8fIrpyNUxa3jgL3EYBlRVNS7ohQIJXkIIAUEVvoLqlyRCCCHaPHOVybPiVNc0QvM0RR2+zFWqrCy4PmYVU6qWAHAdz7Jqzy8oKwObrfFBLxSEVPDatm0bI0eOJCkpCZvNxquvvmp53DAMHA4HSUlJtG/fnoyMDD755BPLMRUVFUydOpWuXbsSFxfHqFGjOHToUCu+i8AIqg9yjkAPQAghhBBCNEZdAauuipS3aYqWx6/6hKejbgJg66DZbIr7HWlpKmTNmlV30AtlIdUYv6ysjHPOOYcbbriByy67rNbjDzzwAIsXL+bpp5/m//7v/8jNzWXYsGF8/vnnxMfHAzBt2jRef/11Vq1aRZcuXZgxYwYjRoxgz549REZGtur7adPdDEXDNu/237ku6O+/c4UzB0Hzi4GN744K9BCEEEK0YXptVlaWCj/mgJWT4z4uK0vdV1dFyuvjJSXuTZIvvJAh/8ihtHU/hgdESFW8hg8fTm5uLmPG1K7eGIbBkiVLmDNnDmPGjCElJYVnnnmG8vJyXnjhBQCKi4t58sknWbRoEUOHDiU1NZWVK1fy8ccfs3HjxtZ+O22TI9ADCGKbd1u/QuXcQgghhAg7npWsuqb86YqUYXiviNWamjjX4O+db4AvvoCePdUmya1c/AiUkApe9dm/fz+FhYVkZma67ouJiWHIkCHs2LEDgD179uB0Oi3HJCUlkZKS4jrGm4qKCkpKSixfoSRophk6Aj2AIBSoMCRBrG6OQA9ACCGECBw9pTA11Rq0Gpry52sTjOoHF/G76jVUYodXXoGf/MS/byCIhU3wKiwsBKC7xw7X3bt3dz1WWFhIdHQ0nTp1qvMYb+bPn09CQoLrKzk5udnjlWmGbVgwBp5gG0+gOQI9ACGEECIwdIAqKPB9bVV2NlRUgN3eQBOMLVvIdd4JwPSIh8l+o/ZSiKbsExYqwiZ4aTabzfKzYRi17vPU0DGzZ8+muLjY9XXw4EG/jLU1SLUriIRCuAnGUCiEEEKIVtOULoJ5ear9e3R0PUHtm2/gyiuJMGp4znYdf6m5hQULvJ8rXNrHewqb4JWYmAhQq3J19OhRVxUsMTGRyspKioqK6jzGm5iYGDp27Gj5EsJnoRpkQnXc/uII9ACEEEKI1udrF0FzZaqhsOa4q5Jdva6Ao0ehb1+mRD4C2PBW90hNtd6Gk7AJXmeccQaJiYls2LDBdV9lZSVbt25l0KBBAPTr1w+73W455siRI+zbt891TGtorWmGUu0KsHAJLuHyPoQQQgjhN55dDusLa90fnMmAmp38SAKsWcOts2JdbeM9FRRYb8NJSAWv0tJS9u7dy969ewHVUGPv3r0cOHAAm83GtGnTuP/++1m7di379u1jwoQJxMbGMm7cOAASEhK48cYbmTFjBps2baKgoIBrr72WPn36MHTo0AC+MxFWwjWohON7aogj0AMQQgghgpPPUxJfeIE/VS0F4M0rn4Of/azeoBZOGyZ7Cql9vD744AMuuOAC18/TT/6JXH/99Tz99NPccccdHD9+nEmTJlFUVET//v1Zv369aw8vgLy8PKKiohg7dizHjx/nwgsv5Omnn271PbzaDEegB9CK2kIw0e9R9gUTQggh2rScHOt+Xl59/DFMnKi+nzOHa3JHWh723CvM/HM4bJjsKaQqXhkZGRiGUevr6aefBlRjDYfDwZEjRzhx4gRbt24lJSXFco527dqxdOlSvv/+e8rLy3n99df90qXQV21ummFb0RZCl1m4VvW8cQR6AEIIIUTL8dZFsDGdBc3HWp5XXKw2SS4vh2HD4N57az3Xs5FGQ401Qr3jYUgFLxFiHIEeQCtoSwHEm7b83oUQQogwoMNObq470NQVgLwFnwUL1LELFpiet9iACRPgq6+gVy/m93mBDgmRrnBmt6sOiJ57hTU0zTDUOx5K8BItwxHoAbQCCR1KW7gOjkAPQAghhGgZWVnu73Wg0R0Fy8ogPd36uGfw0Z0JbTZ3cFoz4AF49VWVrl55hXmPdXU9b8EC1Xre6ay9V1hDTTpCff2XBK9WJNMMw0hbCBuN0dYrf0IIIUSQq2tK4YIFEBEBUVHuQGPuKJif7z7W2ybJd96Jq0NhTg6UvvYOmVvuAuDvQ5fS4YLzXZWt1FQVujR9Hl+nEPra6j5YSfAS/ucI9ABakASM+oXztXEEegBCCCFE4+lQo6cEmqtVeuPjmhqIiXEHmqwsFcbAXfHytklyrWYYhw7BVVepE95wA9dsmUhZmbuytWuXdVz6PKE+hdBXErzCjFS7WlA4hwp/kuskhBBCtApvlaLcXOutDjU2m3uann5eaqqqdJmrWDpM3XUXGAZs26buz8pSx1ZW1l4LtmABdI6r4OCAy+G77+Dcc+EvfyFrus0yNVBPS7TbrVWrrCx1X0VF6DbO8IUEr1bSWtMMA84R6AG0EAkTjROu18sR6AEIIYQQ7uC0cGHtStHy5dZbvV6rf3/3ND0dmAoK1Fqrykrv1SdzsMvJUcHJ6XQ34tBrrmw2yCmfTvI3uyniFP7v49Vk39++1tRA87RE8/vYskWdt6oqvKteEryEaEi4hoiWJtMyhRBCiBahw5Fh1G42MWmSup08Wd3q6X35+e5qkmeTCnPAMlef5s1TrzNvnnrcvD5LV9RKS+GF4c8xGZX0ruF5vqz+qdcA5RnE9PvQ68igduOMUG8hbybBK4wEfJqhI7Av3yIkODRfuF1DR6AHIIQQoq3TwWn27NrNJubOVbdz5qhbPb0P3NWkugJQXp56LDpahSzDUI8bhno8MtJ6vtxcWPbHj7h8g5rZtTn9bv4RcQngrrTVF5z0+0hLU7fmdV/mMYfL+i8JXkLUJdwCQyDJtRRCCCH8xtfufjrs2Gy1uxGaeVbAdNXL0+zZEBvr/jmBH7l4xRg4fpwvf3oRv9tzt6sph66w1TV10fw+MjLUzzroeVbgGttCPlirZBK8WkGbWd8VTiQo+F84XVNHoAcghBBCNCwvT62dio11r+PyFko8g5yueplFRanHdSXLRg3Pch0/59/8l9O4sPB5jpVH1qqw6eCUmqoqZJ6bNevjzFUtzwpcY1vIB2uVTIJXmJBphn4UTgEh2Mi1FUIIIerlz2qNt7VcOvx4hpLsbBW27HZ3pSkqyr3H1+zZ6ji9x9ddEQsYxeucIIYrbKu5fnoXV+OMuXPdr5uTo85lXscF1tf3VnFrzkbJwbrRsgQvIcwkGLS8cLnGjkAPQAghRDjyZ7VGV4s2b1bTDefNcz+WmuoOeOnpKpDpzoK6cYbTCdXV6tYw3C3oR7TbwH01ajHZZP7Ctz37Wfbz8raGTNPrucyhyFvFrTkbJQfrRssSvFpYm5hm6Aj0APwkXAJBKJBrLYQQQgC1K1zeqjVNrYLpKpauNuk1VGlpqnKlA55nNQrU3lzm19St6w/vOsDrcVcTgcET3MhfuZGDB+sPi/o9ZWfD9u3BGYpagwSvMBDwaYbhQIJA6wuHa+4I9ACEEEKEOs8Kl7dqjecxvgYxvcbL065dUF6uvk9NVUFMi4hw781lfk3DgGgqWFV1OXz/Pd/06McUlgHuzZlTU63TFTX9ngzD++NthQQv0TyOQA/AD8IhAAghhBAiJPmyHsnzGF+nI+ruhDab+wvU9EFd/dq9273XF0BNDXTq5A5slZUqJA0YAA9zG+fzPt/TmVWXvcLtc9sRFweDB7vPZZ6uqMOVDooLFrSNjZLrIsFLtG0SugIrHK6/I9ADEEIIEcp8WY/keUx9GyB7Pq+yUu3pFRurmmSAutWNM3QQMjt0yP2906lC1M/yn+YWHqMGG9fwPPc8dbprXHraomFY29B7dinUbe2jooKv8UVrkODVglpjfVdApxk6AvfSfhEOH/rDgfw5iBC3bds2Ro4cSVJSEjabjVdffdXyuGEYOBwOkpKSaN++PRkZGXzyySeWYyoqKpg6dSpdu3YlLi6OUaNGccj8yUcIIUzq2wDZG70+y+lUoad/f4iJwbXnVkPOpYBH+BMADhyst11sCU7mDZ3vvLN2uNKPz5qlgqDTKWu8hGg75MN+cJE/DxHCysrKOOecc1i2bJnXxx944AEWL17MsmXLeP/990lMTGTYsGEcO3bMdcy0adNYu3Ytq1atIj8/n9LSUkaMGEF1dXVrvQ0hRAD4q3W8bv1eWenuSGhmrmhVVcGOHSqI1dS4K191OYUiVnMZ7TnBm1xCLnMxDGtwMq/h0t0RY2LcnRCh7TbUMJPgJYQIDqEcvhyBHoAIpOHDh5Obm8uYMbVnIBiGwZIlS5gzZw5jxowhJSWFZ555hvLycl544QUAiouLefLJJ1m0aBFDhw4lNTWVlStX8vHHH7Nx48bWfjtCiFbky1otb+HM876cHBV0nE5Yvrz2OfQUQ62mRt0ahgpi+ueoKEhOdh9no4bnuZafsh/OOINlA1ZiEEF6eu3X0C3ptdTU4N3IOFAkeIUwmWbYRKH8AT/cyZ+NCDP79++nsLCQzMxM130xMTEMGTKEHTt2ALBnzx6cTqflmKSkJFJSUlzHCCHCk56CZ95Ty5OeJrhwofs+HWjMLd/1ufr2VcdcfLH7sTvv9P76usGGVlUF11+vNkAGmEsul/AWtGsHq1dz3tBOREWpZhyeY/VsSV9QoN4XuG/buqiGDxFN0Sb27wpF8sFetBQHof0LCdEiCgsLAejevbvl/u7du/P111+7jomOjqZTp061jtHP96aiooKKigrXzyUlJQA4nU6c3vpHN0A/pynPFYpcw+Zra9fw7rvVV5cuqur08MPqZ7N27dzNMHSji8hIiI9XzSqcTli0SB0bEQH//Ke6dnv3OqmpgUcfhcOH1WMPPtjwmBYvVoFsVPQ/cFQ6AJgatYzOr6bw6KNOV/OMRYvUOefOVWOKjVXP69kTiopg8mT4y1+gfXv47DPvbe2DVWP/Hvp6nAQv0XiOQA+giSR0hYbNu+GC/oEehRB+ZdM9nE8yDKPWfZ4aOmb+/Pnce++9te5fv349sbGxTRsosGHDhiY/VyhyDZuvrV3D555zf//WW/U/9qtfwbPPNnzOv/7VfQ3181580bfxtP/2WzJmziSi0mD/RRcx9E9dgbd44onax+pzn5w9bWE+3vN9hQJf/x6W603RGiDBK0TJpskirEn4EmEiMTERUFWtHj16uO4/evSoqwqWmJhIZWUlRUVFlqrX0aNHGTRoUJ3nnj17NtNNbcVKSkpITk4mMzOTjh07NnqsTqeTDRs2MGzYMOzmftDCZ3INmy9cr2FurrvaFBenKlAASUlqymBUlFqjNXmyav1upo/Rz8vNVeu49LG5uar6pNdpxcU5eeKJDfzhD8OIiLC7Xgvg1FNVkwvNZlNVqqgo6N4dvvkGYowTbKrIINo4xodR53FXxStsuzrG9ZyICFVxMww4/3z46CM1vfGjj6xjWr4cJk1Sz9Hf6ymMwa6xfw/1jIOGSPASbYNUu0RrcBC6FWHRIs444wwSExPZsGEDqScXOVRWVrJ161YWnlyw0a9fP+x2Oxs2bGDs2LEAHDlyhH379vHAAw/Uee6YmBhiYmJq3W+325v1gbW5zxdyDf0hnK5hdra16cTMme69rm65Ra3Xmjat7o5/t9yi1nf9+KM6JidHhayHHoJNm9Raqqwsdaz5dU6csFNebuenP1VT/7Ky4LvvvL+G3Q5ffaW+f5hJ/IoP+R9dGF21moNbOtCzp3VvLx2g9Ovt3q0CXXa2mnKouyjed58KajU1Khx6KdIHNV//Hvr6d1WCVwsI6/VdjkAPoAkkdIUmqXqJEFFaWspX+hMLqqHG3r176dy5M7169WLatGncf//9/OIXv+AXv/gF999/P7GxsYwbNw6AhIQEbrzxRmbMmEGXLl3o3LkzM2fOpE+fPgwdOjRQb0sI4Sfmjn7Z2e6AlZ2tHsvKsoYufX+nTirspKVBdLSqeumgs2CBCje6oYW3roG6cYYOTAsWqHVhpp0sXPr3h3ffhQnGX5nIE9Rg42pe5CC9LOfQ9Otruviel1d7M+aaGhXsGtow2Xw9cnLqPzZUSVdDIUTwCsXQ7Aj0AERr++CDD0hNTXVVtKZPn05qaip3n1whf8cddzBt2jQmTZrEeeedxzfffMP69euJj493nSMvL4/Ro0czduxYBg8eTGxsLK+//jqRkZEBeU9CCP/R3QbNoQtUeNGdCdPT1bS/9HR3x0IddvLz3RUtUOFLTysE9bzp0xvuHFhTY32efq7drl7jXONDlqPmBr6TkcMm2zCv57HbreHK/L70fmJ2u7UtvdNZu4Oip7bQel6CVwiS9V2NEIof3IUQISUjIwPDMGp9Pf3004BqrOFwODhy5AgnTpxg69atpKSkWM7Rrl07li5dyvfff095eTmvv/46yeZPLUKIkKU3FzZXujp0AL0/ek2Nu3KlQ1ZcnKpOgTvAmPfiMm94rDczLiiwvq7n7DfDAM8eEIahQlEnfmA1l9GOCl5jJJlbZtcZlKKj3d+npdXeSNnpVBs5HzhgXdPVUKDS77uhylgok+AlfOcI9AAaSUJXeJA/x7Awf/58zj//fOLj4+nWrRujR4/m888/r/P4m2++GZvNxpIlSyz3V1RUMHXqVLp27UpcXByjRo3ikMccmKKiIsaPH09CQgIJCQmMHz+eH3/80XLMgQMHGDlyJHFxcXTt2pVbb72VyspKf71dIYSok67sREWpoGEOUeaNiU+cULfffKOqXLrKZLfD7NmqWgXuSllZmfV1PDucG0btqpPNpjZJXsm1nMF/+YqfcR3PYpgigvl3QHa7tfrmGfY85eSo8OVLoPIMqOFIgpefhfX6LiECJdTClyPQAwg+W7duZfLkyezatYsNGzZQVVVFZmYmZZ6fFIBXX32V3bt3k5SUVOuxadOmsXbtWlatWkV+fj6lpaWMGDGCav2rY2DcuHHs3buXdevWsW7dOvbu3cv48eNdj1dXV3PppZdSVlZGfn4+q1atYvXq1cyYMaNl3rwQQpjoys6sWSpozJrlnoq4bZs7mDmdKuh4Tg/UFa7Bg9XPp55ae/Pi+nhWy7LJ4RLeppz2XMZqijnFcuzBg+7jnU5rmEpNVWOMjva++TO0jUDlKwleISZg0wwdgXnZJgu1D+pChLl169YxYcIEzj77bM455xyeeuopDhw4wJ49eyzHffPNN0yZMoXnn3++Vpeo4uJinnzySRYtWsTQoUNJTU1l5cqVfPzxx2zcuBGATz/9lHXr1vHEE08wcOBABg4cyIoVK3jjjTdcFbb169fzr3/9i5UrV5KamsrQoUNZtGgRK1as8LklsBBCNFZ2tgooCxZYG2p4BhNzRSk6Wm1IbFZdrc6lw5Zn44uGmJeOXszb3INqNbj4F4+yL+Icy7GeoU9X5PSYCwpUJc7pVO+rQ4e6A5iQ4CXCkYSu8CR/rmGluLgYgM6dO7vuq6mpYfz48dx+++2cffbZtZ6zZ88enE4nmZmZrvuSkpJISUlhx44dAOzcuZOEhAT693d3xBwwYAAJCQmWY1JSUiwVtYsuuoiKiopaQVAIIfwlL08FlKoq7+uddION3Fz3NELd2dDMMKxt430xd667SqWnG57Ofp7nGiIweO9XtzD3i+ssQSs+3j0ObcgQ68/mZho2m6rULVwoAawuEryEEKEjlMKXI9ADaB0lJSWWr4qKigafYxgG06dPJy0tzdJkYuHChURFRXHrrbd6fV5hYSHR0dGWTYYBunfvTmFhoeuYbt261Xput27dLMfozYu1Tp06ER0d7TpGCCH8LStLBZSoqNrrncwVLKjdCh7czTYaMnBg7ftyc2HePDU10GaDdhxnNZfRmSJ282vSP1xCerpqlqEdO2atjoEKjNnZ6n6bDZ5+Wm383L+/GrPdrm4b251QNxwJ97Am+3j5Udiu73IEegCNEEofzIVoLdOADn4+ZynwCrU6791zzz04HI56nzplyhQ++ugj8k2fMvbs2cPDDz/Mhx9+iM3zV6wNMAzD8hxvz2/KMUII0VTe9qTKyam9P5U+rq7ePsnJ7jVWx465NyOuz86doH9/Zbe7m2wYhg53Bo8xmV9RwHd05XJeoZIY8vNVVWzXLncjD889uTp3VuPVYzC3vAdVUcvKUsc0pjuhuZV8uO7hBVLxCinSRl4IJFwHmYMHD1JcXOz6mj17dr3HT506lddee43NmzfT07RwYfv27Rw9epRevXoRFRVFVFQUX3/9NTNmzOD0008HIDExkcrKSoqKiiznPHr0qKuClZiYyLffflvrdb/77jvLMZ6VraKiIpxOZ61KmBBCNIXnnlR1VXT0cYahQktamrrVvwM6dMjaFr6h0OXJs7OhzQY38QQ38BTVRHAVq/jGpn6Blpxs7Z6omdvYHzxYuyW9Pq/uXNiUZhptoZU8SPAS4UQ+kItg4wj0AFpex44dLV8xMTFejzMMgylTprBmzRreeecdzjjjDMvj48eP56OPPmLv3r2ur6SkJG6//Xb+8Y9/ANCvXz/sdjsbNmxwPe/IkSPs27ePQYMGATBw4ECKi4t57733XMfs3r2b4uJiyzH79u3jyJEjrmPWr19PTEwM/fr188+FEUK0aZ5BYuFC9/onvZYrIkKt4QLVMKNTJ1U5On7cHbz0Plv+0s94n2VMAWAuubzDhURGqtf54QfrsXoMAwZYG3zoaZB6bVdUlKqU1RW2fJlGWNdeZ+E29VCCl6ifI9ADEMILCdkhZ/LkyaxcuZIXXniB+Ph4CgsLKSws5Pjx4wB06dKFlJQUy5fdbicxMZEzzzwTgISEBG688UZmzJjBpk2bKCgo4Nprr6VPnz4MHToUgLPOOouLL76YiRMnsmvXLnbt2sXEiRMZMWKE6zyZmZn07t2b8ePHU1BQwKZNm5g5cyYTJ06kY8eOgblAQoiwkpOjwtfixSo86LBSVeWelmcY7ql65u9ralQo0xUw3biiuTOhu/A/XuFyYqjk74xiIXe6xpSebu2mqMcEarzmSQI2mwpbs2erKZJOpzq2rqDkWf3zRVOeEwokeInwIB/EhQhqjzzyCMXFxWRkZNCjRw/X10svvdSo8+Tl5TF69GjGjh3L4MGDiY2N5fXXXyfStAL8+eefp0+fPmRmZpKZmUnfvn157rnnXI9HRkby5ptv0q5dOwYPHszYsWMZPXo0Dz30kN/erxCi7dLVGl3lysuDxET1mHkDY5vNHayiotxVpYgIFWqyslS7dr3xcWystflFY0RQzfNcw2kc4Et+XmuTZB0G6zq/OfRFRqqGGps3q/eZnq6mKNYVlJoyjTBcpx5Kcw0/aenGGrK+SwgPm3fDBf0bPi7QHEjlGDXVsLH++9//1rqvXbt2LF26lKVLl9b5vM6dO7Ny5cp6z92rVy/eeOONRo9JCCEaoqs1UVHWdU+avs88LU832Zg7Vx2bnu4OQ3rDYz0VsSkcOLiI9ZTTnjGsoYQEr+M+OQnBpWdP+PZbFfzS0tTrV1VZK3fmMXkLSt6aijSkKc8JBVLxEnVzBHoAPpJqlxBCCCGCQHa2mn6np+LpdUu6kmSzqZbuegqifo6uGOlNiM1hxrODYGNdyhtkozb+utm2gn308XpceXnt5h2Fhe69xwoK6n8du71xDTXaIgleQojQJaFbCCFEENGbJMfEeF/3pFu665AF7ltQwaeszH/j+Sn/5jnGA7CUKayNvabOY80TE5KTVXg0dzhMTbU22QBrx8NZs8K3KYa/SPASoU0+eItQ4Aj0AIQQQpj5IyB4niM7GyoqVOVn+nRrgwhzBUtPHayuVhUwc7ipr1283d64NV7tjXJWcxmd+JGdDGAGi3wKdTYbHDlSu618QYFqJz93rpoumZ2tOh6CGtd994VvUwx/keAVAmR9lxD1kPAthBCikZoaEMxhS58jN9f9c1UVREer6pE5hOnAlJysgpfdbq0weTLv3QUqDLk3QPaBYfCwcwrn8k++pRtX8DecRFsO8axemVvYe4YuUFMRs7Otrd/19MP8fPVYuDbF8BcJXn7Q0o01AsIR6AH4QD5wCyGEEKIJmhoQzIHN3H5d/6zPqUOY06mCWX4+xMeripEOZ/VVrzz37oqM9B6G6nL6P/7BtdUr3Zsk07PWMYcPW38ePNi6ebMnw6gdVFNT3d/n5TVt8+S2RIKXECL0SQgXQgjRCE0NCOZwlZPjDk/mAGIY1lCmK1vHjrnv69wZ3n3X99dtTOg6v+Y9+jzxBACzWMAWLvB6nOe0xvx867htNjWtUO8jFhVVO6iaG254C7Gy5stKgpcITfJBW4QaR6AHIIQQork8A9vukx9H8vOt+3bl5KjQUpeDB+ufathUXfmO5yuvIqKqilcjRvMQMxv1/Nxc67h0s5DYWHV7333WMKWDaHa29xAra76sJHiJ2hyBHoAQTSBhXAghRCszhxTDsE5fNFfEWkME1bzI1fQ0DlGalMTN0U8Adcwb9JGu5HlOKTQHzPoqh7Lmy0qCV5CTxhpeyAdsIYQQQgSBxET39+Z9u3RVaNeu1htLDtkMZRNlxPLerFkcs3Vs1PPNreH1z3oqYUGB2tTZZnN3ZTSHsTrHJGu+LCR4NVNYNtYQIlQFeyh3BHoAQggh/Mm8qbE5XOiqUFWVCit1Nazw1NiW8doo/s5dzAfgT/bHONarV6PPMWuWmh4ZFaXG0b+/tTOj7qio16o1tKGyqE2Clwgtwf7BWgghhBAhSVepkpNVUEpP9/54err7Vgeq9PTaa580w3B3DGyI09mIlvEn/ZwveZbrAFjCbbwSdWXjTnDSggVqnRrAnXeqYKU7MN53n7UlvkwfbJqohg8RbYoj0AMQopk274YL+gd6FEIIIUKMrlLpTYY9A5B+XN9vfnzXLvWzYagAM2uWe+8tUB0MW6KZRnvUJskJlJDPYG7nQewNPw2wjg+snRN1e/y8PHfA2r7db8Nus6TiFcRkfZcQQgghRPP50tZcN4JITlY/e1a89Jqmnj3VceYpgU6nO8TYbCqweDbe8D+Dx7iZvnxMId25gr9R5XPsqn9MqalqfVZWFixeXPu6SZv4ppHgJUKHTDMU4cAR6AEIIUTb40tbc90I4sABFUq2bbM+rtc0FRWpYKIrXjabWgelA1u7duq1fF3X1VSTWM54VlJFJGN5mUJ6NPictDTfxqXfa13XTdrEN40Er2Z4khsCPQQhhDcS0oUQQpg0pa15drZa32S3q+pXZaV7E2HzNMPISDVN7+BB9bNuPmEYEB9vPacOac3Vn13koRaS3cEDbOc3Pj2voKDh4GXeKDkrS/1cWWmtbkmb+KaR4CXcHIEeQD3kg7QQQgghmqgpbc315sFVVSpoOZ0QE6POEWH6BO25VsocrHQI0wxDnac5fsJRXuFyonHyNy53BTBfHD8ONTV1P56d7d4oGdR1s9nUfbrxhr5f2sQ3ngQvIYQQQgghTLKzVSv1iAhV8UlLs1Z4kpLcx7ZrZ31uc4NVfSKpYhVX0ZNv+JRf8gf+SmM2SfYWunSITE5WjUHsdmt1SzfdMDffEE0jXQ2DlDTWEKKZgrm7oYPgrjALIUQbk53t7uQHkJurbuPiVGVHH7N4sapamffv8qxqeYqK8l9oyWUuv2Uzx+jAGNZQSnzDT/LQs6d1/HPmqPek3zOo77dsse7VFRnZ9HELRYKXCH4yzVAIIYQQLaiuZhGdOnk/Ji3N9/22/BW6RrOWWaj5fjfyJJ9xVpPOU1joDoNRUWq6YIcOtY/T789uV2vdZD1X88lUQ6E4Aj0AIVqAhHYhhBA+0K3iU1Otmx/rylB6ugpdEREqgGzfXntDZD1Fb+5c/zTQMPsFX/AM1wOwiOn8jbFNPpeebmi3w+zZ6nvdLEOP32zWLFnP5S8SvERwkw/OQgghhPAjb3tQ6Sl1BQWqcUTPnupn3SJeV39qalQA0UHMrLLSPWXPn+u8YiljDWPoyDG2kc4sFvj0vIEDa99ns6nwWFWlqljmJho6XOXkuPcoi4hwNw6RvbuaT4KXEEIEgiPQAxBCiLbJ27RCz/boRUXq9ocfrBspewYxLT5ehZJ58/w9WoMVTCSFTzhMD8byss+bJK9bp6YSamlpKjjOmqXea2pq3UFKV/RqatzXSfbuaj4JXkKI8CZVUyGEECZ6WmF5uTt0eLZH10HMvFEywJEjKqx47s917JgKJea28v4whWWM40WcRDGWl/mWRJ+f27WrdX3Zbo//He7apcacm+u+DuaqlmcYlb27mk+CVxBq9Y6GjtZ9OZ/JB2YhhBBC+JmeVmgYqnpT3xS6HTvc39ts6qusrOFOhv4wiHdZjEo5t/Mg75LWqOd7TnfUoVBXrswbKes9usxVLc8wKnt3NZ8ELyGEEEII0WZkZakpeHa7qt7osKErP9nZ6vuyMuu+V3PmQP+Tu5T4u3mGp+4U8jJjsVPFKq7kYW7z+bm2Orb1GjDAvT+Z3a6mHOqpiFVVKnymprqrWuZAKuu7/EPayQshwl8w7+klhBCiVeXkqC/NvIeVeS8rT+bHWmOT5FM5zCf05iaeoDGbJNe131ZBgZpeWFWlwtnixSqMFRSoxiBlZep7vW9Zhw7WNV3mSphoGql4ieAk0wxFW+AI9ACEEKJt8azc6I2TdRdDs7TGzezzm/nMJoOtlBDPZaymDC+bbNWjrorX9OnuxwxDBal331W33bvXXr9lXtMl67v8QypeQgghhBCiTfBcw6R/9mwND5CRob7qq4L522W8wu08BMANPMXn/LLR5/BWjcvOVmuz9Lq21FR39QvUfmWejUE8K4NS6Wq+sKt4ORwObDab5Ssx0d0BxjAMHA4HSUlJtG/fnoyMDD755JMAjjjAHIEegBCtRKqoQgjRZtS1PqmuTn1pabXXbeXmtm7oOpPPeIobAHiQmazhMr+de/NmdasbZGzfDjEx7sfT02UdV2sIu+AFcPbZZ3PkyBHX18cff+x67IEHHmDx4sUsW7aM999/n8TERIYNG8ax1mhP44NW72gohBBCCBFmzJUtb/tPbd6sQgao8LVrl/o+UNML4yhlDWOIp5TNZDCb+X49f36+ClR2u9o42RxCs7Nh2zbZp6s1hGXwioqKIjEx0fX1k5/8BFDVriVLljBnzhzGjBlDSkoKzzzzDOXl5bzwwgsBHrVwkcqEEEIIIZpB79WVmuoOGJ06ubsV5udbg1lVlZqiV1AAc+daNx5ueQZPciO9+ZRvSOIqVlHt59VA6enW9+mtXbys42p5YRm8vvzyS5KSkjjjjDO46qqr+M9//gPA/v37KSwsJDMz03VsTEwMQ4YMYYd5owYPFRUVlJSUWL6EEMIvHIEegBBChB+9V1dBgTtgHDrkfjwtzR0ydEiLiFA/5+SocBIX1zpjncYSruRlnERxBX/jKN19fq5ui5+crH6OiICBA9X3druqZhmGqmh5ttH3nFoo+3S1vLALXv379+fZZ5/lH//4BytWrKCwsJBBgwbx/fffU1hYCED37ta/0N27d3c95s38+fNJSEhwfSXrv91CiNAi1VQhhGgTvFVv9DTC9HS1xikrS7VU333yfw01NWoKYnq66v7XqVPLjzON7TzI7QBMZzE7GVTrmPr2DNMVrIMH1c81Ne5pk9HR1hCVk6P27oqOVu9TV//01EJZ49Xywi54DR8+nMsuu4w+ffowdOhQ3nzzTQCeeeYZ1zE2jz6bhmHUus9s9uzZFBcXu74O6r/doc4R6AF4IR+MhRBCCNEI2dkqTNjtKjTptVue1Zvt293VH/MmybqzH6gpiPn56vtDh+puze4PiRzhZcYSRTXPM45lTPF6XGP3DNPdCSdPrv2YXsel3yO4w6ms8Wp5YRe8PMXFxdGnTx++/PJLV3dDz+rW0aNHa1XBzGJiYujYsaPlSwghhBBCBF5engonVVXWtVt1SU+3div0bKNuVt9jzRGFk5cZSw8K+ZgU/sjjNGaTZF88/7wKjvqrY0e1UbL+WU9FNK/xstuhokKqXi0l7INXRUUFn376KT169OCMM84gMTGRDRs2uB6vrKxk69atDBpUu7Tb2qSjoRBCCCFE4+jAEBXl3ghZr9vyxlztCZSF3Ek6+RTTkctYTTn+X1D2zTfWn48dUwHVMNSXt6mI0dEqwErVq2WEXfCaOXMmW7duZf/+/ezevZvLL7+ckpISrr/+emw2G9OmTeP+++9n7dq17Nu3jwkTJhAbG8u4ceMCPXQhRGsIxumsjkAPQAghQldOjqrkOJ1QVKTu0801PNctZWe7pw+mp6sOhvWtoWoJV/Ay01HJ5nqe4Uv+z6/nr2t6ZHy89Wdv3Quls2HLatVmma3h0KFDXH311fzvf//jJz/5CQMGDGDXrl2cdtppANxxxx0cP36cSZMmUVRURP/+/Vm/fj3xnn8bResLxg/EQgghhAgZWVmqWqO79ukphbm5sHCh+t4wVLjYts39vNbaKPks/sVf+QMAC7iTvzO6WeeLi1Nr2SIi1Puy2WDmTPXYqafCV1+px+bMUdWt9HRV8UtL8969MCdHfYmWEXbBa9WqVfU+brPZcDgcOByO1hmQEEIIIYRoFebgoJtsaE6nmo5orujoINIa4ilhDWPoQBmb+C1zaXzai4pSnQsNQ32v38ecOe7AOXcuvPUW/Pijeqx9e3fIMrfZF60v7KYaCh85Aj0AIYQQQgj/09MLvbWDHzBANY9YsEAd13rrvQz+yh/4JZ9ziFO5mhebtElyVZU7eEVHq9sOHWDLlpOvYmoG0revujWvdzNvLC1anwQvIUTbI9NahRAiJHmu2dJ7bqWnu4/RbdHNGybr5xYUuPe+8pxe2JKt46ezmMtZTSV2LucVvqNbs84XFaXCk26J762b40cfqVtzdUsqXoElwUsEB/kgLIQQQrQZTd2sV4eq3FxrxcpcudINItLS1PomUMHsvvvUY97YbGqKXkv4DVtZyJ0ATGMJuxnQ7HNWVbk3StbMUw9BNRzxvE+aZwSWBC8hhAgGjkAPQAghWk9TNuvNzlZhwnyOtDT1fXq6O8yBajixfTvcdZcKH7t2qcdzcmoHrPh4NX3vvvvc7ej9pQeHXZskP8e1PMKf/HZu88bPmrlhhtOpAuV999W+Nt4aa4iWJ8ErSMgeXkIIIYRoK5pSedEbJdvt6rmpqWrKXFoafPihWrdlDnO6q6F5aqEOXzqwgdrfyhxM/MVOJX/jCrpzlH/Sl5t5DH9vkmzmbaqkXvPVlKAr/E+ClxCibZLprUIIETA5OY2vvOiwNmuWem5BgXV9k81mDXPeQsa8eSpgZWRY77//fu/rwprjQW5nMDv4kQQuYzXHifXfyU+y21WI1NfFLC4OZs9W38sUw+AQdu3khQ8cgR6AEEIIIUTj6DbxixerSo7es0tXvqZPtwa5rCwVtMyd/gzDvUbMrKbGv2O9ihe5jT8DcB3P8m9+3uRz2e2qYucpORkOHLDel50Njz4KTzwBhw+7N4eW/bmCg1S8ROBJ5UEIIYQQPjBPmdNVs+3ba1fPsrPVMXPmqDVerels9vEENwEwj7t4nVHNOp+3tVwAhYXWBiV6amVZWbNeTrQgCV5CCCFa3Pz58zn//POJj4+nW7dujB49ms8//9xyjGEYOBwOkpKSaN++PRkZGXzyySeWYyoqKpg6dSpdu3YlLi6OUaNGcchjblBRURHjx48nISGBhIQExo8fz496J9GTDhw4wMiRI4mLi6Nr167ceuutVJpX7QshglJWlqriVFTU3RExPd0dQHJz1d5dcXHu6k9L6kgxaxhDHOVsYCh30/wuFuaKnWa3u6t3ekql59TKrl1rX6OmdpMU/iHBSwghRIvbunUrkydPZteuXWzYsIGqqioyMzMpM/1q9oEHHmDx4sUsW7aM999/n8TERIYNG8axY8dcx0ybNo21a9eyatUq8vPzKS0tZcSIEVRXV7uOGTduHHv37mXdunWsW7eOvXv3Mn78eNfj1dXVXHrppZSVlZGfn8+qVatYvXo1M2bMaJ2LIYRospwctXFwVZWaRmizqZbx5iDhuSnyjh0qoHibrudfBk8zgf/jSw6QzNW8SA2Rfn8Vmw3uvFOt6TKv29LruHTAdDprhzFpshFYEryEEG2XTHNtNevWrWPChAmcffbZnHPOOTz11FMcOHCAPXv2AKratWTJEubMmcOYMWNISUnhmWeeoby8nBdeeAGA4uJinnzySRYtWsTQoUNJTU1l5cqVfPzxx2zcuBGATz/9lHXr1vHEE08wcOBABg4cyIoVK3jjjTdcFbb169fzr3/9i5UrV5KamsrQoUNZtGgRK1asoKSkJDAXSAjhMx0wdCXIMKydDD3Vt34rwo+fhO/gAX7Pq1QQzeW8wvd0bfQ5fNnEWb9fzwYl+udp09TPdnvtZhrSZCOwJHgJIUSwcAR6AK2nuLgYgM6dOwOwf/9+CgsLyczMdB0TExPDkCFD2LFjBwB79uzB6XRajklKSiIlJcV1zM6dO0lISKB///6uYwYMGEBCQoLlmJSUFJKSklzHXHTRRVRUVLiCoBAi+Ok9t2y2ujsZ2u2qCUVd/NVU4wLe4X7uAuBW/sz7/LpJ5/E2rVAzdzCcPl1NqbTZ1PszTx/U+5T973+1u0Y2pZuk8B8JXkIIIZqspKTE8lVRUdHgcwzDYPr06aSlpZGSkgJAYWEhAN27d7cc2717d9djhYWFREdH06lTp3qP6datW63X7Natm+UYz9fp1KkT0dHRrmOEEMFLT5crKlJBRW9+DKqiY2YY8MMPvp23qWvATuUQq7iKSGp4igk8zh/rPd5ms+4jZuZZgTNv6Ox0qjb4OjjpKZWHDsn0wVAh7eSDQJvePFmmegnR4t7q81tiO/r3n/vykirgHZI9fpV8zz334HA46n3ulClT+Oijj8j3XIgB2Dzm2RiGUes+T57HeDu+Kcf4S1VVFQ6Hg+eff57CwkJ69OjBhAkTmDt3LhEnP2UZhsG9997L448/TlFREf379+cvf/kLZ599tt/HI0Soy8pSmyUfP67C0qxZsGVL7bVdoNaC1dUV0FP37o3fx0tvktyN7yjgXCaxnIY2STYMFaA8xxsRAXfdZW11X1SkKlj6vnnzVMDKylLhLT9fVbx++EGmD4YCqXi1NY5AD0AIEU4OHjxIcXGx62u23q2zDlOnTuW1115j8+bN9DT9KjcxMRGgVsXp6NGjrupUYmIilZWVFBUV1XvMt99+W+t1v/vuO8sxnq9TVFSE0+msVQnzh4ULF/Loo4+ybNkyPv30Ux544AEefPBBli5d6jrGl8YiQrQ1nh349M+gqkY1NSpULVjgPXQ1VlM2T17EDAayiyJO4TJWc4L2Pj3Pcx8xUK3vc3Kslbfp0633mTsZbt+ufr7+evdj3kgnw+AhwUsIIUSTdezY0fIVExPj9TjDMJgyZQpr1qzhnXfe4YwzzrA8fsYZZ5CYmMiGDRtc91VWVrJ161YGDRoEQL9+/bDb7ZZjjhw5wr59+1zHDBw4kOLiYt577z3XMbt376a4uNhyzL59+zhy5IjrmPXr1xMTE0O/fv2aeUVq27lzJ7/73e+49NJLOf3007n88svJzMzkgw8+AHxrLCJEW+TZgW/BAneLeHMVq6oK4uOtz/XWNKO+tV5NMY7nmcoyAK5lJfv5aZPPZbOp6YPZ2dYA9dRTKjT176/WdpnXeGme10mHOn0rnQyDhwQvIUTbJtNdW8XkyZNZuXIlL7zwAvHx8RQWFlJYWMjx48cBNfVv2rRp3H///axdu5Z9+/YxYcIEYmNjGTduHAAJCQnceOONzJgxg02bNlFQUMC1115Lnz59GDp0KABnnXUWF198MRMnTmTXrl3s2rWLiRMnMmLECM4880wAMjMz6d27N+PHj6egoIBNmzYxc+ZMJk6cSMeOHf3+3tPS0ti0aRNffPEFAP/85z/Jz8/nkksuAXxrLCJEW2TuwJedbQ1bhmHtAHjsmNoo2W5Xx7b3Ung6eNB/Y+vDR6xgIgD3kc1bXNqs8+n34xkq9fqtgoK6N4tOTbXeLl9uvZVOhsFD1ngJIYRocY888ggAGRkZlvufeuopJkyYAMAdd9zB8ePHmTRpkmud0/r164k3/So7Ly+PqKgoxo4dy/Hjx7nwwgt5+umniYx075Xz/PPPc+utt7qCzKhRo1i2bJnr8cjISN58800mTZrE4MGDad++PePGjeOhhx5qkfd+5513UlxczC9/+UsiIyOprq5m3rx5XH311UD9jUW+/vrrOs9bUVFhaWaiW+E7nU6cTdiwSD+nKc8VilzD5jNfw7vvhrvvVvcnJdUOU3Fx0Lcv7Nxpvf/hh6FHD/jmm5YZY4LxI2sqLiPWOM6GiGE8EH0X7W0t82fes6da59W3L/zkJ+r2o4/ct5MmwWefqWvz2WeqAceUKWosU6c6cTqxXEf5q+mbxv637OtxNsOor3Gl8KakpISEhASGFj+HvWNss8/Xqs01HK33Uj6RaoMIBhf0b/iY1uI4eVtWApckUFxc3OQqjP636sXilmmucXXCO80aX1uxatUqbr/9dh588EHOPvts9u7dy7Rp01i8eDHXX389O3bsYPDgwRw+fJgePXq4njdx4kQOHjzIunXrvJ7X4XBw77331rr/hRdeIDa2+f9vEkJ4UVPDrxcsoMd771H+k5+wZdEinPJvYJtXXl7OuHHjGvx/olS8ROBI6BJCtAG33347s2bN4qqrrgKgT58+fP3118yfP5/rr7/e0ljEHLzMTUO8mT17NtNNc4dKSkpITk4mMzOzSWHY6XSyYcMGhg0bhr2pfbXbuLZ4DXNz1ZS2SZPc+0c1h76Ge/cOY+FCdQ2jouD7792vNXmyakRx8cW1q10tbaZzIb+reo8KoskseY0Pb27+utBTT627Onf77e6uhsuXq2mHWlSUmp44bZr12nv+PUxKcj8vLg4OH272kMNeY/9b1jMOGiLBSwghgomD4KtMi2YpLy93tY3XIiMjqTm5c6u5sUjqyUUaurHIwoUL6zxvTEyM12Ymdru9WR/6m/t80bau4aJF6kP9okXgpQDrs+xs1fxhxgz41a9g2TI7x4+ra2i3qzVNuo263rHinXeaP/7GuJCN3MM9AExhGe9WDPDLeb/6yh2i+ve3dmjMzVXdG/V7X7BArQGLilK3TifMn+/92uu/h7fcop5ns8Gf/tT0/craIl//W/b1v3dpriGEEEK0oJEjRzJv3jzefPNN/vvf/7J27VoWL17M73//e8C3xiJCBCt/NW7Qnfd0Q4hJk1RAiIpS+3Tpx3NzITq69Vuj9+QgL3I1kdTwV27gCW7y6/l1iNrtMRlIhy7dlXDWLHW9Z892dz9saNFQTo46d2WltSmHaH1S8RJCCCFa0NKlS8nOzmbSpEkcPXqUpKQkbr75Zu7Wq93xrbGIEMEoJ0d9NVdWlgoWffu676usdH9vGO726E6n+t5mc4cO8/f+Fk0Fr3A5P+F/fEgqk/kLDW2S3FSGoQKn7tWQnKz26crLU+H2vvvc19sw3PeL0CAVLyGEkPWGogXFx8ezZMkSvv76a44fP86///1vcnNziY6Odh1js9lwOBwcOXKEEydOsHXrVlJSUgI4aiFaV06OapP+0UfqZ1350rZsqf2c1moPt4Rp9Oc9fqBTozZJroveiyvKVP6w292VrMpK9T3ADz+4r41ntaqu+0XwkuAlhBBCCCFaRXa22hC4rqmCkyap28mTrfeb1z1501IhbDzP8icepQYb1/A8/+WMhp/UAL0n16xZ7vu6d7eGKNl7KzxJ8GpLHIEegBBCCCHaMvN6JW90d745c9z3ZWdbN0u221XVqD42m/U5TXEOe3mMmwG4j7tZx/DmnfDkuFJTVfg0V/EOHbIeJ9Ws8CTBK8BadQ8vIYQQQogAakolJy/PWtGKjoaMDDVVz25Xmwx7MozmVcFOoYjVXEZ7TvAWw7mPuxt+Uj100zvDgF27VPg0V/HS05t1ehEiJHiJwJA1NUIIIUSb462S42364cUXq+pQerqqEIEKWFFRag2UbqvudMK33/p3jDZqeJbr+Bn/YT+ncy0rMZrxkTktDe680/1zVZX7+4gI9Z6GDKn9vIamZYrQI8FLCCGEEEIEjLfph3pj5Px8d4v1b75xh62T2+AB6ucIP36ivYv7GckbnCCGy1hNEZ2bdb78fBUUvampUe/J29TLhqZlitAjwUsIIYQQQgREdjZUVKjgVF4OXbuq+wcOVLfx8e7W6uapg57TCM1BrDmGsd41rXASyyngV00+l3mNmbnKZX5cdzj0NvVSGmyEHwleQgghhBDCbxozRU5PGaypUWFKhywdSI4dq/2c5OSW6WLYi695kauJwOBxJvIUf2jW+Ww2a8t4s7g49Z63b6+7iYY02Ag/EryEEEIIIYTfNGaKnK4KeXYgXL5cnUNPIdTNKZKT1d5W/hbDCV7hcrrwAx/Qj1v5c7PPWVMD1dW177fZ4Phx9d6io2sHVFnbFb4keAkhhBBCCL9pzBS5/v293z9pkjrHnDmquqX3Gz94UAUyf/szt3I+H/A9nbmM1VTQrtHn8Na+3ltlLjLSWuFbuFC9P7tdhS1Z2xW+JHgJIUSwcQR6AEII0XSNmSJXUOD9/iVLVIDbvFkFmpYIW9oEnuKPrKAGG1fzIgc4rUnniYx0V+bqkpxce08yHcB0kw1Z2xW+JHgJIQTIFgdCCOFHDU2XS09XAaRTJ3XrWRlyOlUIMe911RLOpYDlTALgbu5jA5lNPpfuuFifwkL1XnV1q7ISBgxQj9lsKmzJ2q7wJcFLiBB2Lp/zNrdxDl8EeihCCCGEi+d0Oc8gpgPVoUPep+NFRKgQkpbWcmPsxA+sYQztOcHrjOB+7mq5F0NVsQxDBbToaHew0lW/2FgJW+FOgpcQIWwsm7iY3YxlU6CHIoQQQrh4TpfTQWzePFXZiY9X96enu8OVeQpeTY2aZrh9u9o42d9s1LCSazmD//Jvfsp1PNusTZJ9UVoKs2bVnkYoUwvbDgleQoSw37PFciuEEEIEmm4QkZXlruDocKGrW8eOqe+3bVPhyjBUxccsP19VyQ4daoExksMlvM1x2nEZq/mRTs0+p81W/0bO2dmqfX5lpbXKl5Ojrs/ixSqISkfD8CXBS4gQdTqH+SUHADiLrzmNwwEekRBCCOGubi1c6A4Ret2Srm6lp6tb8xREHc40b001dKWsOS5iHfdwLwA38xj/5NzmnxQVpurbyDkvz70OzLNjob5m+fnqNjdXwlc4kuAlRIgaQT7VqHkZNdgYwbsBHpEQQghhrW7pdV46YGVkwNy5sGuXajAxb557CmJeHvTtq85x++1w6qm1z+1tQ+XGOI3/8gLjiMDgEW7hOa5r3gl9lJ6urktUlHrf06d7D53mNW3STj78SPASIkT9jm2u7w2Pn4UQQohAME8zNK9nMlfBcnPd7dP1lDsd0nbuVD8vX+7/KYYxnGA1l9GZInbza6axxC/ntdtVmPTcxysiwh2mPvwQtmyBmBi48041BVNfk9xcdXxpqZp2OXeuel5qat3TDmWT5dAkwUuIEBRPGUMoIBL1f6xIDDL4kA604EYnQgghRAPM3QzNbdE913iBqv7U1TjD13276ltT5WkZU+jHh3xHVy7nFSqJ8f3JdYiKUgEzJ0dNMzRPlRw0SL3/ggLv0wizstzHmqtb+rrp53mrfMkmy6FJgpdofbJfUrNlshs71Zb77FSTiVxbIYQQ/udrhcWzQ5/er2vLFmtXv+xsVfX69tvmjau+NVVmN/IEN/Ek1URwNS9yiOTmvfBJVVWq+yK49+XSCgrc90VF1Z5GmJPjrm5562iYlaWqaRUVta+7dEIMTRK8hAhBI9mOk0jLfU4iGUkL7zQphBCiTWpshWXzZhXU9H5d+fm1ux2mpze84bA//Io9LGMKAHPJZRND/Xp+/d4WLFDvx2azTrF0OtUUQ/M0Qh2Y6tssOSdH7fdVVVX7ussmy6EpKtADEEK4JXGU7vxQ7zE2YBT5Xitev2M7v+IzvOxFafEtnTlMt+YNVgghRJuRlaU+/DdUYTF35wMVQgxDhSz92IIFaq1XQ6FLP7c5OvM9q7mMdlTwd0axkDubdJ6GxpKX566+2WwqFIF6jvm65eSo2/nz1XW48073fd74et1FaJDgJUQQeZFsfsM/GzyuBpvX+xMoZQ8TGnz+Vs4lg0cbOzwhhBBtVE5O/QFBy8pyN4sAVeHRVRldFaqq8u01mxu6Iqjmea7hdL7mK37G9TzT5E2SGxpLaqrq1FhTo9ad6fdqs0H//mqPLsNQ11C3lQf3lMO6+HrdRWiQqYZCBJEn+B3Hia4zWGkRddS06rpfq8HGcaJ5klFNHqMQQghRF/O6pexs61S4nBw15U6LqufX/3Z73Y03fHU393Ex/6Cc9oxhDcWc0rwT1qOgwL1+bfZs655d3ppqmNvK10U6F4YfCV5CBJHnuIR+PMOXJFPt5/88q4ngC3rRj2d4jkv8em4hhBBC0+uPDMMdHHSISE21Nteoi9PZvHbyl/Am96BS3x95nI/p2/ST+cAcoAxDhSvdXt4cIHWFy+lUTTfMwdQzaEnnwvAjwUuIIPMpZ/ArnuFZhgPgY8OmOunnP8Ml/Ipn+JQzmnlGIYQQomHm4LBwofp+925rUwhzpz9/OYP/sJJrAVjGZJ4/+X1L0mu59PvdssU9PbGoqP7uhZpn0JLOheFHgpcQQaic9vyBbK4nmwqia3Uw9JWTSCqI5jru5kbmcpx2fh6pEEII4Z05OJg3StaVnY4d3U04/KUdx1nNZXTiR3YygOks9uv5dRUrOdk6VXLBAtX2XU8fNL8vHZwqKtRxycnqPOnp1nN7Bi3pXBh+JHgJEcSe5VL68Qz/4dRGTz2sJoJ/05NfydRCIYQQDfB1PVFj1h2Zg4Pn+qeyMjh2zD9jdzNYziRS2ctRfsIV/A0n0X59hchIVb06cEBNF9SVrOpq95ouw3BX8tLT1fs3r/nSUyg9Q6cErfAnwUuIIKenHq5hSKOet4Yh/Ipn+EymFgohhGiAr+uJmrruyBwqUlObPs76/JHHuYGnqSaCq1jFNzSzO4cX5j219L5kqanWrod5eZCRoQLZkCHuTZRtNlURSz65d7NnxUuEPwleQoSActpzhK4+Tzl0EslhfiJTC4UQQvjE1/VETV13lJ2tNgO229U6L81mc0/fa47zeY8/cysAs5nPZn7b/JPWYfp09X5yc617loGafqg3Ti4rU2vbcnNVpSs2VgWwAwdUUNu2rcWGKIKUBC8hQoCNGq5kY61Nk+tip5qr2ICt2a05hBBCtAW+TnOr67j6piCmp7vDh55uBypwRUY2f7+uLvyPV7icGCpZw+95kNubd8J6JCer8Zr3KtMVrLQ09d7uu88dUM3vraJCWsO3dRK8hAgBg/iI7hTVur/G49asO0UM5OMWHZcQQojQ5O89orxNQdSvUVcDDZvN982U6xJBNS9yNb04yBf8ght4ChrYC7M5vvnGGroiIuDgQfV9QYEKmTab6mpYWupe22a3W6cpirZJgpcQIWAsm2pNM9QdCxdzldfOh04iGcum1hymEEKIEOHrWq26Aprn/brCk5rqnlK4YIF6DW/sdqjxw6SM+7ibYWykjFjGsIYSEpp/Ug9RUe7pkJ5jNv9cXu4Omfn56troCuGdd0preCHBS4ig522aoe5Y2I9nmME0r50PZbqhEEKIuviyVsu8jskzoJmDm24ykZWl1m/pKYX1VbOiTc0Gm7rGaySvMYf7AbiJJ/iElKadqB5RUer9nHqq98fMDENVwLTcXHcwlY6FAiR4CRH0zNMM69oMua5Nl2W6oRBCCG/qCwK6mrVggfs+z4BmDm7mEFbXei273d1iPTkZjh93P9aUNV4/4yue5ToA/sxUVnF140/ig8REFQx1C3iz6moVvvQar4gImDNHtZjXFi5skWGJECXBS7S+C/oHegQhZSybMICqBjZD9tx0uYoIjJPPF0IIIXylg5TNpsJVdnbdlRrDsIYwvaYpPt56nNMJ776rQskPPzRvmmF7ylnNZZxCMe8yiJk81PST1aOuwKUZBsTEqC6Fc+dC+/awebO6frqKp0Olv9fUidAkwUuIIKanGdqAr05OLWxoM2S96fK/6YkNZLqhEEKIRtH7bPXvX3dVzFzlyslR4WvBApg3T3Xv0xWtuDj3cwzDPSUxwssnUN9ayxs8yi2cw0d8SzfG8rLfN0l2vVIdlTgdKm02dyVQX4/8fHUbFeXeMNr8eF1r6iSYtQ0SvIQIYu2p4N+cyl8ZYZla2BA99fApLuXfnEp7Klp4pEIIIcJFQYH11lso8FwjlpenqlqGodZ26WqZ52bJ06eroOYteEVFNTzt8BYe5Tqeo4pIruQlDuNl8VULO3ZM3UZGqrBpt9d+n7NmWUNrQ2vqmroxtQgtEryECGLltCeNx71OLfTluX8gmzQep5z2LTRCIYQQ4cYzJOjuhHrNl7mZhjlY6DBls6ngkZpau5W8Pt5b4w29v1ddfs1uHuY2AGaxgK1kNP7NNYPdrsJhz57qZ70nWVWVCqlz59Y9NbOh5hpN3ZhahBYJXkIEOaOZ/5k29/lCCCHaFs+QoKf/6VtdnVm4UIUtvW+VDl6Gob687d+lj2+sn3CUV7icaJy8wmUsYkbjT9IAc9t4b5xOtaarqPa2mqSmNq9zoXQ9bBv8+olsz549/jydEEIIIYQIML0HVf/+asphaqr6WQcsUCGr2r3rCQsWeJ9O2JQOhpFU8SJXk8whPuPMFtkk2WZTDT+8jc9mc1e5UlPd1SndpRFg1y5ZoyUa5tfg9fvf/96fpxNCCCGEEAGmm2foxhH5+VBZCQMGWI8zhxYdZDS7vRmvTzYX8g6lxDGGNZQS3/CTGskw6u60GBvrrnLpKl5pKWzf7p5eaLPJGi3RsKiGD7EaO3as1/sNw+CHH35o9oCEECIgZJsDIYRwMa/jysmpHSicTrVZsjdRUao6Zp5q2ND6rbr8jleZjVpcdiNP8im9m3aiBsTHu5tm2GwweLAaf0SEqnLt2OE+NjdXTa3cvl1dm5wc9/WSNVqiPo2ueG3cuJHrr7+eyZMn1/qKM/cMDXLLly/njDPOoF27dvTr14/t27cHekhCCKE4Aj2AlrFt2zZGjhxJUlISNpuNV199tdYxn376KaNGjSIhIYH4+HgGDBjAgQMHXI9XVFQwdepUunbtSlxcHKNGjeKQx0Y7RUVFjB8/noSEBBISEhg/fjw//vij5ZgDBw4wcuRI4uLi6Nq1K7feeiuVlZUt8baFCDq+tC737LJnnl4XFaUqWHVNG6yq8r6+CxpX+foFX/AM16vxMI2XudL3JzfSsWPqfYF1fVpEhGqc4VkNy8+3XkdfNqSWaYii0cErIyODDh06MGTIEMtXRkYGqZ69NIPUSy+9xLRp05gzZw4FBQWkp6czfPhwy//chRBC+FdZWRnnnHMOy5Yt8/r4v//9b9LS0vjlL3/Jli1b+Oc//0l2djbt2rk7ek6bNo21a9eyatUq8vPzKS0tZcSIEVSbFpeMGzeOvXv3sm7dOtatW8fevXsZP3686/Hq6mouvfRSysrKyM/PZ9WqVaxevZoZM/y/WF+IYORL63LPLns6WGzfrjoWRkerqYZRjZw7pStfDTXYiDXKWM1lJFDCdtK4gwca90KNZLPVnjoJat2a+eOt3sMrPd33FvDSKl5oPgevzz//HIA1a9YwZMgQr8esW7fOP6NqYYsXL+bGG2/kpptu4qyzzmLJkiUkJyfzyCOPBHpoQggRtoYPH05ubi5jxozx+vicOXO45JJLeOCBB0hNTeWnP/0pl156Kd26dQOguLiYJ598kkWLFjF06FBSU1NZuXIlH3/8MRs3bgRUxWzdunU88cQTDBw4kIEDB7JixQreeOMN1//H1q9fz759+5gyZQqpqakMHTqURYsWsWLFCkpKSlrnYggRQL60Lves4JirNrq9/K5dqstfY8THq5BTb5MNw2CZ80/0YR9HSGQsL1NFMxaJ+aCuLoyGod6nphtwDBmiNoq22xueXiit4oXmc/Dq27cvl1xyCevXr2/J8bS4yspK9uzZQ2ZmpuX+zMxMdpgn8JpUVFRQUlJi+RJCCEGtfxsrKpq2WXdNTQ1vvvkm//d//8dFF11Et27d6N+/v2U64p49e3A6nZZ/v5OSkkhJSXH9+71z504SEhLo39+9Zm/AgAEkJCRYjunYsSPjxo3jF7/4Bffffz99+vShoqJCuvOKNqEprcvNLeT1HlxVVdCpU+Ne+9ixhjsbnvHmm1xVvYoqIhnLyxTSo3Ev4kfJydbqXEWFCp/m69DQdZRW8ULzuUC8f/9+Hn/8cW644QY6duzIbbfdxnXXXUdsbGxLjs/v/ve//1FdXU337t0t93fv3p3CwkKvz5k/fz733ntvawxPCCH87kluwI5//612Ug68Q3JysuX+e+65B4fD0ejzHT16lNLSUhYsWEBubi4LFy5k3bp1jBkzhs2bNzNkyBAKCwuJjo6mk8cnPfO/34WFha4KmVm3bt0sx/Tv358XX3yRlStX8vTTT3PPPfdgs9n4+9//TlpaGvbmtGATIgzpzZA9Nz72WGLZbP2rd5Ly1FMA3M6D5JPu3xdopG++gbvuUsGzslJNlczLs4ZPIXzlc8UrKSkJh8PB119/zb333suqVavo2bMnd9xxB19//XVLjrFF2DwmFxuGUes+bfbs2RQXF7u+Dh482BpDFEKIoHfw4EHLv4+zZ89u0nlqTq5c/93vfkdWVhbnnnsus2bNYsSIETz66KP1Ptfz329v/5Z7O6ZLly7cdtttFBQU8N5772Gz2Vi+fDlJSUlkZWXx5ZdfNum9CBGOCgrUred/Xk3ZDLku3fiW5yuvJqK6mlciL2cJ05p9zsb8DsXbe6mpcVes9H5m06e717Y1do2baNt8Dl7Hjx/n8OHDfP755yQlJTF9+nRuuukmHnnkEX7xi1+05Bj9qmvXrkRGRtaqbh09erRWFUyLiYmhY8eOli/RTNK6W4iw4PlvY0xjF3yc1LVrV6Kioujd29oq+qyzznI1PkpMTKSyspIivaHOSeZ/vxMTE/n2229rnf+7776zHGP+f8CRI0f4+9//Tk1NDZGRkVxyySV88skn9O7dmzxZDS8E4F6npDdF1rennqrCTXMDWCRVvMSVJHGYYz17Msn+GP7YJNnXNvbmdWfmjZ/TTQU3vZ/Z4sWqXX5cnGo0IoSvfA5ecXFx9O7dm9GjR3PrrbeyePFiPvvsM373u99x0003teQY/So6Opp+/fqxYcMGy/0bNmxg0KBBrT6e4b9Z0+qvKYQQwSY6Oprzzz/f1QBD++KLLzjttNMA6NevH3a73fLv95EjR9i3b5/r3++BAwdSXFzMe++95zpm9+7dFBcXW475+OOPeeKJJxgxYgSnnXYazz33HFFRUXz11Vc888wzrF+/nueee477ZFGGaMPS01UgMYePAQOsAezQIRVuoqLUZsJNNZ/ZZLCVY3TgvVmzKLX5f5Pk+pjXnenv09JUEw1zK3i91q2gQNZticbzuUB6xRVXsH79ei6++GJuu+02fv7zn7fkuFrU9OnTGT9+POeddx4DBw7k8ccf58CBA9xyyy2BHlrLchC2+wMJIYJfaWkpX331levn/fv3s3fvXjp37kyvXr24/fbbufLKK/nNb37DBRdcwLp163j99dfZsmULAAkJCdx4443MmDGDLl260LlzZ2bOnEmfPn0YOnQooCpkF198MRMnTuSxxx4D4I9//CMjRozgzDPPBFQzpYiICP70pz/x+9//nqVLl5Kbm8stt9zCqaee6hrfRRddxCmnnNI6F0eIIKS7/OXnq6BRVqY2Tdat5D03SM7NbdrrjGE1t/MQADdHr+DKnu2bOfLmiYxUa7cKCtzvOy9PVbz0WrcQ2UFJBBmfK14vvfQSH3/8MXFxcQwYMIBRo0axefPmlhxbi7nyyitZsmQJ9913H+eeey7btm3jrbfecv1WVQghhP998MEHpKamuvZ8nD59Oqmpqdx9990A/P73v+fRRx/lgQceoE+fPjzxxBOsXr2atLQ01zny8vIYPXo0Y8eOZfDgwcTGxvL6668TGRnpOub555+nT58+ZGZmkpmZSd++fXnuuedcj0dGRvLQQw8xdOhQ3njjDe666y5Gjx7NQw89ZBlvp06d2L9/f0teEiFaVWM28s3Otk4fLC9XUwqrqlQQqWuD5MY6k894ihsAeIgZvBp5mX9O7CPzGjC7Xb3vWbPca7k8W8HrtW56A2UhGsNmGA019aytvLycZ555hocffpiYmBimTZvGDTfc0BLjC0olJSUkJCQwtPg57B2b3yns7W3e97RpEY7We6kGbd4d6BEIoQTbmkMHUFYClyRQXFzc5HWl/v63ysxZUs7GhPHNGp/wL/3n3dQ/E6fTyVtvvcUll1wiXR2bKNivYYcOKjTFxalpct5kZ1s7+JnVt/9WRIRqRKFvfRFHKe/xa3rzKVsYwlA2Et3e4MUX3+Lqqy/h+PHWvYZ2u6rmZWWp6pY32dnuyl591zGQgv3vYSho7DX09d9fn6caPvzwwxw7dozS0lLX7S9/+UveeecdbrrppjYVvIQQQgghQk1WlgpV9W3kq9cwgQoi/fur6YWGUXfrdJsN5sxRxyxY4GvwMniCm+jNpxymB1eximqiAB+7YTRTWpqqXqWmwrvvqrE7nepr4cK6g5e+v6HrKIQ3Pk81XLVqFe+++y4HDhzAMAx69uzJ4MGDWbx4MS+//HJLjlEIIYQQQjSRnmII3htCmKcgZmW574+Ohu3bVfhqaL+qzZtVJcjXfa1u42Gu4iWcRHEFf+NbEn1/Q36QkaGuRUZG7Sqe0+meRuhteqZsiCyayueK186dO1tyHEIIISC4pgMLIUKOniponi6nq1h6d4T6HtdNI2w2d0XHcz1XRIT60iHLMBq35msw+TzI7QDMYBE7GNyEd9o8ulmGeccI8zRJ8+Pm5hqat+ssREN8rngJ4XfBtq5GCCGECHGeIQusDSIaelwHKMPwvp4rOxuqq5u+f1V3CnmZsdip4gWuZilTm3aiZiorU0ErNVW9d/2+5s61NtPQQdSzi6G36yhEQyR4CSGEEEKECc8ufGCdGlff44Zh7WSYl2ftbpie7p5e15TAEYXz5CbJR9jH2UxkBf7YJLmpdKWustIdMs2bJGdnu7sY7t5tnXLo7ToK0RAJXkIIIYQQYaKh9Uf1PZ6XZ61y6QqZvm/7dveGyp06NX5s85nNELZRQjxjWEM5cY0/SQvQDTU0czVLByzDsFa4ZJ2XaAoJXkKItk2mvAohwkxj9+vq0AGSk1WwsNnUl92uwoa52YaWnw+HDjVuTJfzN2ayCIDreYYv+b/GncDPoqKse3iZA6e5mqUDlnlvLyGaSoKXEEIIIUQYacz6I32sDlJ6bZfT6W4oYdrDvEl+yaf8lT8AsJA7eJXfN++EjaSDJKh1XXFxMGCA9bEBA9xh1Vs1Sypcwh8keLU1jkAPQAghhBAtyZf1R7rSpacMxsfXPqZzZxVKGtOx0FMHjrGGMcRTyjtcwBzmNf1kTWQYqiV+XJzabywrS70np1M9Fh2t1nJJswzR0iR4BYHhv1kT6CEIIYQQIkz4Up1ZuNBa6Tp2DHr2tDbXOHjQ9325vFObJJ/FZxziVNMmya2voMDdNMO8nisqSgXUuroXCuFPErxEYMn6GiFEG/DNN99w7bXX0qVLF2JjYzn33HPZs2eP63HDMHA4HCQlJdG+fXsyMjL45JNPAjhiEe68tYo/dAhiY/33GtNYwpW8TCV2ruBvfEc3/53cR/HxtVvpO52qkpedrb6/7z5398Jdu3xfHydEY0nwEkKIYOEI9ABESygqKmLw4MHY7Xbefvtt/vWvf7Fo0SJOOeUU1zEPPPAAixcvZtmyZbz//vskJiYybNgwjh07FriBi7DhrdmGt324kpPrrvikp6v1Ub5KZ5trk+Qs8tjFwEaM2H+OHXNXuszvLTraWhHU0zNtNplyKFqOBC8hRNslFVfRChYuXEhycjJPPfUUv/71rzn99NO58MIL+dnPfgaoateSJUuYM2cOY8aMISUlhWeeeYby8nJeeOGFAI9ehDIduPS0wgULrAHMbldT7fT0wkOH3Ou5dMiKiFCbCm/b5r1K5k0PDvMyY4mimpVcw3Im+feNNUJysrvSVVBg3SDZHEj1/l2Goa6LdC8ULUGClxBCCNGCXnvtNc477zyuuOIKunXrRmpqKitWrHA9vn//fgoLC8nMzHTdFxMTw5AhQ9ixY0cghizChA4chlG7mpOXp6bZxcSo8AXWYFVT477NzVUBzJfgFYWTlxlLIt/yMSnczGMEcpPkwkKoqFBhKjVVhdDychVC581zB1JQ16SqqnY1TAh/CcwKRyGEEKKN+M9//sMjjzzC9OnTueuuu3jvvfe49dZbiYmJ4brrrqOwsBCA7t27W57XvXt3vv766zrPW1FRQUVFhevnkpISAJxOJ06ns9Hj1M9pynOFEmzXcMYMWL4cJk9W3fxyc90/b98OO3eq49LT4aOPoG9ftcbJ18qWNw9UziCt+l2K6ci4mJcwIqJpj+/Xo317p+XWVxER7rAIMHAg7N7tvi8uDj77TIVMHTT1bUSECqH9+6tr0r+/+jlUBdvfw1DU2Gvo63E2w2jOf15tU0lJCQkJCQwtfg57R/+sQn172xi/nMcnjtZ7KZ9t3h3oEYi2KNimGjpM35eVwCUJFBcX07FjxyadriX+rdKcJeVsTBjfrPG1FdHR0Zx33nmW6tWtt97K+++/z86dO9mxYweDBw/m8OHD9OjRw3XMxIkTOXjwIOvWrfN6XofDwb333lvr/hdeeIFYf3ZIEMJHp27fznmL1CbJu2fPprB/kP0bK0QLKS8vZ9y4cQ3+P1EqXm2Rg+AMX0IIEYZ69OhB7969LfedddZZrF69GoDExEQACgsLLcHr6NGjtapgZrNnz2a6aSFKSUkJycnJZGZmNikMO51ONmzYwLBhw7Dr3WZFo7TWNUxKUlPk4uLg8OHa92v68dxcePBB932VlbUrOlFRzWsdf1bNJ2yrGAfAg1G3c8+S2r8U8EX79k7++tcN/OEPwzh+vHHXcOBAWLcOunRp+L3otW2GodZzeVYE58xp0vCDgvy33HyNvYZ6xkFDJHgJIdqmYKt2ibA1ePBgPv/8c8t9X3zxBaeddhoAZ5xxBomJiWzYsIHUk23XKisr2bp1KwvNGw55iImJISYmptb9dru9WR+2mvt80fLX8JZb1HqkP/1JrV3yvD81VTWS+OUv1QbJ5qA1cybMn187mOgQ0hTxlPACVxJHORu5kFlV86mpimzayU46ftze6OC1e7dam6Wbgdrt6r2np6umIebpiHa7uiZxceBwqPvuvVd9hQv5b7n5fL2Gvl5naa4RJGQTZSGECE9ZWVns2rWL+++/n6+++ooXXniBxx9/nMmTJwNgs9mYNm0a999/P2vXrmXfvn1MmDCB2NhYxo0bF+DRi2DkbYPk9HRVsUlNVeu3SktV+DI310hLU23VTxZZARW47PbmrOsyeIobOJMvOEhPruZFamhe6Goq3TRD0zMdt29X7++uu9zXQXcvTE2VfbtE65HgJYQQwcAR6AGIlnL++eezdu1aXnzxRVJSUsjJyWHJkiVcc801rmPuuOMOpk2bxqRJkzjvvPP45ptvWL9+PfHx8QEcuQhG3vbkAncbeH2bna2qPVFRMGCA6uyXn6+C2KFD6pi4OFUBqqys/To9e7q/t9XTlHAmD3EZa6jEzuW8wv/4SdPfXDMZhrWSt2OH9VrpwFpQ4O5eqMOp7NslWoMELxEcZNqXECKMjRgxgo8//pgTJ07w6aefMnHiRMvjNpsNh8PBkSNHOHHiBFu3biUlJSVAoxXBTLeI9wwKaWnqNj3dfZxuF79rl/c1T3qJoLdqz6FDas+r+trIZ7CZBaidmG/lz7xHcP2/vKbGfa3MgVVvljx9uvV7IVqarPESQgghhAgRWVkqSHgGhe3b6z7OPP0uPl6tgbLZYPNmFUa8Vbw0c4t2syS+YRVXEUkNz3Adj3Fz095QC0hLU5UsvdZt+nQ1xVKHsNJSVf3SzN8L0ZKk4tVWOQI9ACECSCqsQogQ5W19V33Hbd5s7WCoG08YhnvqoX7csz9Abq73c9up5G9cQXeOspdz+BOP0JqbJEdFuadC9uzpngpps6mKll7jpm/vu6/uylZdUzeFaAkSvIQQQgghwpRe86XVt2zQ1/12FzGDQezkRxK4jNUcp3X3jZs1y71OragI9LZ1sbHWQOotVHlOm1y4UIXPehqICuE3ErxE8JAqhBBCiDYuO1tVnqKj/VOFMTfGyM52V7y88aWXyzieZyrLALiWlfyHnzVzhI1nDkmpqdZqljlsLVigQtWCBXWvjdNBrOldHYXwnQQvIYQINEegByCECBZ5eaoRhtPZuE57ntUd/fPgwdZW8nVJTq4/lAGczT4e548A5DCXNxnh+wD9yFyZe/ddNSWyvFyFJ3PA0uvTamrc4cyzffysWer+2bNb/32ItkeCVxCRvbyEaAVSWRVCBLGsLLWGyW5vXKc9HTgWLlTBYt489XN+vgobej1XXa3hDx6s//wdKWYtvyeOcv5BJo4A/MbI29jNFau8PGv1K+Lkp9yICGsreXPly9c1c0L4gwQvIYQQQoggkZOjKjqVlY0LA6mp6raqyr1psmZe5xXVhH7WNmp4huv5BV/xNb24hucDskmyt+mA5sYa06dbg5RnNSs7G44fV9/r6yVEa5Lg1ZY5Aj0AL6QaIYQQQjRaQYG69QxWdrs7nEREuPfzqm9TZE938ACj+TsVRHM5r/A9XZs/YA+6o2JjxqUZBsyZo6ZSpqe7pxJ6VrPM0w/19RKiNUnwEkK0HRLshRBhSk+xmzXLGl7uvFOFkrg462bIvjaT+C2bmMccAKawjA843y/j9WzkYRhqjDNn1j7WZnOvUzMHSf08u93dnVBPqfS2Pi4rSx0bFVW7EYcQrUGClxBCBJIj0AMQQoQDc3Vnzhz3/ebNkwcMsD4nooFPgT056Nok+a/cwBPc5Lfxejby0FMkH3qo9rFRUSo0FRSoaZhRUdbKXlWVO7ilpXnfrwvUNaqsVOe47766Ox0K0VIkeIngI1UJIYQQoslycqxT93TAyM+3Vov0tDtvoqngb1zBT/gfH5LKZP5Ca2yS7K0S53SqAFlRod6XYaiwpZuQREWpdVyemyY3pK5NlYVoKRK8hBBCCCFCgK9T47KzVTjRIcvcSMKzWuSN3Q6Lmc4AdvMDnbiM1ZygffMG30w2m7uyZbO5w5auYOkph43Z/0w6GorWJsEryLR6S3lH676cEAEjlVQhRIjzdWrcwoXukOJ0wu7d7urQrFkQE1P/8690PsdkllODjWt4nv9yhv/eRBNERam1anFxKnQ5neo9GIY7iJr3PzNvsCxEMJHgJYQQQggRAsxT4+qrfunperopRVWV+2vxYujUqe7X6MNHPMbNANzH3axjeAu8k4bFxalNncG9Nq2yUr0HvceZOYiaq3qGIY0zRHCS4CWCk1QnRFvgCPQAhBChxDw1Tnfxu//+2gFD7181d646Xk85NAz1nEOH3McmJ7sfT+BH1jCGWI7zNhdzH3fXGoNeO+ZPdrs7ZA0apG4PH4YfflDfFxSo96unFEZHq2tgDqLm9vA2m1oTJo0zRLCR4CWECH8S5IUQIciXqlZNTd0BY/Nm9XzPJhrm8HTw4Ml1U9TwLNfxc/7Nfk7nGp7H8PIx0elsxhvyIiJCTSP84QfVkfCf/3Q/Zg5W5qYburplDqL62KgoNUZd7ZPGGSKYSPASQgghhAhC9a3p0lUtb+3TzV0My8qsz4uP9x6eZrGAUbzOCWK4nFcoorN/30wdamogN7f2eHNzrcFq1iz3c7xtfqyP1ddl1ixpnCGCjwSvICQNNk6SKoUQQog2rL41XTpoZGSon3VFKD1dhRebzR3KzC3kPffPAhjKBnKZC8Bk/sKH9Gu5N1UPPd0QYPlydavfN6ipkw1VsaRToQhmDTQUFUKIECcBXggRonJy1BeodU26Y5++D9xrn3Jz1c/5+erWMFRlKCsLtmxx32+WnQ1P5xzgRa4mAoMV3MRfubFF35PWsycUFVkrcgcPws9/rr4/ftzdrVBX/UpLre9diFAjFS8hhAgER6AHIIQIBbriU1WlfvbcYFjfDyqcpKWp7202FVhyc72HLoCFORW8wuV05Xs+oB9TWer/N1CHQ4dUkNLj1b75Rt3W1Kj3I5sci3AiwUsEN6lWCCGEaMN0dz5QAWTAAOuUw8hI97HTp8P27SqczZnT8Lkf5jZ+zft8T2cu5xUqaOf/N1CH+Hj1PjIy1Hj1NELztMjp02XqoAgvEryE4gj0AIRoARLchRAhztwKPjXV3YBCN9zQzSSys60bCufkqHBTl+t5mlt4zLVJ8tec3qLvI8LjE+exY9b3oQPWzJnq5zvukLAlwo8ELxH85MOzEEKINurOO93fm6cM6ql35oqQXg+Vm6vCl7mRhrmSdC4FPMKfAHDg4B9c7Ncxe04fBBUKzV0Ye/ZU95s3PgZV+QLfKnZChBoJXkGq1TsbCiFajyPQAxBCBJP69uvKyXFPwzPLzVXTDO121cmwQwdriKlr4+BTKGI1l9GeE7zJJa5uhv60e3ft+6KirF0YCwvVbX6+e/zZ2e4mITo81nVd6ntMiGAlwUsIEZ6kUiqECBH17dcF7qqWuWplGKoBRVWVe/rhrl0q4EDt/buiotQmySu5lp+yn/9wBncmrfS6SXJzVVVZxwrQv78KSnrNmvlx8/RJ3UZ++fL6r0tD10yIYCTBS4QG+RAthBAiTNXXuc9c2YmqYxMgvZarutra5RDc0/sMA+aSy6W8xXHacRmr+eRwp0aN07PqVpeoqNrdF999VwWlmhr3Bse6kmfeBHrSJHX85Mn1XxfpdihCkQSvZriRpwI9BP9yBHoAQviJBPWgtG3bNkaOHElSUhI2m41XX33V9ZjT6eTOO++kT58+xMXFkZSUxHXXXcfhw4ct56ioqGDq1Kl07dqVuLg4Ro0axaFDhyzHFBUVMX78eBISEkhISGD8+PH8+OOPlmMOHDjAyJEjiYuLo2vXrtx6661UVla21FsXol6enfvS01VFKDlZTbkrK1OVojvvtAYVHcT0Wi4ddnQQs9lUQNm1Cy6sWofj5P/o/8Qj7MVjcZUPfA053bvXDml6bBER7veq3/f27erWMNwVL8Nwt5P31mRDuh2KUCTBSwghWpMj0AMInLKyMs455xyWLVtW67Hy8nI+/PBDsrOz+fDDD1mzZg1ffPEFo0aNshw3bdo01q5dy6pVq8jPz6e0tJQRI0ZQXV3tOmbcuHHs3buXdevWsW7dOvbu3cv48eNdj1dXV3PppZdSVlZGfn4+q1atYvXq1cyYMaPl3rwQjaCbaJh/p2Cz1Q4qAwZ4f/7x4+rWMFRwO7XqvzzPNURg8Cg38wwTGj2mtDTfQ44et7nJRny8CmOzZ9f9PD19EFQAk6mEItzUUbQWwWD4b9bw9rYxgR5G8LigP2z2smJXCBEShg8fzvDhw70+lpCQwIYNGyz3LV26lF//+tccOHCAXr16UVxczJNPPslzzz3H0KFDAVi5ciXJycls3LiRiy66iE8//ZR169axa9cu+vdXlc8VK1YwcOBAPv/8c84880zWr1/Pv/71Lw4ePEhSUhIAixYtYsKECcybN4+OHTu24FUQomFpaSp8JSfDkSMqdM2aVfu4ggLvzzdPN4zhBK9wOV34gfc4n9t42OtzbLba0wPN8vMb18iirMzahfHYsfrPD6q69eij6vtJk2DRIplKKMKLVLyElSPQAxCimWSaYasqKSmxfFVUVPjt3MXFxdhsNk455RQA9uzZg9PpJDMz03VMUlISKSkp7NixA4CdO3eSkJDgCl0AAwYMICEhwXJMSkqKK3QBXHTRRVRUVLBnzx6/jV+Iptq+Xa1/+uEHFbgqK1VosdutnQwrKmrvj+VpKVM5jz38jy5czitUEuP1uIZCEajqk93ehDeEGq9ZQ10J585t3lRC6XoogpFUvERokaqXEI228d1REOfnKk5ZCQDJycmWu++55x4cDkezT3/ixAlmzZrFuHHjXBWowsJCoqOj6dTJ2hCge/fuFJ7sTV1YWEi3bt1qna9bt26WY7p37255vFOnTkRHR7uOESLQzF37cnLUra5k1dS4q0lRUXDXXe427GY38Fcm8gQ12LiaFzlIr2aNafp02LzZWsnyJj0dhgxxjykuDrZtq//96ftqapo1xHrPL0SgScWrmW7hsUAPQQihBXu1yxHoAfjfwYMHKS4udn3Nrm8Bh4+cTidXXXUVNTU1LNcr7ethGAY2U29qm2cf6yYeI0QgeXbty8ryfpxe+zXXYzuuX7GH5agWgXPJZSPDmj2m3FzvoUs38wBryNLVOPP+YroSlZpauyuhfs/+IF0PRTCS4CVCT7B/uBaiDenYsaPlKybG+zQmXzmdTsaOHcv+/fvZsGGDZb1VYmIilZWVFBUVWZ5z9OhRVwUrMTGRb7/9ttZ5v/vuO8sxnpWtoqIinE5nrUqYEIHi2bXPvJGyua28Yagwk5PjngbYme95hctpRwWvMZIFeFkgdlJDUxXNPKcjZme79xPTUlPd+3Xp+9991/24rkQVFNSeSpiTAx6NTJtMuh6KYCTBK8gN/82a1n9RR+u/pBDNJoE85OnQ9eWXX7Jx40a6dOliebxfv37Y7XZLE44jR46wb98+Bg0aBMDAgQMpLi7mvffecx2ze/duiouLLcfs27ePI0eOuI5Zv349MTEx9OvXryXfoghD/lpL5Mt5cnJUJcdmU+HLblfTDxcsUPc5nRBBNSu5ljP4L1/xM67j2Xo3SfZlbReoRh+e5s1T0wrLy9XPNhvs3l17g2Tza0glSrRlErxEaJIP2UKEnNLSUvbu3cvevXsB2L9/P3v37uXAgQNUVVVx+eWX88EHH/D8889TXV1NYWEhhYWFrv21EhISuPHGG5kxYwabNm2ioKCAa6+9lj59+ri6HJ511llcfPHFTJw4kV27drFr1y4mTpzIiBEjOPPMMwHIzMykd+/ejB8/noKCAjZt2sTMmTOZOHGidDQUjWZeS+SLugKW+Tz1hbC8PBWwYmLc+3qZK07Z5DCcdZTTnstYTTGnWJ7vWeEyh6KoKOu0QbODB2vfp9ea6XMYhvrSFbmePdWtzeZ+L1KJEm2ZBC8hROgLhSDuCPQAAu+DDz4gNTWV1JMLPqZPn05qaip33303hw4d4rXXXuPQoUOce+659OjRw/WluxEC5OXlMXr0aMaOHcvgwYOJjY3l9ddfJzIy0nXM888/T58+fcjMzCQzM5O+ffvy3HPPuR6PjIzkzTffpF27dgwePJixY8cyevRoHnrooda7GCJsNLaC4y2oZWerDoV2uzrPggXuTZP14x06WDsZVlTAli3qcR18hvMWDu4FYHanx/iIc2q9vrfmFXqKYnW1ezPmxoqIUAFLfzmd7v289GbIQrR10tXQD27hMR7l5kAPw78cyAdFIYRfZWRkYNQzr6m+x7R27dqxdOlSli5dWucxnTt3ZuXKlfWep1evXrzxxhsNvp4QDcnJcXfNczobPj4rS4WQ6dNVoMrLUyGqqkoFuPvucwcuPV1PhzVzYwtzZ0ObDc7gPzzPNQAs50/8uWg8vtLjNoyG9/Pyxm5X1Tc9Tm89amRqoRBS8QoJAVnnFQpCocohWp78PRBChBDzVDtzUDFXzfQ2dPpWV9X01D3PvbRijOOs5jI68SO76E8W7vKSL2vP9HkjIlQDj7lz1XRBX5t8Op3qvehxRnn8Wj87W6YWCgESvIQQouU5Aj0AIURrSkryLfDooDJrlgpjhqGmFO4+uV1lQYH72IoK99Q9c2UtbbDBciaRyl6+oytX8DfXJslpaSrw6GAF7pCn70tLgwkT1H133eWuuFVVWStfeiqh3a6eY7ergJWWVnuqZf/+7scldAnhJlMNRWiTDZXbNql2CSGCkK8b9+ppinoNV2WlClVRUdYwo4OQJ5sNUnau4AaeppoIrmIVh3C3H9TBzbwDw6mnqgB3/Lj6efdu95TFvDy1bszba+m1YdXVsGuXCoue769DB3er+JM9cYQQJlLxEnVzBHoAQgghRPDTwSk3V/3sa7MN/TzdTMMw1HNnz7Z2/jNP+TNXm5b/4X2W1EwFYK5tHtuiLrSc//hxdWynTurn5GR31aymRj1mrmqlpnrfINmspkYFM2/NMupqNNJQq3x/teQXIthJ8PKTW3isRc8v67zqIVWPtilU/twdgR6AEKKl6bVay5ernw8frj29zlu48FzjpQOXnnKoj9Vt47OzVYXK6YSEqv8xeuXlxFDJq4xmoXFnrUqVDkk6bHm2hI+OVpUrfW5TA9F62WzucJWern7WjUW9tYpvqOV+Y1vyCxGqJHiJ8BAqH8KFEEKEHV3pmTy57mO8hQvPNV46sHgea27IYRhqk+QXGEdixQG+5Odcz9MYeO+EYbN53/wYVHjSmzIvXmxtNT93bu09v7SoKDUOu91dIaupqd0iX7fA1xssn9xJohbZVFm0FRK8RP0cgR6AEF5I0BZCBBEdjObMqfuYrCwVWCorG95M2BxEzJWy7GwVcBw4yGQDZcQyhjWUkFDn68bGuitenjZvVueeN08FPS09XYUob3t+gXtfLnOFLSLCGpzMLfD1dEZzsxAz2VRZtBUSvET4kA/jItg4Aj0AIUSwyMmBmBg1TXDBAnc1yNvaJm8t53NzYeFCuKTmdbJRi8kmsoJ99HE9Lzvb2mo+KkpVmeralys/3722DNx7eG3bpsJfXWbPdlevIiLU6951l6qa6feiw2NamhqH3hxaiLYsrILX6aefjs1ms3zNmjXLcsyBAwcYOXIkcXFxdO3alVtvvZXKEGm9I+u8hEACthAiZOkwYrO5q0ENrW0yB6Bezn/zHGpj5D8zlRcZZzl2wQLo3t39c1WV6kDoSTfrMLeZBxW6dBgEFZo0Pe1Qt6jX1av27a0B0XN65PbtKmxWVrZcRUuac4hQEVbBC+C+++7jyJEjrq+5c+e6HquurubSSy+lrKyM/Px8Vq1axerVq5kxY4ZfXrulG2wEjCPQA2gE+VAuhBAiSOkwoptleNsDS9PVq4UL1XFdY8tZzWWcQjG7Igbyw+yHiIuzrsNyOmtPKzRPF9T7cOkNjg8dqh2+zGHQPDVQv46+z3Ndlrd1Wq0ViKQ5hwgVYRe84uPjSUxMdH110L+2AdavX8+//vUvVq5cSWpqKkOHDmXRokWsWLGCkpKSAI5aCOGTUArWjkAPQAgRjLKzVUDIyoKMDHWft6mAeg2V0wkFHxp8d/mfOId/cpRubJ/6Nx76czRlZSoQ2e3uUOXZEMMcvAxDbW58553u+zyDmu6wOH26O0xlZ7u7H+pg5bkuy9s6rdYKRNKcQ4SKsAteCxcupEuXLpx77rnMmzfPMo1w586dpKSkkJSU5LrvoosuoqKigj179tR5zoqKCkpKSixfIoiF0odz4Tv5cxVChAEdRhYsUOu29PegAk50tApQqanutVGOHo/Bs89SbYuk2+aXuH3Jqa6wMXu2ClK60+CgQe6qls1Lo0PdhVA/lp5urXpFRakgc9991jDVlAYYrRWIpDmHCBVhFbxuu+02Vq1axebNm5kyZQpLlixh0qRJrscLCwvpbp78DHTq1Ino6GgKCwvrPO/8+fNJSEhwfSXX1Ze1FQRsnZcjMC/bZPIhXQghRBDSYcRzCmB2tgpiTqeqdBUUqO+XXrubW/99KwDZ9gWQkUF6ujq2vFx1JvR8XmWlqlDpSprd7l6vZbOpLoaGoULWtm1QVOQei9PpvS287qrYmKmDEoiEsAr64OVwOGo1zPD8+uCDDwDIyspiyJAh9O3bl5tuuolHH32UJ598ku+//951PpuXX/8YhuH1fm327NkUFxe7vg567kBoErbrvIQIpFAL0o5AD0AIESw8w4oOI+YpgbNmWcOOzaYqXqfHfcclT11ONE5e4TK2nz+DDh3cVSvDcH+v6eqS+XyzZqkmF3Fx6jnmLobg7lDYs6cKaRUV7vGapwvKWiohmifog9eUKVP49NNP6/1KSUnx+twBAwYA8NVXXwGQmJhYq7JVVFSE0+msVQkzi4mJoWPHjpYvEQJC7cO6EEKIsKPDysKF7mmE5jVT2dmqImTuXhgbC+/trGZF+TiSOcQXtjP5/I6/UrDXRlmZ9ymE+ry6umRen2W+z6x/f/W4Dm9FRWqMVVXucKX3Hysvh+PH1feylkqIpokK9AAa0rVrV7p27dqk5xacbL3To0cPAAYOHMi8efM4cuSI677169cTExNDv379/DPgVjD8N2t4e9uY1n9hB6H3m/wL+sPm3YEehWgOCdBCiBCVna2qR3a7qjLpDYfz8lTVKyfHfaz+Pi9PBZvYeXczjI2UEsf/fbyaOWd35NEXVIg79VR1rG6MYQ5X5vOZz+9NQYG1c+H06e7Nkc1NNHR4NAx3+3ghROMFfcXLVzt37iQvL4+9e/eyf/9+Xn75ZW6++WZGjRpFr169AMjMzKR3796MHz+egoICNm3axMyZM5k4caJUsYQIRqEYuhyBHoAQIljozoTR0arCpZteeKsY6XVbqalw5md/Z1bN/QBMtD2J/dyzyc52B61Dh6zdCBsKQnq6o27ioZWXq9fTre0XL1b3e67L0lUv2QRZiOYJm+AVExPDSy+9REZGBr179+buu+9m4sSJvPjii65jIiMjefPNN2nXrh2DBw9m7NixjB49moceesivYwnrdV6OQA+gCULxw7sQQoiQZ+7ql5Ojug/GxHhvH6+n+xXmf8mIv10HwBJuY5VxJVVVKpTp7oPp6RAfr76Pj2+46cXChapipStueqqiYaiKV2mputXrt7ytS2vpTZCFaAvCJnj96le/YteuXfz4448cP36czz77DIfDQWxsrOW4Xr168cYbb1BeXs7333/P0qVLiYmJCdCoRauR8BV6QvHPzBHoAQghgolnVz9vzSl0yOnZE2IpY13sZSRQwo6Iwbw66EFLE45Dh2DuXNWJUHdFPH7c3ZZen9czOHkGvaio2hUsc0iUJhpCtIywCV5tTcDaygvRGkIxdAkhxElJSd6rT+Zwo8PRvHkq5BQeMSi79hZ+Vv4x39q6kz/1Zba8a6d9e+s5zE0v4uKsjTbMHQ3NwWnWLPdxNptqqhEToypw3jZAlg2JhWgZErxE4zkCPYAmkg/zoUH+nIQQIa6uapE53OjApatRN9csh5UrqSKSK4yXmfXnJDp0sK7BMochfa477/TevdDzWD0BKDbWOq3QG9l/S4iWIcGrhYT1Oq9QJh/qRUtxBHoAQohg4Uu1yDz9bwA7WWyoXu93RSxkO7/BMFQ40muwtm9Xt4Zh3dA4L08FLXNI8hacdBhLTVVrtVq7LXxjN18WIhxJ8AphAZ1u6AjcSzebhK/gJX82QogwcPhww9WitDR1e27SUV6xXUE0Trj8cmJmT3dVuKKi1Bouu1011NCdCT03NM7NbTjQ6DBWUKAaZcTEtG5FS9aNCSHBSwgRLEI5dDkCPQAhRKjZvh0MZxUFZ17FqcY38Mtfwl//6lqMlZGhvq2pUd0I8/PdnQl1tcq8IbIOXw1VlsyVr9asQMm6MSEkeIm2KpQ/5Icj+fMQQoQ5z0CUnQ2LY+fA5s3qgTVrID7eVRlauFBVpjRdIQNVrdq82dpiHqxVsIbWbzW0zsvfZN2YEBK8WlRrrPOS6YbNIB/2g4P8OQghwoy5q6F582Jz0Pn3g2uY7nxA/fDXv8JZZwHuypB5DVh2tqqQzZ3rrhrpfb8OHVKVMZtNrd3SzTgaqixJBUqI1ifBS7Rt8qFfNJcj0AMQoWb+/PnYbDamTZvmus8wDBwOB0lJSbRv356MjAw++eSTwA1SNIs5YOkKlM3mDjoPT/qcRysmALCjfxZccYXruboyNGtW7W6FOTkqMC1ebK10GYb6cjrdzTgaqix5VqCk+YUQLU+Cl2geR6AH4AcSvgJHrr1oY95//30ef/xx+vbta7n/gQceYPHixSxbtoz333+fxMREhg0bxrFjxwI0UtEUubnq1twxMCtLNccwjJPdB+8oZdijl9GRY7wbkc6g7Qu9TkPU3QrNXQzBHeSKilQFzG5Xr+fZbr6xpPmFEC1PglcYkM2U/UACQOsLh2vuCPQARCgpLS3lmmuuYcWKFXTq1Ml1v2EYLFmyhDlz5jBmzBhSUlJ45plnKC8v54UXXgjgiIWZLxWh5cvVrbljYE4OREerphi5uQYf9Z9Ib+MTDtODB857Gez2WqHH/LPnY+Ypgjk5anqh0+luN9/UNVQy9VCIlhcV6AGEu1t4jEe5OdDDaFkOwuMD6AX9YfPuQI+ibQiH0CVEI02ePJlLL72UoUOHkqtLI8D+/fspLCwkMzPTdV9MTAxDhgxhx44d3Hyz9/+HVFRUUFFR4fq5pKQEAKfTidPclcFH+jlNeW5b8OijqsPgn/+svp80SVWczKZMUddu6lSnpTHGjBnw4IPwp6pl9P3XKpxEMT76BT76TxecTiczZqjQNnmyClHmnw3D+tjdd6svsDbfaK6WOm9jyd/D5pNr2HyNvYa+HifBSwgzCV8tL1xClyPQAxChZNWqVXz44Ye8//77tR4rLCwEoHv37pb7u3fvztdff13nOefPn8+9995b6/7169cTGxvb5LFu2LChyc8NZ088Ufu+t96y/nzuuer2nHM2WB771a/gH3d/yuCTSe2zG6/n1pHFwFu89ZZ6XJ/f82fza3u+XjiTv4fNJ9ew+Xy9huXl5T4dJ8ErTAz/zRre3jYm0MMIDxK+Wk64hC4hGuHgwYPcdtttrF+/nnbt2tV5nO3k/k2aYRi17jObPXs2003zwkpKSkhOTiYzM5OOHTs2epxOp5MNGzYwbNgw7HZ7o5/fVuTmuitQc+ZYH9PXcMqUYfzhD3Z3RaywkKg//QlbdTU1V1zBL5cv55cef7ZJSWpKYVyc2oC5uePzVpHz5fFAk7+HzSfXsPkaew31jIOGSPBqBTLdMARJ+PK/cApdjkAPQISSPXv2cPToUfr16+e6r7q6mm3btrFs2TI+//xzQFW+evTo4Trm6NGjtapgZjExMcTExNS63263N+vDVnOfH+7uvVd91ef77+0sWmRXxzmdcO21cOQI9O5NxF//SkR0dK3n3HKLWsf1pz+phhlNtWiRCnCLFnkfZ0OPBwv5e9h8cg2bz9dr6Ot1luYaQtQlnIJCoMm1FG3YhRdeyMcff8zevXtdX+eddx7XXHMNe/fu5ac//SmJiYmWKS2VlZVs3bqVQYMGBXDkoqksTSpmz4Zt2yA+Xm2S3KGD1+eY27vX1cjDlwYfDTXJMD8uLeSFaF0SvMJIwLsbOgL78i1CAkPzyTUUbVx8fDwpKSmWr7i4OLp06UJKSoprT6/777+ftWvXsm/fPiZMmEBsbCzjxo0L9PBFPTyDi+6ZMmnSye6Cr7yiSksATz8NZ57p03nrau3uS8t3z/256ntcWsgL0bokeAnREAkOTReO184R6AGIcHTHHXcwbdo0Jk2axHnnncc333zD+vXriY+PD/TQRD08g4tuJ798OfDZZ3DDDeo4++1kF/i+DruuqpW/W75LC3khWpcEr1ZyC48FegitwxHoAbSQcAwQLemC/nLNhKjHli1bWLJkietnm82Gw+HgyJEjnDhxgq1bt5KSkhK4AQqfeAaXSZNO3j+xFMaMgdJStkVkcLvzfvLyID0dbDZITq5/il9dVauGqlmN5e/zCSHq9//t3Xl8TPf+P/BXZA/JWEImgxL32iqqyi3RulFL1FpXFaVKr6VKqmnQ2m4dWnTR0FJUq6j9tuhXW9VEa2kuWtJEQ/3ovZZQIqWRRJD18/tjmmkmm0kyM59zzryej8c8TM58ZuZ1Pjkjn/d8zsLCS2ek726oZywkbKPnflJkByAiNSlZuMyZA0AIzPhlAnDqFGAy4dCUrfCp6YHoaCA+3tzu0iXu4kfkilh4kf0psgM4kJ6LCntg/xCRi2v2+eeo8emngIcH8MknmLEkyFKcPfywuU3jxhXv4seTXhDpEwsvJ3KZ3Q31jrvRlU3vfaLIDkBEaucWH48269aZf4iJAUqclfK77wAhgJSUinfxc9ZJL1jgETkXCy8dUsXuhorsAE6g90LDVixEiYiAK1fgPmIEahQWonD4cCAyssov5ayTXvCshkTOxcKLqDpcvehwlXVXZAcgIlXLywOGDoVbaioy77kHBStXms+iUUXOOukFz2pI5FwsvJzMWbsbctbLyVylACniSgWnIjsAEaneyy8D8fEQAQH44eWXYWpeUxO77/GshkTOxcKLHEuRHcCJXKUYcYV1JCKy1b//bdlXr2DNGmQ3bMjd94ioTCy8iOxNrwWYXterIorsAESkaj//DPzzn+b7M2ZAPPYYgLJ33+OJLIiIhZcELrW7IeC6g1e9FCp6WQ8iokqqsFjKyjJfJDk7G+je3bzf3h8uXy69+x5PZEFELLyIHE2rhYtWc9uLIjuAvuTn52POnDkICQmBr68vmjVrhvnz56OwsNDSRggBRVFgMpng6+uLbt264eTJk1avk5OTg+effx6BgYGoWbMmBg4ciEuXLlm1SU9Px6hRo2AwGGAwGDBq1CjcuHHDGatJOlNusSQE8MwzwOnTQKNGwJYt5ut2VYAnsiAiFl46x1kvFdFKIaOVnKQpb7zxBlatWoXly5fj1KlTePPNN/HWW29h2bJlljZvvvkmYmJisHz5chw9ehRGoxG9evVCVlaWpU1UVBR27tyJrVu3Ij4+Hjdv3kT//v1RUFBgaTNixAgkJSVhz5492LNnD5KSkjBq1Cinri/pQ7nFUkwMsH074OkJfPIJ0KCB1cMmU+lZsuqcyIK7KRLpAwsvSXgxZRdWVNioqbhRYyaZFNkB9Ofw4cN47LHH0K9fPzRt2hRDhgxBREQEjh07BsA827V06VLMnj0bgwcPRmhoKNavX49bt25h8+bNAICMjAysWbMGb7/9Nnr27In27dtj48aNSE5Oxt69ewEAp06dwp49e/Dhhx8iLCwMYWFh+OCDD/DFF1/g9OnT0taftKnMYunAAfNZDAFg6VKgc+dSz7P3LoXcTZFIH1h4kfMosgOokMyCh8UWOdHDDz+Mb775BmfOnAEAHD9+HPHx8ejbty8A4Ny5c0hNTUVERITlOd7e3ggPD8ehQ4cAAAkJCcjLy7NqYzKZEBoaamlz+PBhGAwGdOr053bduXNnGAwGSxuiKvv1V2DoUKCgABg1CnjuuTKb2XuXQu6mSKQPFe+QTLrQ5+878NXBwbJjmClgAVaekgXQvu8d+/pUNkV2AG3JzMy0+tnb2xve3t6l2r388svIyMhAq1at4O7ujoKCAixYsABPPvkkACA1NRUAEBQUZPW8oKAgXLhwwdLGy8sLderUKdWm6PmpqaloUGK3LwBo0KCBpQ1RleTmmouutDTgvvuAVavKvUjy5cvmvRDt5dVXrc7dQUQaxcJLool4H6vwrOwYpFZ3K5RKFmYsrKpPkR3gTz0f2oW99nqxRbD///b55n8aN25stXju3LlQFKVU823btmHjxo3YvHkz2rRpg6SkJERFRcFkMmH06NGWdm4lBrJCiFLLSirZpqz2trwOUYWmTwcOHQIMBvPxXX5+shMRkcaw8HIRnPXSIRZapAIXL15EQECA5eeyZrsAYPr06ZgxYwaGDx8OAGjbti0uXLiARYsWYfTo0TAajQDMM1bBwcGW56WlpVlmwYxGI3Jzc5Genm4165WWloYuXbpY2ly9erXU+//222+lZtOIbLZlC/Duu+b7H38M/PWvcvMQkSbxGC8iIkBVXwao5mykNggICLC6lVd43bp1CzVqWP/JcXd3t5xOPiQkBEajEXFxcZbHc3NzceDAAUtR1aFDB3h6elq1uXLlCk6cOGFpExYWhoyMDPzwww+WNt9//z0yMjIsbYgq5cQJYNw48/1Zs4CBA+XmISLNYuElmTPPbqiqwZwiOwBRMYrsAPo3YMAALFiwAF9++SXOnz+PnTt3IiYmBv/4xz8AmHcPjIqKwsKFC7Fz506cOHECY8aMgZ+fH0aMGAEAMBgMGDt2LKZOnYpvvvkGiYmJeOqpp9C2bVv07NkTANC6dWs8+uijGD9+PI4cOYIjR45g/Pjx6N+/P1q2bClt/UmjMjKAxx8Hbt0Cevas2rngiYj+wMKL5FFkByBSH1V9QWJHy5Ytw5AhQzBp0iS0bt0a06ZNw7PPPotXi50x4KWXXkJUVBQmTZqEjh074tdff0VsbCz8/f0tbZYsWYJBgwZh6NCheOihh+Dn54fPP/8c7u7uljabNm1C27ZtERERgYiICNx3333YsGGDU9eXdKDoIslnzgCNG5t3Nyy2ndkLr9FF5Dp4jJeLUdWxXkRqoMgO4Br8/f2xdOlSLF26tNw2bm5uUBSlzJNzFPHx8cGyZcusLrxcUt26dbFx48ZqpCUC8NZbwM6dgJcX8OmnQGCgQ96m+DW6eOZCIn3jjJcKuPTFlBXZAYjUQ6+zXURa89FT36Lg5ZnmH959F3jwQYe9F6/RReQ6WHiRfIrsAOSyFNkBiEh1Ll3CgE3D4Y5CbPAYA0yY4NC3e/VV4OZNHj5G5ApYeKmEy55kg0gWRXYAIlKd3FzgiSdQH7/heI37cW7ainIvkkxEVFk8xovUQQEHwuQ8iuwApfELESIViI4GjhwBatdGu4TtaNfMV3YiItIRzni5KFUO8hTZAYiIyGVt3Ai8996f95s1k5uHiHSHhZeKuPRJNoicRZEdoDRVfhFC5Ep++unPY7n+9S+gXz+bnsZTwRNRZbDwcmGqHOwpsgOQrimyAxCR6ty4Yb5I8u3bQO/ewNy5Nj+1+KngiYjuhoUXqY8iOwCR86jyCxAiV1FYCIweDfz3v0CTJsCmTZW6SDJPBU9ElcHCS2Wcvbuhagd9iuwApDuK7ABEpDpvvAHs2gV4e5svklyvXqWezlPBE1FlsPAiIv1TZAcom2q/+CByBXv3AnPmmO8vXw507Cg3DxHpHgsvFeKs1x8U2QFIFxTZAYhIdVJSgCefNO9q+M9/AuPGyU5ERC6AhRepmyI7AJFjqPYLDyK9y8kBhgwBrl0DHnjAPNtFROQELLxUirNexSiyA5BmKbIDEJHqREUBR48CdeqYj+vy9eVp4YnIKVh4kTYosgOQ5iiyA5RP1V90EOnZ+vXAqlWAm5v5DIYhIQB4Wngicg4WXtXQN/lb2RHsioNB0g1FdgAiUp2kJGDiRPP9uXOBPn0sD/G08ETkDCy8VMzZuxuqniI7AGmCIjtAxfgFB5EE6enA4MHAnTtA376l9inkaeGJyBlYeFXTwOOxsiPYleoHhYrsAKRqiuwAFVP954tIjwoLgVGjgHPngKZNgQ0bgBoc/hCR8/F/HpWTMeul+sGhIjsAqZIiOwARqdLChcCXXwI+PsCOHUDdurITEZGLYuFF2qTIDkBUOar/QoNIj77+GnjlFfP9FSuA9u3l5iEil8bCyw4cvbshZ73KocgOQKqhyA5ARKpz4QIwYgQgBDBhAvDMM7ITEZGLY+FF2qbIDkDSKbID3J0mvsgg0pM7d8wXSf79d6BjR+Cdd2QnIiJi4UXl08xgUZEdgKRRZAcgIlWaMgU4dgyoV898kWQfH9mJiIhYeNmLHnc31BRFdgByOkV2ANto5gsMIr1Yuxb44APzRZI3bwaaNJGdiIgIAAsvugtNDRoV2QHIaRTZAWyjqc8PkR78+CPw3HPm+6++CkREyM1DRFQMCy870uusl6YGj4rsAORwiuwARKRKv/8OPP44kJMDDBgAzJwpOxERkRUWXqQ/iuwA5DCK7AC209QXFkRaV3SR5PPngb/8Bfj4Y14kmYhUh/8raQxnvWykyA5AdqfIDkBEqvXaa8Du3eaTaGzfDtSuLTsREVEpLLzszNG7G1IlKLIDkN0osgNUjua+qCDSsj17AEUx33//faBdO6lxiIjKo5nCa8GCBejSpQv8/PxQu5xvslJSUjBgwADUrFkTgYGBmDJlCnJzc63aJCcnIzw8HL6+vmjYsCHmz58PIYQT1sB+OOtVCYrsAFQtCjT3O9Tk54RIq86d+/MiyRMnAk8/LTsREVG5NFN45ebm4oknnsBzRWcrKqGgoAD9+vVDdnY24uPjsXXrVmzfvh1Tp061tMnMzESvXr1gMplw9OhRLFu2DIsXL0ZMTIxds+p51kuTg0pFdgCqEkV2ACJStaKLJKenAw8+CCxdKjsREVGFPGQHsNW8efMAAOvWrSvz8djYWPz888+4ePEiTCYTAODtt9/GmDFjsGDBAgQEBGDTpk24c+cO1q1bB29vb4SGhuLMmTOIiYlBdHQ03NzcnLU61TYR72MVnpUdQzsUcCCvJYrsAFWjyS8miLQqMtJ8+vjAQOCTTwBvb9mJiIgqpJkZr7s5fPgwQkNDLUUXAPTu3Rs5OTlISEiwtAkPD4d3sf+ce/fujcuXL+P8+fPlvnZOTg4yMzOtbq5Ms4NLRXYAsokiO0DVaPZzQaRFH34IrFljPnPhli3APffITkREdFe6KbxSU1MRFBRktaxOnTrw8vJCampquW2Kfi5qU5ZFixbBYDBYbo0bN75rHmfsbijrWC9Aw4NMBZod2LsERXYAIlK9Y8fMs12A+SLJPXvKzUNEZCOphZeiKHBzc6vwduzYMZtfr6xdBYUQVstLtik6sUZFuxnOnDkTGRkZltvFixdtzkQqpcgOQFYUaPp3otkvIoi05vp183FdOTnAwIHAjBmyExER2UzqMV6RkZEYPnx4hW2aNm1q02sZjUZ8//33VsvS09ORl5dnmdUyGo2lZrbS0tIAoNRMWHHe3t5WuyfaauDxWOxqF1Hp51WGzGO9+vx9B746OFjKe9uFAk0P9nVDkR2gelh0ETlJQQEwciRw4YL5Isnr1/MiyUSkKVILr8DAQAQGBtrltcLCwrBgwQJcuXIFwcHBAMwn3PD29kaHDh0sbWbNmoXc3Fx4eXlZ2phMJpsLPLKmi+Kr+L/kXIrsAESkGfPmAV9/Dfj6Ajt28CLJRKQ5mvmqKCUlBUlJSUhJSUFBQQGSkpKQlJSEmzdvAgAiIiJw7733YtSoUUhMTMQ333yDadOmYfz48QgICAAAjBgxAt7e3hgzZgxOnDiBnTt3YuHChQ49o6Hej/XSDUV2ABejQBd9ztkuIif54gvz8VwAsHo1cN99cvMQEVWBZgqvV155Be3bt8fcuXNx8+ZNtG/fHu3bt7ccA+bu7o4vv/wSPj4+eOihhzB06FAMGjQIixcvtryGwWBAXFwcLl26hI4dO2LSpEmIjo5GdHS0rNXSBd0MPhXoohhQPUV2APvQzXZPpHZnzwKjRpnvT54MPPWU3DxERFWkmet4rVu3rtxreBW555578MUXX1TYpm3btjh48KAdk6mD7Ot6aX6Xw+IU6KY4UBVFdgAi0pxbt4DBg4EbN4DOnYGYGNmJiIiqTDMzXlrmjN0N1UBXMwAKWCjYkyI7gH3palsnUishgEmTgOPHgfr1zRdJ/uP4bCIiLWLhpSM81ssBFNkBNE6B7vqQRReRk6xe/eeZC7duBRo1kp2IiKhaWHg5CWe9NEyB7ooHh1Ogyz7T5fZNpEY//ABMmWK+v2gR0L273DxERHbAwktn1DDrpdvBqQJdFhN2pYB9RETVc+2a+SLJubnAP/4BTJ8uOxERkV2w8HIiZ816qaH40jUFLC5KUqD7PtHtFwrkcIsWLcLf/vY3+Pv7o0GDBhg0aBBOnz5t1UYIAUVRYDKZ4Ovri27duuHkyZOSEktUUAA8+SRw8SLQogWwdi3goMu9EBE5GwsvcgiXGKQq0H2xcVcKXKIPXGJ7Joc5cOAAJk+ejCNHjiAuLg75+fmIiIhAdna2pc2bb76JmJgYLF++HEePHoXRaESvXr2QlZUlMbkEr7wC7N0L+PmZL5JsMMhORERkNyy8nMyVZr1cZrCqwCWKDysKXGadXWY7JofZs2cPxowZgzZt2qBdu3ZYu3YtUlJSkJCQAMA827V06VLMnj0bgwcPRmhoKNavX49bt25h8+bNktM70a5dwMKF5vsffgi0aSM3DxGRnWnmOl6kTbq6vtfdKOXc1xNFdgAi7cvIyAAA1K1bFwBw7tw5pKamIiIiwtLG29sb4eHhOHToEJ59tuxrNObk5CAnJ8fyc2ZmJgAgLy8PeXl5lc5V9JyqPLfa/vtfeDz9NNwAFERGonDIEEBGjmqS2oc6wT6sPvZh9VW2D21tx8JLgoHHY7GrXcTdG1aT7IsqF3Gp4quIUs59LVJkB5CHs12Os2jRIsyaNQsvvPACli5dCsA88zNv3jysXr0a6enp6NSpE9577z20KTbzkZOTg2nTpmHLli24ffs2evTogRUrVqBRsVONp6enY8qUKdi1axcAYODAgVi2bBlq167tzFUskxAC0dHRePjhhxEaGgoASE1NBQAEBQVZtQ0KCsKFCxfKfa1FixZh3rx5pZbHxsbCz8+vyhnj4uKq/NyqcM/JQdeXX4YhIwPXW7XCf8LDIXbvdmoGe3N2H+oR+7D62IfVZ2sf3rp1y6Z2LLyIHE0p576aKbIDyMeiy3GOHj2K1atX47777rNaXnSc07p169CiRQu89tpr6NWrF06fPg1/f38AQFRUFD7//HNs3boV9erVw9SpU9G/f38kJCTA3d0dADBixAhcunQJe/bsAQBMmDABo0aNwueff+7cFS1DZGQkfvrpJ8THx5d6zK3ESSSEEKWWFTdz5kxER0dbfs7MzETjxo0RERGBgICASmfLy8tDXFwcevXqBU9Pz0o/v0qEgPs//4ka589DBAUhYM8e9DGZnPPeDiClD3WGfVh97MPqq2wfFu1xcDcsvCThrJeLUsq5L5siO4C6sOhynJs3b2LkyJH44IMP8Nprr1mWlzzOCQDWr1+PoKAgbN68Gc8++ywyMjKwZs0abNiwAT179gQAbNy4EY0bN8bevXvRu3dvnDp1Cnv27MGRI0fQqVMnAMAHH3yAsLAwnD59Gi1btnT+Sv/h+eefx65du3Dw4EGrGTqj0QjAPPMVHBxsWZ6WllZqFqw4b29veHt7l1ru6elZrcFWdZ9fKStXAps2Ae7ucNu2DZ5NmjjnfR3MqX2oU+zD6mMfVp+tfWhrP/PkGi5ADSfaADiYLUUp46bn99UIbqeONXnyZPTr189SOBW523FOAJCQkIC8vDyrNiaTCaGhoZY2hw8fhsFgsBRdANC5c2cYDAZLG2cTQiAyMhI7duzAt99+i5CQEKvHQ0JCYDQarXZpyc3NxYEDB9ClSxdnx3WeI0eAF14w33/jDSA8XG4eIiIH44yXRM6a9VITznzdhVLNxyvbjqyoqegai7XYKzuEDUruXlHeLAwAbN26FT/++COOHj1a6jFbjnNKTU2Fl5cX6tSpU6pN0fNTU1PRoEGDUq/foEEDSxtnmzx5MjZv3oz/+7//g7+/vyWHwWCAr68v3NzcEBUVhYULF6J58+Zo3rw5Fi5cCD8/P4wYMUJKZodLSwOeeMJ8Ao0hQ4Biu0wSEekVCy8XoZZdDgEWX9WiyA5AmvTdMQA17fyi5mtQNW7c2Grp3LlzoShKqdYXL17ECy+8gNjYWPj4+JT7qpU9zqmsNmW1t+V1HGXlypUAgG7dulktX7t2LcaMGQMAeOmll3D79m1MmjTJcmKR2NhYy7FtupKfb75I8qVLQMuWwJo1vEgyEbkEFl6SueKsF8Dii9RHTbNdE/E+bDs/knwXL160OpFDebNdCQkJSEtLQ4cOHSzLCgoKcPDgQSxfvhynT58GUPFxTkajEbm5uUhPT7ea9UpLS7Pskmc0GnH16tVS7//bb79VeLyUIwkh7trGzc0NiqKUWbTqzr/+BXz7LVCzpvkiyVU4EQgRkRbxGC8XopZjvYqoaaBLrk1N26LaPqd3ExAQYHUrr/Dq0aMHkpOTkZSUZLl17NgRI0eORFJSEpo1a3bX45w6dOgAT09PqzZXrlzBiRMnLG3CwsKQkZGBH374wdLm+++/R0ZGhr6Pl9KKzz4DXn/dfP+jj4B775Uah4jImTjjpQLOnPVS0y6HAGe+SD41FV165u/vb7luVZGaNWuiXr16luV3O87JYDBg7NixmDp1KurVq4e6deti2rRpaNu2reVkHa1bt8ajjz6K8ePH4/33zUXshAkT0L9/f6lnNCQAZ84Ao0eb77/4IjB0qNw8REROxsKLiFyW2oourc122ZstxzktWbIEHh4eGDp0qOUCyuvWrbNcwwsANm3ahClTpljOfjhw4EAsX77c6etDxWRnA48/DmRmAg8/bD6LIRGRi2HhpRKc9eKsFzkXiy759u/fb/WzLcc5+fj4YNmyZVi2bFm5berWrYuNGzfaKSVVmxDAhAnAiROA0Qj8+98Ary1ERC6Ix3i5KLUN8tQ2CCZ94/ZG5ETLlwObNwPu7uaiq9jJU4iIXAkLLxUZeDxWdgSpOBgmZ1Djdqa2L0KI7ObQoT+v0fXWW0DXrnLzEBFJxMLLhalxsKfGQTHphxq3LzV+Dons4upV80WS8/PNJ9KIipKdiIhIKhZeKuPsWS81DvrUODgm7eN2ReRE+fnA8OHA5ctA69a8SDIREVh4kUpxkEz2pNbtSY1ffBDZxaxZwP79QK1a5osk16olOxERkXQsvFSIs15mah0sk7aodTtS6+eOqNq2bzcfzwUAa9cCrVrJzUNEpBIsvAiAegeBah00kzZw+yFystOngWeeMd+fOhUYMkRuHiIiFWHhpVKufobD4vr8fQcH0FRpat5m1PpFB1G13LwJDB4MZGUB4eHA66/LTkREpCosvKpjqewA9qX2waCaB9KkLmreVtT+OSOqEiGA8eOBn382X6dr61bAw0N2KiIiVWHhpWIyZr3UPihU84Ca1IHbCJEE7777Z7H1ySeA0Sg7ERGR6rDwqq43HPvyLL5K48CayqP2bUPtny2iKomPB6ZNM99/+23goYfk5iEiUikWXqRJah9gk3Np4ThAFl2kS6mp5osj5+cDTz4JPP+87ERERKrFwsseOOslhdoH2uQcWtgOtPB5Iqq0vDxg2DDgyhWgTRvggw94kWQiogqw8KJyaWGwqIWZDnIc/u6JJJoxAzh4EPD3N18kuWZN2YmIiFSNhZe96HDWC9BG8QVwAO6KtPI718pniKhSPvkEiIkx31+3DmjRQmocIiItYOGlIby2V8W0MhCn6tHSLCeLLtKlU6f+vEjy9Onma3cREdFdsfCyJwfPesmipcGjVgbkVDVa+v1q6XNDZLOsLHOhlZ0NPPIIsHCh7ERERJrBwktjuMvh3WlpRoRsx98pkWRCAP/8J/D//h/QsCGwZQsvkkxEVAksvOxNp7NegLaKL4ADdb3QYiGttc8KkU2WLAE+/RTw9DQf4xUUJDsREZGmsPDSIB7rZTstDtrpT1r83bHoIl06eBB46SXz/SVLgLAwuXmIiDSIhZcjOGHWi7scVo4WB/CuTKsFs1Y/H0QVunzZfJHkggJg5Ehg0iTZiYiINImFF1WaVgeXWh3Muxqt/o60+rkgqlBenrnounoVaNsWeP99XiSZiKiKWHg5io5nvQBtDzK1OrDXOy0Xxlr+PBBVaPp04D//AQICgO3beZFkIqJqYOHlSCy+VEvLg3y94e+CSKW2bAHeecd8/+OPgebN5eYhItI4Fl5ULVouvgAO+mXTQ99r/TNAVKaTJ4Fx48z3Z84EHntMbh4iIh1g4eVoOp/1AvQx8GQB5lx66W89bPtEpWRmmi+SfOsW0KMH8OqrshMREekCCy+dkF186YUeigE100vBBbDoIp0SAu7jxgFnzgCNG5t3N3R3l52KiEgXWHg5g44vqlxET4NQPRUHaqG3PtXT9k5U3F8/+ww1PvsM8PIyXyy5fn3ZkYiIdMNDdgCyn4HHY7GrXYS095+I97EKz0p7f3srXih8dXCwxCTapadiqwiLLtIrt/37ce+GDeYf3nkHePBBuYGIiHSGM17O4qRZL9m7HOp1UKq3GRtH02t/6XX7JsKvv8L9qafgVliIwqeeAp7Vz5doRERqwRkvsju9zXwVV1RMcAasND0WWsWx6CJde+cduKWlIaNpU/gtX44avEgyEZHdsfBypjcAvOz4t5G9yyGg7+IL4G6Ixem94AJYdJELWLQIBb6++CE4GN38/GSnISLSJe5q6Gwusssh4DqDVb3uVleRonV2hfV2le2YXJy7OwrnzMGt4GDZSYiIdIszXuRQep/5Kq5kEaK3mTBXKLJKYtFFRERE9sLCSwYX2uUQcK3iqzit747oioVWcSy6iIiIyJ5YeOkciy910MJsmKsXWsWx6CIiIiJ7Y+Eli5NmvQAWX2pUXpHjrIKMRVb5WHQRERGRI7DwksmJxZdasPiqGAsiudRUdPVN/lZ2BCIiIrIjntXQRajhLIdF1DS4JSqipu1STZ9XIiIisg8WXrI56fTygLoGc2oa5BJxeyQiIiJHY+HlYlh8EVlT23aops8oERER2Q8LLzVw4qyX2qht0EuuRW3bH4suIiIi/WLhpRYuusshYB78qm0ATPqntm1ObZ9LIiIisi8WXi5KjYM8tQ2ESb/Utq2p8fNIRERE9sXCS02cvMuhGgd7ahsQk75wdpWIiIhkYeGlNiy+ODAmh1DrdqXGzyARERHZHwsvUiW1DpJJm9S6PbHoIiIich2aKbwWLFiALl26wM/PD7Vr1y6zjZubW6nbqlWrrNokJycjPDwcvr6+aNiwIebPnw8hhBPWoBI46wWAu4WRfah1G1Lr587RVqxYgZCQEPj4+KBDhw747rvvZEciIiJyCs0UXrm5uXjiiSfw3HPPVdhu7dq1uHLliuU2evRoy2OZmZno1asXTCYTjh49imXLlmHx4sWIiYlxdPzKY/FlodaBM6mbmgt3NX/eHGnbtm2IiorC7NmzkZiYiK5du6JPnz5ISUmRHY2IiMjhNFN4zZs3Dy+++CLatm1bYbvatWvDaDRabr6+vpbHNm3ahDt37mDdunUIDQ3F4MGDMWvWLMTExFRp1uvIp5V+iqqpeTCo1gE0qRO3F3WKiYnB2LFjMW7cOLRu3RpLly5F48aNsXLlStnRiIiIHM5DdgB7i4yMxLhx4xASEoKxY8diwoQJqFHDXF8ePnwY4eHh8Pb2trTv3bs3Zs6cifPnzyMkJKTM18zJyUFOTo7l54yMDABANoDMPMetC14DEOXA1y9Dt//EYnfb7s59Uxs9jfcAAGvwjOQkpGZjsRa3ZIeoQN/kb5FpQ7vMbPO/9tkVOtsOr1H2a2ZmWq+Nt7e31f+xRXJzc5GQkIAZM2ZYLY+IiMChQ4cckM/1FG0rJX8ntsrLy8OtW7eQmZkJT09Pe0ZzGezD6mMfVh/7sPoq24dF/+/e7W+2rgqvV199FT169ICvry+++eYbTJ06FdeuXcOcOXMAAKmpqWjatKnVc4KCgiyPlVd4LVq0CPPmzSu1fDAAOHrWS8qs2rcy3rQS1J6PZNorO4CdXb9+HQaDoUrP9fLygtFoRGrqQDunMqtVqxYaN25stWzu3LlQFKVU22vXrqGgoMDyf26RoKAgpKamOiSfq8nKygKAUr8TIiJyjqysrAr/ZkstvBRFKbOgKe7o0aPo2LGjTa9XVGABwP333w8AmD9/vtVyNzc3q+cUVaYllxc3c+ZMREdHW36+ceMGmjRpgpSUlCoPiGTJzMxE48aNcfHiRQQEBMiOUynMLgezy5GRkYF77rkHdevWrfJr+Pj44Ny5c8jNzbVjsj8JIUr931nWbFdxZf0fXNH/v2Q7k8mEixcvwt/fv0p9quXPi1qwD6uPfVh97MPqq2wfCiGQlZUFk8lUYTuphVdkZCSGDx9eYZuSM1SV0blzZ2RmZuLq1asICgr645tf629W09LSAKDUt7DFlbfrjMFg0OwGHRAQwOwSMLscWs5etKt0Vfn4+MDHx8dOaaouMDAQ7u7uZf4fXNH/v2S7GjVqoFGjRtV+HS1/XtSCfVh97MPqYx9WX2X60JbJGKmFV2BgIAIDAx32+omJifDx8bGcfj4sLAyzZs1Cbm4uvLy8AACxsbEwmUzVKvCIiKhiXl5e6NChA+Li4vCPf/zDsjwuLg6PPfaYxGRERETOoZljvFJSUvD7778jJSUFBQUFSEpKAgD89a9/Ra1atfD5558jNTUVYWFh8PX1xb59+zB79mxMmDDBMls1YsQIzJs3D2PGjMGsWbPwyy+/YOHChXjllVe4qwsRkYNFR0dj1KhR6NixI8LCwrB69WqkpKRg4sSJsqMRERE5nGYKr1deeQXr16+3/Ny+fXsAwL59+9CtWzd4enpixYoViI6ORmFhIZo1a4b58+dj8uTJlucYDAbExcVh8uTJ6NixI+rUqYPo6Gir47ds4e3tjblz5971WAY1YnY5mF0OZleXYcOG4fr165g/fz6uXLmC0NBQ7N69G02aNJEdjaDPbc7Z2IfVxz6sPvZh9TmqD92Efc5VTEREREREROXQzAWUiYiIiIiItIqFFxERERERkYOx8CIiIiIiInIwFl5EREREREQOxsKrAgsWLECXLl3g5+dnuRZYSSkpKRgwYABq1qyJwMBATJkyBbm5uVZtkpOTER4eDl9fXzRs2BDz58+HjHOaNG3aFG5ubla3GTNmWLWxZX1kWLFiBUJCQuDj44MOHTrgu+++kx2pFEVRSvWv0Wi0PC6EgKIoMJlM8PX1Rbdu3XDy5EkpWQ8ePIgBAwbAZDLBzc0Nn332mdXjtmTNycnB888/j8DAQNSsWRMDBw7EpUuXpGcfM2ZMqd9D586dpWdftGgR/va3v8Hf3x8NGjTAoEGDcPr0aas2au530ra7fW5K2rFjB3r16oX69esjICAAYWFh+Prrr50TVqUq24fF/ec//4GHhwfuv/9+h+XTgqr0YU5ODmbPno0mTZrA29sbf/nLX/DRRx85PqxKVaUPN23ahHbt2sHPzw/BwcF45plncP36dceHVSlb/h6X5cCBA+jQoQN8fHzQrFkzrFq1qtLvzcKrArm5uXjiiSfw3HPPlfl4QUEB+vXrh+zsbMTHx2Pr1q3Yvn07pk6dammTmZmJXr16wWQy4ejRo1i2bBkWL16MmJgYZ62GlaLTOBfd5syZY3nMlvWRYdu2bYiKisLs2bORmJiIrl27ok+fPkhJSZGaqyxt2rSx6t/k5GTLY2+++SZiYmKwfPlyHD16FEajEb169UJWVpbTc2ZnZ6Ndu3ZYvnx5mY/bkjUqKgo7d+7E1q1bER8fj5s3b6J///4oKCiQmh0AHn30Uavfw+7du60el5H9wIEDmDx5Mo4cOYK4uDjk5+cjIiIC2dnZljZq7nfSNls+N8UdPHgQvXr1wu7du5GQkIBHHnkEAwYMQGJiooOTqldl+7BIRkYGnn76afTo0cNBybSjKn04dOhQfPPNN1izZg1Onz6NLVu2oFWrVg5MqW6V7cP4+Hg8/fTTGDt2LE6ePIlPPvkER48exbhx4xycVL1s+Xtc0rlz59C3b1907doViYmJmDVrFqZMmYLt27dX7s0F3dXatWuFwWAotXz37t2iRo0a4tdff7Us27Jli/D29hYZGRlCCCFWrFghDAaDuHPnjqXNokWLhMlkEoWFhQ7PXlyTJk3EkiVLyn3clvWR4cEHHxQTJ060WtaqVSsxY8YMSYnKNnfuXNGuXbsyHyssLBRGo1G8/vrrlmV37twRBoNBrFq1ykkJywZA7Ny50/KzLVlv3LghPD09xdatWy1tfv31V1GjRg2xZ88eadmFEGL06NHiscceK/c5asmelpYmAIgDBw4IIbTV76RtZX1ubHHvvfeKefPm2T+QBlWmD4cNGybmzJlT4d8IV2RLH3711VfCYDCI69evOyeUxtjSh2+99ZZo1qyZ1bJ3331XNGrUyIHJtKXk3+OyvPTSS6JVq1ZWy5599lnRuXPnSr0XZ7yq4fDhwwgNDYXJZLIs6927N3JycpCQkGBpEx4ebnUBtt69e+Py5cs4f/68syPjjTfeQL169XD//fdjwYIFVrsR2rI+zpabm4uEhARERERYLY+IiMChQ4ekZKrIL7/8ApPJhJCQEAwfPhxnz54FYP6mJDU11Wo9vL29ER4errr1sCVrQkIC8vLyrNqYTCaEhoaqYn3279+PBg0aoEWLFhg/fjzS0tIsj6kle0ZGBgCgbt26APTR76RfhYWFyMrKsmyvZJu1a9fif//7H+bOnSs7iibt2rULHTt2xJtvvomGDRuiRYsWmDZtGm7fvi07mmZ06dIFly5dwu7duyGEwNWrV/Hpp5+iX79+sqOpRsm/x2U5fPhwqbFo7969cezYMeTl5dn8Xh5Vi0gAkJqaiqCgIKtlderUgZeXF1JTUy1tmjZtatWm6DmpqakICQlxSlYAeOGFF/DAAw+gTp06+OGHHzBz5kycO3cOH374oSXP3dbH2a5du4aCgoJSuYKCgqRlKk+nTp3w8ccfo0WLFrh69Spee+01dOnSBSdPnrRkLWs9Lly4ICNuuWzJmpqaCi8vL9SpU6dUG9m/lz59+uCJJ55AkyZNcO7cOfzrX/9C9+7dkZCQAG9vb1VkF0IgOjoaDz/8MEJDQwFov99J395++21kZ2dj6NChsqNoxi+//IIZM2bgu+++g4cHh1tVcfbsWcTHx8PHxwc7d+7EtWvXMGnSJPz+++8ufZxXZXTp0gWbNm3CsGHDcOfOHeTn52PgwIFYtmyZ7GiqUNbf47KUNUYOCgpCfn4+rl27huDgYJvez+VmvMo6AULJ27Fjx2x+PTc3t1LLhBBWy0u2EX+cWKOs51ZWZdbnxRdfRHh4OO677z6MGzcOq1atwpo1a6wOsLRlfWQoqw9lZyqpT58+ePzxx9G2bVv07NkTX375JQBg/fr1ljZaWI8iVcmqhvUZNmwY+vXrh9DQUAwYMABfffUVzpw5Y/l9lMeZ2SMjI/HTTz9hy5YtpR7Tar+Tfm3ZsgWKomDbtm1o0KCB7DiaUFBQgBEjRmDevHlo0aKF7DiaVVhYCDc3N2zatAkPPvgg+vbti5iYGKxbt46zXjb6+eefMWXKFLzyyitISEjAnj17cO7cOUycOFF2NFWo6O9xSfYYz7vcVzCRkZEYPnx4hW1KzlCVx2g04vvvv7dalp6ejry8PEtVbDQaS30TXbTbU8nKuSqqsz5FZ3r773//i3r16tm0Ps4WGBgId3f3MvtQViZb1axZE23btsUvv/yCQYMGATB/Y1L8WxE1rkfRmRgrymo0GpGbm4v09HSr2Ze0tDR06dLFuYHvIjg4GE2aNMEvv/wCQH72559/Hrt27cLBgwfRqFEjy3K99Tvpw7Zt2zB27Fh88skn6Nmzp+w4mpGVlYVjx44hMTERkZGRAMxFhBACHh4eiI2NRffu3SWnVL/g4GA0bNgQBoPBsqx169YQQuDSpUto3ry5xHTasGjRIjz00EOYPn06AOC+++5DzZo10bVrV7z22ms2z9ToUXl/j8tS3njew8MD9erVs/k9XW7GKzAwEK1atarw5uPjY9NrhYWF4cSJE7hy5YplWWxsLLy9vdGhQwdLm4MHD1odSxUbGwuTyWRzgeeo9Sk6O1XRh86W9XE2Ly8vdOjQAXFxcVbL4+LiVD/QzMnJwalTpxAcHIyQkBAYjUar9cjNzcWBAwdUtx62ZO3QoQM8PT2t2ly5cgUnTpxQ3fpcv34dFy9etGznsrILIRAZGYkdO3bg22+/LbWbsd76nbRvy5YtGDNmDDZv3szjQSopICAAycnJSEpKstwmTpyIli1bIikpCZ06dZIdURMeeughXL58GTdv3rQsO3PmDGrUqHHXgTKZ3bp1CzVqWA/33d3dAUDKpY3U4G5/j8sSFhZWaiwaGxuLjh07wtPTs1JvTuW4cOGCSExMFPPmzRO1atUSiYmJIjExUWRlZQkhhMjPzxehoaGiR48e4scffxR79+4VjRo1EpGRkZbXuHHjhggKChJPPvmkSE5OFjt27BABAQFi8eLFTl2XQ4cOiZiYGJGYmCjOnj0rtm3bJkwmkxg4cKCljS3rI8PWrVuFp6enWLNmjfj5559FVFSUqFmzpjh//rzUXCVNnTpV7N+/X5w9e1YcOXJE9O/fX/j7+1tyvv7668JgMIgdO3aI5ORk8eSTT4rg4GCRmZnp9KxZWVmW7RmAZdu4cOGCzVknTpwoGjVqJPbu3St+/PFH0b17d9GuXTuRn58vLXtWVpaYOnWqOHTokDh37pzYt2+fCAsLEw0bNpSe/bnnnhMGg0Hs379fXLlyxXK7deuWpY2a+5207W6f+RkzZohRo0ZZ2m/evFl4eHiI9957z2p7vXHjhqxVkK6yfVgSz2pY+T7MysoSjRo1EkOGDBEnT54UBw4cEM2bNxfjxo2TtQrSVbYP165dKzw8PMSKFSvE//73PxEfHy86duwoHnzwQVmrIJ0tf49L9uPZs2eFn5+fePHFF8XPP/8s1qxZIzw9PcWnn35aqfdm4VWB0aNHCwClbvv27bO0uXDhgujXr5/w9fUVdevWFZGRkVanjhdCiJ9++kl07dpVeHt7C6PRKBRFcfqp5BMSEkSnTp2EwWAQPj4+omXLlmLu3LkiOzvbqp0t6yPDe++9J5o0aSK8vLzEAw88UOEpP2UZNmyYCA4OFp6ensJkMonBgweLkydPWh4vLCwUc+fOFUajUXh7e4u///3vIjk5WUrWffv2lbltjx492uast2/fFpGRkaJu3brC19dX9O/fX6SkpEjNfuvWLRERESHq168vPD09xT333CNGjx5dKpeM7GVlBiDWrl1raaPmfidtu9tnfvTo0SI8PNzSPjw8vML2rqiyfVgSC6+q9eGpU6dEz549ha+vr2jUqJGIjo62GiC7mqr04bvvvivuvfde4evrK4KDg8XIkSPFpUuXnB9eJWz5e1xWP+7fv1+0b99eeHl5iaZNm4qVK1dW+r3d/ghAREREREREDuJyx3gRERERERE5GwsvIiIiIiIiB2PhRURERERE5GAsvIiIiIiIiByMhRcREREREZGDsfAiIiIiIiJyMBZeREREREREDsbCi4iIiIiIyMFYeBERERERETkYCy8iO+ncuTOWLFli+XnYsGFwc3NDdnY2AODy5cvw8vLCqVOnZEUkIiIiIklYeBHZSe3atZGVlQUAuHjxIr7++mv4+/sjPT0dALB69Wp0794drVu3lhmTiIiIiCRg4UVkJ3Xq1MHNmzcBAMuXL8fIkSNRv359pKenIy8vD6tXr8YLL7wAAPjiiy/QsmVLNG/eHB9++KHM2ERERFL89ttvMBqNWLhwoWXZ999/Dy8vL8TGxkpMRuQYHrIDEOlF0YxXdnY2PvzwQxw+fBiHDh1Ceno6du7cCX9/fzz66KPIz89HdHQ09u3bh4CAADzwwAMYPHgw6tatK3sViIiInKZ+/fr46KOPMGjQIERERKBVq1Z46qmnMGnSJERERMiOR2R3nPEispOiGa/169cjLCwMLVq0QEBAANLT0/Hee+9hypQpcHNzww8//IA2bdqgYcOG8Pf3R9++ffH111/Ljk9EROR0ffv2xfjx4zFy5EhMnDgRPj4+eP3112XHInIIFl5EdlK7dm1kZmbinXfeQVRUFAAgICAA8fHxOH78OEaPHg3AfJKNhg0bWp7XqFEj/PrrrzIiExERSbd48WLk5+fj3//+NzZt2gQfHx/ZkYgcgoUXkZ3UqVMH3377Lby8vNCzZ08A5sJr5cqVGDt2LGrVqgUAEEKUeq6bm5tTsxIREanF2bNncfnyZRQWFuLChQuy4xA5DI/xIrKTol0Ni06gAZgLr9u3byMyMtKyrGHDhlYzXJcuXUKnTp2cmpWIiEgNcnNzMXLkSAwbNgytWrXC2LFjkZycjKCgINnRiOzOTZT19TsROUx+fj5at26N/fv3W06uceTIEdSrV092NCIiIqeaPn06Pv30Uxw/fhy1atXCI488An9/f3zxxReyoxHZHXc1JHIyDw8PvP3223jkkUfQvn17TJ8+nUUXERG5nP3792Pp0qXYsGEDAgICUKNGDWzYsAHx8fFYuXKl7HhEdscZLyIiIiIiIgfjjBcREREREZGDsfAiIiIiIiJyMBZeREREREREDsbCi4iIiIiIyMFYeBERERERETkYCy8iIiIiIiIHY+FFRERERETkYCy8iIiIiIiIHIyFFxERERERkYOx8CIiIiIiInIwFl5EREREREQOxsKLiIiIiIjIwf4/K98cOJ8uROIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=300)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.06155218 56.49744453]\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = y - tx.dot(w)\n",
    "    loss = -1 / N * (tx.T.dot(e))\n",
    "    return loss\n",
    "\n",
    "print(compute_gradient(np.array([y[0]]), np.array([tx[0, :]]), np.array([100, 20])))\n",
    "# print(compute_gradient(y, tx, np.array([50, 10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters + 1 containing the model parameters as numpy arrays of shape (2, ),\n",
    "            for each iteration of GD (as well as the final weights)\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.305745401473644, w1=9.435798704492269\n",
      "GD iter. 1/49: loss=265.3024621089598, w0=66.69746902191571, w1=12.266538315840005\n",
      "GD iter. 2/49: loss=37.87837955044127, w0=71.31498610804834, w1=13.115760199244333\n",
      "GD iter. 3/49: loss=17.410212120174467, w0=72.70024123388814, w1=13.370526764265632\n",
      "GD iter. 4/49: loss=15.568077051450455, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.386020684743531, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638307, w0=73.29348920882515, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.385887965652202, w0=73.29379216412117, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543452, w0=73.29388305070998, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613665, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835752, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.385887868829451, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829403, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.385887868829402, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.385887868829402, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.385887868829402, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.385887868829402, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.385887868829402, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.385887868829402, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.385887868829402, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.385887868829402, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829402, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829402, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.046 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "# gamma = 0.001\n",
    "# gamma = 0.01\n",
    "# gamma = 0.5\n",
    "# gamma = 1\n",
    "# gamma = 2\n",
    "# gamma = 2.5\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cb69a112d34dd5b5078d16a2b09c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    return compute_gradient(y, tx, w)\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    batches = batch_iter(y, tx, batch_size, max_iters)\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        yb, txb = next(batches)\n",
    "        loss = compute_loss(yb, txb, w)\n",
    "        gradient = compute_stoch_gradient(yb, txb, w)\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=1535.0233762859084, w0=5.540800260406268, w1=-4.802345087307414\n",
      "SGD iter. 1/49: loss=3067.576411487092, w0=13.373521896577302, w1=-0.8330161614799794\n",
      "SGD iter. 2/49: loss=1042.728672349076, w0=17.9402026875875, w1=-4.801463591421773\n",
      "SGD iter. 3/49: loss=3480.751123722016, w0=26.28376442550497, w1=7.627872317822676\n",
      "SGD iter. 4/49: loss=795.7944475257051, w0=30.273236690167817, w1=2.7026046824979346\n",
      "SGD iter. 5/49: loss=558.4472109381431, w0=33.61523373067561, w1=1.1418641208034996\n",
      "SGD iter. 6/49: loss=388.89190458200517, w0=36.4041112990963, w1=0.5082927611267903\n",
      "SGD iter. 7/49: loss=1203.8715529585559, w0=41.31098719513964, w1=1.3561586047249476\n",
      "SGD iter. 8/49: loss=783.88709140985, w0=45.27050002226837, w1=-0.3125016999785162\n",
      "SGD iter. 9/49: loss=1635.1865340247873, w0=50.98921759533454, w1=8.609485634850884\n",
      "SGD iter. 10/49: loss=350.63500027119494, w0=53.637367894208055, w1=11.11993399867346\n",
      "SGD iter. 11/49: loss=230.46270024118832, w0=55.78428522024177, w1=14.596499963788126\n",
      "SGD iter. 12/49: loss=182.28094421811628, w0=57.69363560305848, w1=13.648178414819348\n",
      "SGD iter. 13/49: loss=225.43675758523196, w0=59.817013843435035, w1=17.727929797316158\n",
      "SGD iter. 14/49: loss=354.23388520064356, w0=62.478719631837066, w1=14.718058085169407\n",
      "SGD iter. 15/49: loss=74.3506834396191, w0=63.69815133094628, w1=13.53814696329745\n",
      "SGD iter. 16/49: loss=91.76739389323716, w0=65.0529014473385, w1=13.284317901697424\n",
      "SGD iter. 17/49: loss=27.599528692107704, w0=65.7958621285607, w1=12.971137428953913\n",
      "SGD iter. 18/49: loss=0.06682357606376185, w0=65.75930434524065, w1=12.931771634662397\n",
      "SGD iter. 19/49: loss=0.4705529749363756, w0=65.85631496063262, w1=12.868745010061073\n",
      "SGD iter. 20/49: loss=10.179978166049374, w0=66.30753504365308, w1=11.936313133825893\n",
      "SGD iter. 21/49: loss=36.22187644108272, w0=65.45639608389288, w1=13.271555026313493\n",
      "SGD iter. 22/49: loss=15.051285560129438, w0=66.0050541843549, w1=12.972024714359478\n",
      "SGD iter. 23/49: loss=15.10182273514936, w0=66.55463261797743, w1=13.434952888281604\n",
      "SGD iter. 24/49: loss=10.460991165310316, w0=67.01203815282175, w1=13.949888104955463\n",
      "SGD iter. 25/49: loss=15.627545510128176, w0=67.57110068081174, w1=12.794603263870805\n",
      "SGD iter. 26/49: loss=56.65004869602288, w0=68.63552586555723, w1=12.620229556129512\n",
      "SGD iter. 27/49: loss=4.032838176089824, w0=68.91952720978256, w1=13.124068244444755\n",
      "SGD iter. 28/49: loss=6.9125322145153305, w0=68.54770649453083, w1=13.15383349151087\n",
      "SGD iter. 29/49: loss=77.94184561525486, w0=69.79624039967922, w1=13.364747070353255\n",
      "SGD iter. 30/49: loss=2.0293333289261986, w0=69.59477907192989, w1=13.237130853659947\n",
      "SGD iter. 31/49: loss=0.7224129151280736, w0=69.714979980007, w1=13.178572047868606\n",
      "SGD iter. 32/49: loss=0.025879392926192245, w0=69.73773053733036, w1=13.14708956360719\n",
      "SGD iter. 33/49: loss=34.01242926656215, w0=70.56250237567794, w1=12.393513256793984\n",
      "SGD iter. 34/49: loss=73.60333765658322, w0=71.77578995623404, w1=11.33427752443245\n",
      "SGD iter. 35/49: loss=5.302051702886896, w0=71.45015053285637, w1=11.720163043702454\n",
      "SGD iter. 36/49: loss=12.927096484737033, w0=71.95862071850617, w1=11.899100966316484\n",
      "SGD iter. 37/49: loss=4.548471188763083, w0=71.65700933978304, w1=12.325707737735332\n",
      "SGD iter. 38/49: loss=8.977530777506573, w0=72.08074347287847, w1=13.00769115687155\n",
      "SGD iter. 39/49: loss=1.765667122095143, w0=71.8928250266261, w1=13.217541533227926\n",
      "SGD iter. 40/49: loss=13.510646603311873, w0=72.4126451224922, w1=13.513881276218358\n",
      "SGD iter. 41/49: loss=8.860682250234781, w0=72.83361263312062, w1=13.905656880288507\n",
      "SGD iter. 42/49: loss=0.002344199295754428, w0=72.84045982129645, w1=13.910963714784192\n",
      "SGD iter. 43/49: loss=6.321345750846941, w0=72.48489419441874, w1=13.403373696353427\n",
      "SGD iter. 44/49: loss=9.37677531640529, w0=72.91794789354635, w1=13.814946104112964\n",
      "SGD iter. 45/49: loss=1.0482231777727806, w0=72.77315679038233, w1=13.843127395646635\n",
      "SGD iter. 46/49: loss=15.782883940069105, w0=73.33499099973717, w1=13.84521550440956\n",
      "SGD iter. 47/49: loss=8.730610979406565, w0=73.75285726971853, w1=13.935358048831626\n",
      "SGD iter. 48/49: loss=21.90053231008665, w0=73.09103354227916, w1=13.925726758737111\n",
      "SGD iter. 49/49: loss=0.058411488478794765, w0=73.05685416590136, w1=13.974391724555824\n",
      "SGD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5b4fe101e54f20a5ea4796d0fab3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200, 2))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2829.2722244384163, w0=51.54259072181176, w1=10.132993413506084\n",
      "GD iter. 1/49: loss=267.0500258779429, w0=67.0053679383553, w1=13.172891437557825\n",
      "GD iter. 2/49: loss=36.45002800750046, w0=71.64420110331838, w1=14.084860844773322\n",
      "GD iter. 3/49: loss=15.696028199160635, w0=73.03585105280729, w1=14.358451666937965\n",
      "GD iter. 4/49: loss=13.828168216410077, w0=73.45334603765397, w1=14.440528913587356\n",
      "GD iter. 5/49: loss=13.660060817962522, w0=73.57859453310797, w1=14.46515208758217\n",
      "GD iter. 6/49: loss=13.644931152102243, w0=73.61616908174418, w1=14.472539039780616\n",
      "GD iter. 7/49: loss=13.643569482174817, w0=73.62744144633503, w1=14.474755125440149\n",
      "GD iter. 8/49: loss=13.643446931881353, w0=73.63082315571229, w1=14.47541995113801\n",
      "GD iter. 9/49: loss=13.643435902354941, w0=73.63183766852546, w1=14.475619398847368\n",
      "GD iter. 10/49: loss=13.643434909697561, w0=73.63214202236942, w1=14.475679233160175\n",
      "GD iter. 11/49: loss=13.643434820358397, w0=73.6322333285226, w1=14.475697183454017\n",
      "GD iter. 12/49: loss=13.643434812317876, w0=73.63226072036856, w1=14.47570256854217\n",
      "GD iter. 13/49: loss=13.64343481159423, w0=73.63226893792235, w1=14.475704184068615\n",
      "GD iter. 14/49: loss=13.643434811529096, w0=73.63227140318848, w1=14.475704668726548\n",
      "GD iter. 15/49: loss=13.643434811523235, w0=73.63227214276833, w1=14.47570481412393\n",
      "GD iter. 16/49: loss=13.643434811522708, w0=73.63227236464228, w1=14.475704857743143\n",
      "GD iter. 17/49: loss=13.64343481152266, w0=73.63227243120446, w1=14.475704870828908\n",
      "GD iter. 18/49: loss=13.643434811522656, w0=73.63227245117312, w1=14.475704874754637\n",
      "GD iter. 19/49: loss=13.643434811522656, w0=73.63227245716372, w1=14.475704875932356\n",
      "GD iter. 20/49: loss=13.643434811522653, w0=73.6322724589609, w1=14.475704876285672\n",
      "GD iter. 21/49: loss=13.643434811522656, w0=73.63227245950004, w1=14.475704876391665\n",
      "GD iter. 22/49: loss=13.643434811522656, w0=73.63227245966179, w1=14.475704876423464\n",
      "GD iter. 23/49: loss=13.643434811522654, w0=73.63227245971032, w1=14.475704876433003\n",
      "GD iter. 24/49: loss=13.643434811522656, w0=73.63227245972487, w1=14.475704876435865\n",
      "GD iter. 25/49: loss=13.643434811522656, w0=73.63227245972924, w1=14.475704876436724\n",
      "GD iter. 26/49: loss=13.643434811522654, w0=73.63227245973054, w1=14.475704876436982\n",
      "GD iter. 27/49: loss=13.643434811522654, w0=73.63227245973094, w1=14.47570487643706\n",
      "GD iter. 28/49: loss=13.643434811522656, w0=73.63227245973106, w1=14.475704876437083\n",
      "GD iter. 29/49: loss=13.643434811522656, w0=73.6322724597311, w1=14.475704876437089\n",
      "GD iter. 30/49: loss=13.643434811522656, w0=73.63227245973111, w1=14.47570487643709\n",
      "GD iter. 31/49: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 32/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 33/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 34/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 35/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 36/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 37/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 38/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 39/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 40/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 41/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 42/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 43/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 44/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 45/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 46/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 47/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 48/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 49/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a2ac9fd0b443c3b6969ec202c75cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    loss = 1 / (2 * N) * np.sum(np.abs(y - tx.dot(w)))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = y - tx.dot(w)\n",
    "    subgradient = -1 / N * tx.T.dot(np.sign(e))\n",
    "    return subgradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        subgradient = compute_subgradient_mae(y, tx, w)\n",
    "\n",
    "        w = w - gamma * subgradient\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=36.81613622986557, w0=0.7, w1=1.6895373988745632e-15\n",
      "SubGD iter. 1/499: loss=36.46613622986557, w0=1.4, w1=3.3790747977491264e-15\n",
      "SubGD iter. 2/499: loss=36.116136229865575, w0=2.0999999999999996, w1=5.068612196623689e-15\n",
      "SubGD iter. 3/499: loss=35.76613622986558, w0=2.8, w1=6.758149595498253e-15\n",
      "SubGD iter. 4/499: loss=35.41613622986557, w0=3.5, w1=8.447686994372816e-15\n",
      "SubGD iter. 5/499: loss=35.06613622986557, w0=4.2, w1=1.013722439324738e-14\n",
      "SubGD iter. 6/499: loss=34.716136229865576, w0=4.9, w1=1.1826761792121944e-14\n",
      "SubGD iter. 7/499: loss=34.366136229865575, w0=5.6000000000000005, w1=1.3516299190996507e-14\n",
      "SubGD iter. 8/499: loss=34.01613622986557, w0=6.300000000000001, w1=1.520583658987107e-14\n",
      "SubGD iter. 9/499: loss=33.66613622986557, w0=7.000000000000001, w1=1.6895373988745633e-14\n",
      "SubGD iter. 10/499: loss=33.31613622986558, w0=7.700000000000001, w1=1.8584911387620195e-14\n",
      "SubGD iter. 11/499: loss=32.96613622986557, w0=8.4, w1=2.0274448786494757e-14\n",
      "SubGD iter. 12/499: loss=32.61613622986557, w0=9.1, w1=2.196398618536932e-14\n",
      "SubGD iter. 13/499: loss=32.26613622986557, w0=9.799999999999999, w1=2.365352358424388e-14\n",
      "SubGD iter. 14/499: loss=31.91613622986558, w0=10.499999999999998, w1=2.5343060983118443e-14\n",
      "SubGD iter. 15/499: loss=31.566136229865574, w0=11.199999999999998, w1=2.7032598381993005e-14\n",
      "SubGD iter. 16/499: loss=31.216136229865576, w0=11.899999999999997, w1=2.872213578086757e-14\n",
      "SubGD iter. 17/499: loss=30.866136229865578, w0=12.599999999999996, w1=3.0411673179742136e-14\n",
      "SubGD iter. 18/499: loss=30.51613622986558, w0=13.299999999999995, w1=3.21012105786167e-14\n",
      "SubGD iter. 19/499: loss=30.16613622986558, w0=13.999999999999995, w1=3.3790747977491266e-14\n",
      "SubGD iter. 20/499: loss=29.816136229865577, w0=14.699999999999994, w1=3.548028537636583e-14\n",
      "SubGD iter. 21/499: loss=29.46613622986558, w0=15.399999999999993, w1=3.7169822775240396e-14\n",
      "SubGD iter. 22/499: loss=29.116136229865578, w0=16.099999999999994, w1=3.885936017411496e-14\n",
      "SubGD iter. 23/499: loss=28.76613622986558, w0=16.799999999999994, w1=4.0548897572989527e-14\n",
      "SubGD iter. 24/499: loss=28.41613622986558, w0=17.499999999999993, w1=4.223843497186409e-14\n",
      "SubGD iter. 25/499: loss=28.066136229865577, w0=18.199999999999992, w1=4.392797237073866e-14\n",
      "SubGD iter. 26/499: loss=27.71613622986558, w0=18.89999999999999, w1=4.561750976961322e-14\n",
      "SubGD iter. 27/499: loss=27.366136229865578, w0=19.59999999999999, w1=4.730704716848779e-14\n",
      "SubGD iter. 28/499: loss=27.01613622986558, w0=20.29999999999999, w1=4.899658456736235e-14\n",
      "SubGD iter. 29/499: loss=26.66613622986558, w0=20.99999999999999, w1=5.068612196623692e-14\n",
      "SubGD iter. 30/499: loss=26.316136229865577, w0=21.69999999999999, w1=5.237565936511148e-14\n",
      "SubGD iter. 31/499: loss=25.96613622986558, w0=22.399999999999988, w1=5.406519676398605e-14\n",
      "SubGD iter. 32/499: loss=25.616136229865578, w0=23.099999999999987, w1=5.5754734162860613e-14\n",
      "SubGD iter. 33/499: loss=25.266136229865587, w0=23.799999999999986, w1=5.744427156173518e-14\n",
      "SubGD iter. 34/499: loss=24.916136229865582, w0=24.499999999999986, w1=5.913380896060974e-14\n",
      "SubGD iter. 35/499: loss=24.566136229865585, w0=25.199999999999985, w1=6.08233463594843e-14\n",
      "SubGD iter. 36/499: loss=24.216136229865583, w0=25.899999999999984, w1=6.251288375835886e-14\n",
      "SubGD iter. 37/499: loss=23.866136229865585, w0=26.599999999999984, w1=6.420242115723341e-14\n",
      "SubGD iter. 38/499: loss=23.516136229865584, w0=27.299999999999983, w1=6.589195855610797e-14\n",
      "SubGD iter. 39/499: loss=23.166136229865582, w0=27.999999999999982, w1=6.758149595498253e-14\n",
      "SubGD iter. 40/499: loss=22.816136229865585, w0=28.69999999999998, w1=6.927103335385709e-14\n",
      "SubGD iter. 41/499: loss=22.466136229865587, w0=29.39999999999998, w1=7.096057075273165e-14\n",
      "SubGD iter. 42/499: loss=22.11613622986559, w0=30.09999999999998, w1=7.265010815160621e-14\n",
      "SubGD iter. 43/499: loss=21.766136229865584, w0=30.79999999999998, w1=7.433964555048077e-14\n",
      "SubGD iter. 44/499: loss=21.416136229865582, w0=31.49999999999998, w1=7.602918294935533e-14\n",
      "SubGD iter. 45/499: loss=21.066136229865588, w0=32.19999999999998, w1=7.771872034822989e-14\n",
      "SubGD iter. 46/499: loss=20.716136229865583, w0=32.899999999999984, w1=7.940825774710444e-14\n",
      "SubGD iter. 47/499: loss=20.366136229865585, w0=33.59999999999999, w1=8.1097795145979e-14\n",
      "SubGD iter. 48/499: loss=20.016136229865584, w0=34.29999999999999, w1=8.278733254485356e-14\n",
      "SubGD iter. 49/499: loss=19.66613622986558, w0=34.99999999999999, w1=8.447686994372812e-14\n",
      "SubGD iter. 50/499: loss=19.316136229865577, w0=35.699999999999996, w1=8.616640734260268e-14\n",
      "SubGD iter. 51/499: loss=18.966136229865576, w0=36.4, w1=8.785594474147724e-14\n",
      "SubGD iter. 52/499: loss=18.616136229865575, w0=37.1, w1=8.95454821403518e-14\n",
      "SubGD iter. 53/499: loss=18.266136229865573, w0=37.800000000000004, w1=9.123501953922636e-14\n",
      "SubGD iter. 54/499: loss=17.916136229865575, w0=38.50000000000001, w1=9.292455693810092e-14\n",
      "SubGD iter. 55/499: loss=17.56613622986557, w0=39.20000000000001, w1=9.461409433697547e-14\n",
      "SubGD iter. 56/499: loss=17.21613622986557, w0=39.90000000000001, w1=9.630363173585003e-14\n",
      "SubGD iter. 57/499: loss=16.86613622986557, w0=40.600000000000016, w1=9.799316913472459e-14\n",
      "SubGD iter. 58/499: loss=16.516136229865566, w0=41.30000000000002, w1=9.968270653359915e-14\n",
      "SubGD iter. 59/499: loss=16.166136229865565, w0=42.00000000000002, w1=1.0137224393247371e-13\n",
      "SubGD iter. 60/499: loss=15.816136229865563, w0=42.700000000000024, w1=1.0306178133134827e-13\n",
      "SubGD iter. 61/499: loss=15.466136229865564, w0=43.40000000000003, w1=1.0475131873022283e-13\n",
      "SubGD iter. 62/499: loss=15.11613622986556, w0=44.10000000000003, w1=1.0644085612909739e-13\n",
      "SubGD iter. 63/499: loss=14.76613622986556, w0=44.80000000000003, w1=1.0813039352797195e-13\n",
      "SubGD iter. 64/499: loss=14.416136229865556, w0=45.500000000000036, w1=1.098199309268465e-13\n",
      "SubGD iter. 65/499: loss=14.066136229865556, w0=46.20000000000004, w1=1.1150946832572106e-13\n",
      "SubGD iter. 66/499: loss=13.716136229865556, w0=46.90000000000004, w1=1.1319900572459562e-13\n",
      "SubGD iter. 67/499: loss=13.368895729010555, w0=47.59300000000004, w1=0.012822729222841382\n",
      "SubGD iter. 68/499: loss=13.027516832739124, w0=48.27900000000004, w1=0.038067565076886134\n",
      "SubGD iter. 69/499: loss=12.690921617212485, w0=48.96500000000004, w1=0.06331240093093088\n",
      "SubGD iter. 70/499: loss=12.359552562791006, w0=49.63000000000004, w1=0.12140253076845677\n",
      "SubGD iter. 71/499: loss=12.043560503034099, w0=50.28800000000004, w1=0.19295915708008177\n",
      "SubGD iter. 72/499: loss=11.730643109627595, w0=50.94600000000004, w1=0.2645157833917068\n",
      "SubGD iter. 73/499: loss=11.42162857431239, w0=51.59000000000004, w1=0.36003710381024834\n",
      "SubGD iter. 74/499: loss=11.120560981259002, w0=52.22000000000004, w1=0.47488016550951173\n",
      "SubGD iter. 75/499: loss=10.827643027472178, w0=52.84300000000004, w1=0.6005235649987757\n",
      "SubGD iter. 76/499: loss=10.53969791636455, w0=53.45900000000004, w1=0.735466325292315\n",
      "SubGD iter. 77/499: loss=10.257422942905814, w0=54.06800000000004, w1=0.8798253451603716\n",
      "SubGD iter. 78/499: loss=9.980562658812977, w0=54.66300000000004, w1=1.0417652853159167\n",
      "SubGD iter. 79/499: loss=9.708955841514705, w0=55.25800000000004, w1=1.2037052254714617\n",
      "SubGD iter. 80/499: loss=9.439118455397258, w0=55.83900000000004, w1=1.3822638190738608\n",
      "SubGD iter. 81/499: loss=9.176728298781343, w0=56.41300000000004, w1=1.5664626351241284\n",
      "SubGD iter. 82/499: loss=8.922026169948287, w0=56.95200000000004, w1=1.7871599649710128\n",
      "SubGD iter. 83/499: loss=8.680858096788311, w0=57.48400000000004, w1=2.013835121218472\n",
      "SubGD iter. 84/499: loss=8.441996935031305, w0=58.016000000000034, w1=2.240510277465931\n",
      "SubGD iter. 85/499: loss=8.206806751325324, w0=58.513000000000034, w1=2.4977608864129537\n",
      "SubGD iter. 86/499: loss=7.983101840037027, w0=59.01000000000003, w1=2.7550114953599762\n",
      "SubGD iter. 87/499: loss=7.761553426065862, w0=59.49300000000003, w1=3.019114299724235\n",
      "SubGD iter. 88/499: loss=7.545096789442245, w0=59.97600000000003, w1=3.2832171040884934\n",
      "SubGD iter. 89/499: loss=7.330292620993735, w0=60.45200000000003, w1=3.5478129339056244\n",
      "SubGD iter. 90/499: loss=7.11986651541864, w0=60.89300000000003, w1=3.842709112855987\n",
      "SubGD iter. 91/499: loss=6.920133722350442, w0=61.32000000000003, w1=4.148442254175186\n",
      "SubGD iter. 92/499: loss=6.723448350630483, w0=61.74000000000003, w1=4.458787226613845\n",
      "SubGD iter. 93/499: loss=6.5286526349748035, w0=62.16000000000003, w1=4.769132199052504\n",
      "SubGD iter. 94/499: loss=6.333856919319121, w0=62.580000000000034, w1=5.079477171491163\n",
      "SubGD iter. 95/499: loss=6.141359949530738, w0=62.979000000000035, w1=5.401328404320427\n",
      "SubGD iter. 96/499: loss=5.954870014981918, w0=63.37100000000004, w1=5.725928703251706\n",
      "SubGD iter. 97/499: loss=5.7702191232852, w0=63.74900000000004, w1=6.061744039727748\n",
      "SubGD iter. 98/499: loss=5.58774605156699, w0=64.12000000000003, w1=6.401747716728324\n",
      "SubGD iter. 99/499: loss=5.406857837014197, w0=64.49100000000003, w1=6.7417513937289\n",
      "SubGD iter. 100/499: loss=5.226593886451517, w0=64.87600000000003, w1=7.061378131166487\n",
      "SubGD iter. 101/499: loss=5.048961268917558, w0=65.24700000000003, w1=7.387523593880775\n",
      "SubGD iter. 102/499: loss=4.874667081168191, w0=65.61800000000002, w1=7.713669056595062\n",
      "SubGD iter. 103/499: loss=4.700620867537106, w0=65.98200000000003, w1=8.040435506798637\n",
      "SubGD iter. 104/499: loss=4.530324710460103, w0=66.34600000000003, w1=8.353859837656561\n",
      "SubGD iter. 105/499: loss=4.366001637137887, w0=66.71700000000003, w1=8.65351368365696\n",
      "SubGD iter. 106/499: loss=4.204790120974009, w0=67.08100000000003, w1=8.955524223771478\n",
      "SubGD iter. 107/499: loss=4.045351133126419, w0=67.43800000000003, w1=9.254985017110517\n",
      "SubGD iter. 108/499: loss=3.8906628809661257, w0=67.78100000000003, w1=9.560846653934009\n",
      "SubGD iter. 109/499: loss=3.74189806381343, w0=68.11700000000003, w1=9.860337267127171\n",
      "SubGD iter. 110/499: loss=3.5999003575386963, w0=68.43200000000003, w1=10.156521139455217\n",
      "SubGD iter. 111/499: loss=3.4666319394831033, w0=68.74700000000003, w1=10.4444534773485\n",
      "SubGD iter. 112/499: loss=3.3390603205815435, w0=69.03400000000003, w1=10.743406876764555\n",
      "SubGD iter. 113/499: loss=3.217581218266177, w0=69.31400000000004, w1=11.038005391074643\n",
      "SubGD iter. 114/499: loss=3.10229940532159, w0=69.59400000000004, w1=11.313287847901137\n",
      "SubGD iter. 115/499: loss=2.994561579893026, w0=69.86700000000003, w1=11.578413278202857\n",
      "SubGD iter. 116/499: loss=2.8911183700411174, w0=70.14000000000003, w1=11.843538708504578\n",
      "SubGD iter. 117/499: loss=2.7887985194735485, w0=70.39900000000003, w1=12.104101240231266\n",
      "SubGD iter. 118/499: loss=2.6928810754448835, w0=70.65100000000002, w1=12.36722983468919\n",
      "SubGD iter. 119/499: loss=2.598863942414504, w0=70.90300000000002, w1=12.607410619209137\n",
      "SubGD iter. 120/499: loss=2.5143245428520533, w0=71.14800000000002, w1=12.829819894660064\n",
      "SubGD iter. 121/499: loss=2.437535320856304, w0=71.37900000000002, w1=13.051299546685483\n",
      "SubGD iter. 122/499: loss=2.3675148779407174, w0=71.59600000000002, w1=13.253978279130138\n",
      "SubGD iter. 123/499: loss=2.3073779913729906, w0=71.80600000000001, w1=13.44375255576235\n",
      "SubGD iter. 124/499: loss=2.2536064040743717, w0=71.98100000000001, w1=13.60001256733914\n",
      "SubGD iter. 125/499: loss=2.220587815253969, w0=72.12100000000001, w1=13.709638751573966\n",
      "SubGD iter. 126/499: loss=2.1980635981472934, w0=72.254, w1=13.823710297553676\n",
      "SubGD iter. 127/499: loss=2.1786427247099396, w0=72.35900000000001, w1=13.928950177753503\n",
      "SubGD iter. 128/499: loss=2.1631878129815134, w0=72.45700000000001, w1=14.033063640618654\n",
      "SubGD iter. 129/499: loss=2.1502149013843197, w0=72.534, w1=14.118590076651586\n",
      "SubGD iter. 130/499: loss=2.14075506476968, w0=72.611, w1=14.204116512684518\n",
      "SubGD iter. 131/499: loss=2.132372238071067, w0=72.667, w1=14.26236232246874\n",
      "SubGD iter. 132/499: loss=2.127777139991264, w0=72.71600000000001, w1=14.312508189781902\n",
      "SubGD iter. 133/499: loss=2.1242659914137, w0=72.76500000000001, w1=14.362654057095064\n",
      "SubGD iter. 134/499: loss=2.1207548428361362, w0=72.81400000000002, w1=14.412799924408226\n",
      "SubGD iter. 135/499: loss=2.117243694258572, w0=72.86300000000003, w1=14.462945791721388\n",
      "SubGD iter. 136/499: loss=2.1138239756190718, w0=72.91900000000003, w1=14.500669552403235\n",
      "SubGD iter. 137/499: loss=2.110969763400801, w0=72.96100000000003, w1=14.528246426173618\n",
      "SubGD iter. 138/499: loss=2.1091676114250264, w0=73.01000000000003, w1=14.543000570721277\n",
      "SubGD iter. 139/499: loss=2.1074822070518837, w0=73.04500000000003, w1=14.568377913364856\n",
      "SubGD iter. 140/499: loss=2.106408530569614, w0=73.07300000000004, w1=14.586058146365032\n",
      "SubGD iter. 141/499: loss=2.1056252515417997, w0=73.10100000000004, w1=14.603738379365208\n",
      "SubGD iter. 142/499: loss=2.104841972513985, w0=73.12900000000005, w1=14.621418612365384\n",
      "SubGD iter. 143/499: loss=2.1040731169972338, w0=73.16400000000004, w1=14.626276116142835\n",
      "SubGD iter. 144/499: loss=2.1034907670679983, w0=73.18500000000004, w1=14.637490968842995\n",
      "SubGD iter. 145/499: loss=2.1030859292672224, w0=73.20600000000005, w1=14.648705821543155\n",
      "SubGD iter. 146/499: loss=2.1026810914664464, w0=73.22700000000005, w1=14.659920674243315\n",
      "SubGD iter. 147/499: loss=2.1022762536656705, w0=73.24800000000005, w1=14.671135526943475\n",
      "SubGD iter. 148/499: loss=2.1018714158648946, w0=73.26900000000005, w1=14.682350379643635\n",
      "SubGD iter. 149/499: loss=2.101466578064119, w0=73.29000000000005, w1=14.693565232343795\n",
      "SubGD iter. 150/499: loss=2.101083597084562, w0=73.30400000000004, w1=14.703897822273019\n",
      "SubGD iter. 151/499: loss=2.1009686262115266, w0=73.30400000000004, w1=14.699292575283707\n",
      "SubGD iter. 152/499: loss=2.1009879158926834, w0=73.30400000000004, w1=14.71264121692517\n",
      "SubGD iter. 153/499: loss=2.1009973872771677, w0=73.30400000000004, w1=14.708035969935858\n",
      "SubGD iter. 154/499: loss=2.1009822384915733, w0=73.30400000000004, w1=14.703430722946546\n",
      "SubGD iter. 155/499: loss=2.100968696408385, w0=73.31100000000005, w1=14.704357257956694\n",
      "SubGD iter. 156/499: loss=2.100976679730035, w0=73.30400000000004, w1=14.712174117598698\n",
      "SubGD iter. 157/499: loss=2.10099585077162, w0=73.30400000000004, w1=14.707568870609386\n",
      "SubGD iter. 158/499: loss=2.100980701986025, w0=73.30400000000004, w1=14.702963623620073\n",
      "SubGD iter. 159/499: loss=2.100969005539727, w0=73.31100000000005, w1=14.703890158630221\n",
      "SubGD iter. 160/499: loss=2.10097928776566, w0=73.30400000000004, w1=14.711707018272225\n",
      "SubGD iter. 161/499: loss=2.1009943142660723, w0=73.30400000000004, w1=14.707101771282913\n",
      "SubGD iter. 162/499: loss=2.1009791654804775, w0=73.30400000000004, w1=14.7024965242936\n",
      "SubGD iter. 163/499: loss=2.1009693146710693, w0=73.31100000000005, w1=14.703423059303748\n",
      "SubGD iter. 164/499: loss=2.1009818958012834, w0=73.30400000000004, w1=14.711239918945752\n",
      "SubGD iter. 165/499: loss=2.1009927777605246, w0=73.30400000000004, w1=14.70663467195644\n",
      "SubGD iter. 166/499: loss=2.10097762897493, w0=73.30400000000004, w1=14.702029424967128\n",
      "SubGD iter. 167/499: loss=2.1009696238024116, w0=73.31100000000005, w1=14.702955959977276\n",
      "SubGD iter. 168/499: loss=2.1009845038369077, w0=73.30400000000004, w1=14.71077281961928\n",
      "SubGD iter. 169/499: loss=2.1009912412549765, w0=73.30400000000004, w1=14.706167572629967\n",
      "SubGD iter. 170/499: loss=2.100976092469382, w0=73.30400000000004, w1=14.701562325640655\n",
      "SubGD iter. 171/499: loss=2.1009699329337534, w0=73.31100000000005, w1=14.702488860650803\n",
      "SubGD iter. 172/499: loss=2.100987111872532, w0=73.30400000000004, w1=14.710305720292807\n",
      "SubGD iter. 173/499: loss=2.100989704749429, w0=73.30400000000004, w1=14.705700473303494\n",
      "SubGD iter. 174/499: loss=2.1009745559638344, w0=73.30400000000004, w1=14.701095226314182\n",
      "SubGD iter. 175/499: loss=2.100970728076533, w0=73.30400000000004, w1=14.714443867955646\n",
      "SubGD iter. 176/499: loss=2.101003317029476, w0=73.30400000000004, w1=14.709838620966334\n",
      "SubGD iter. 177/499: loss=2.100988168243881, w0=73.30400000000004, w1=14.705233373977022\n",
      "SubGD iter. 178/499: loss=2.1009730194582867, w0=73.30400000000004, w1=14.70062812698771\n",
      "SubGD iter. 179/499: loss=2.1009751817490474, w0=73.30400000000004, w1=14.713976768629173\n",
      "SubGD iter. 180/499: loss=2.101001780523928, w0=73.30400000000004, w1=14.709371521639861\n",
      "SubGD iter. 181/499: loss=2.1009866317383334, w0=73.30400000000004, w1=14.704766274650549\n",
      "SubGD iter. 182/499: loss=2.100971482952738, w0=73.30400000000004, w1=14.700161027661236\n",
      "SubGD iter. 183/499: loss=2.1009796354215617, w0=73.30400000000004, w1=14.7135096693027\n",
      "SubGD iter. 184/499: loss=2.1010002440183797, w0=73.30400000000004, w1=14.708904422313388\n",
      "SubGD iter. 185/499: loss=2.1009850952327853, w0=73.30400000000004, w1=14.704299175324076\n",
      "SubGD iter. 186/499: loss=2.100969946447191, w0=73.30400000000004, w1=14.699693928334764\n",
      "SubGD iter. 187/499: loss=2.1009840890940756, w0=73.30400000000004, w1=14.713042569976228\n",
      "SubGD iter. 188/499: loss=2.100998707512832, w0=73.30400000000004, w1=14.708437322986915\n",
      "SubGD iter. 189/499: loss=2.1009835587272376, w0=73.30400000000004, w1=14.703832075997603\n",
      "SubGD iter. 190/499: loss=2.1009684307886327, w0=73.31100000000005, w1=14.704758611007751\n",
      "SubGD iter. 191/499: loss=2.1009744387868445, w0=73.30400000000004, w1=14.712575470649755\n",
      "SubGD iter. 192/499: loss=2.1009971710072843, w0=73.30400000000004, w1=14.707970223660443\n",
      "SubGD iter. 193/499: loss=2.1009820222216895, w0=73.30400000000004, w1=14.70336497667113\n",
      "SubGD iter. 194/499: loss=2.1009687399199746, w0=73.31100000000005, w1=14.704291511681278\n",
      "SubGD iter. 195/499: loss=2.100977046822469, w0=73.30400000000004, w1=14.712108371323282\n",
      "SubGD iter. 196/499: loss=2.1009956345017367, w0=73.30400000000004, w1=14.70750312433397\n",
      "SubGD iter. 197/499: loss=2.100980485716142, w0=73.30400000000004, w1=14.702897877344657\n",
      "SubGD iter. 198/499: loss=2.100969049051317, w0=73.31100000000005, w1=14.703824412354805\n",
      "SubGD iter. 199/499: loss=2.1009796548580932, w0=73.30400000000004, w1=14.71164127199681\n",
      "SubGD iter. 200/499: loss=2.100994097996189, w0=73.30400000000004, w1=14.707036025007497\n",
      "SubGD iter. 201/499: loss=2.100978949210594, w0=73.30400000000004, w1=14.702430778018185\n",
      "SubGD iter. 202/499: loss=2.1009693581826596, w0=73.31100000000005, w1=14.703357313028333\n",
      "SubGD iter. 203/499: loss=2.100982262893717, w0=73.30400000000004, w1=14.711174172670336\n",
      "SubGD iter. 204/499: loss=2.1009925614906413, w0=73.30400000000004, w1=14.706568925681024\n",
      "SubGD iter. 205/499: loss=2.100977412705046, w0=73.30400000000004, w1=14.701963678691712\n",
      "SubGD iter. 206/499: loss=2.100969667314002, w0=73.31100000000005, w1=14.70289021370186\n",
      "SubGD iter. 207/499: loss=2.1009848709293415, w0=73.30400000000004, w1=14.710707073343864\n",
      "SubGD iter. 208/499: loss=2.100991024985093, w0=73.30400000000004, w1=14.706101826354551\n",
      "SubGD iter. 209/499: loss=2.1009758761994983, w0=73.30400000000004, w1=14.701496579365239\n",
      "SubGD iter. 210/499: loss=2.100969976445344, w0=73.31100000000005, w1=14.702423114375387\n",
      "SubGD iter. 211/499: loss=2.1009874789649663, w0=73.30400000000004, w1=14.71023997401739\n",
      "SubGD iter. 212/499: loss=2.100989488479545, w0=73.30400000000004, w1=14.705634727028079\n",
      "SubGD iter. 213/499: loss=2.10097433969395, w0=73.30400000000004, w1=14.701029480038766\n",
      "SubGD iter. 214/499: loss=2.1009713549504405, w0=73.30400000000004, w1=14.71437812168023\n",
      "SubGD iter. 215/499: loss=2.101003100759592, w0=73.30400000000004, w1=14.709772874690918\n",
      "SubGD iter. 216/499: loss=2.1009879519739973, w0=73.30400000000004, w1=14.705167627701606\n",
      "SubGD iter. 217/499: loss=2.1009728031884025, w0=73.30400000000004, w1=14.700562380712293\n",
      "SubGD iter. 218/499: loss=2.1009758086229544, w0=73.30400000000004, w1=14.713911022353757\n",
      "SubGD iter. 219/499: loss=2.1010015642540445, w0=73.30400000000004, w1=14.709305775364445\n",
      "SubGD iter. 220/499: loss=2.10098641546845, w0=73.30400000000004, w1=14.704700528375133\n",
      "SubGD iter. 221/499: loss=2.1009712666828553, w0=73.30400000000004, w1=14.70009528138582\n",
      "SubGD iter. 222/499: loss=2.1009802622954687, w0=73.30400000000004, w1=14.713443923027285\n",
      "SubGD iter. 223/499: loss=2.101000027748497, w0=73.30400000000004, w1=14.708838676037972\n",
      "SubGD iter. 224/499: loss=2.100984878962902, w0=73.30400000000004, w1=14.70423342904866\n",
      "SubGD iter. 225/499: loss=2.1009697301773076, w0=73.30400000000004, w1=14.699628182059348\n",
      "SubGD iter. 226/499: loss=2.1009847159679826, w0=73.30400000000004, w1=14.712976823700812\n",
      "SubGD iter. 227/499: loss=2.1009984912429487, w0=73.30400000000004, w1=14.7083715767115\n",
      "SubGD iter. 228/499: loss=2.100983342457354, w0=73.30400000000004, w1=14.703766329722187\n",
      "SubGD iter. 229/499: loss=2.1009684743002226, w0=73.31100000000005, w1=14.704692864732335\n",
      "SubGD iter. 230/499: loss=2.1009748058792788, w0=73.30400000000004, w1=14.712509724374339\n",
      "SubGD iter. 231/499: loss=2.100996954737401, w0=73.30400000000004, w1=14.707904477385027\n",
      "SubGD iter. 232/499: loss=2.100981805951806, w0=73.30400000000004, w1=14.703299230395714\n",
      "SubGD iter. 233/499: loss=2.1009687834315645, w0=73.31100000000005, w1=14.704225765405862\n",
      "SubGD iter. 234/499: loss=2.1009774139149027, w0=73.30400000000004, w1=14.712042625047866\n",
      "SubGD iter. 235/499: loss=2.100995418231853, w0=73.30400000000004, w1=14.707437378058554\n",
      "SubGD iter. 236/499: loss=2.100980269446258, w0=73.30400000000004, w1=14.702832131069242\n",
      "SubGD iter. 237/499: loss=2.100969092562907, w0=73.31100000000005, w1=14.70375866607939\n",
      "SubGD iter. 238/499: loss=2.1009800219505266, w0=73.30400000000004, w1=14.711575525721393\n",
      "SubGD iter. 239/499: loss=2.1009938817263047, w0=73.30400000000004, w1=14.706970278732081\n",
      "SubGD iter. 240/499: loss=2.100978732940711, w0=73.30400000000004, w1=14.702365031742769\n",
      "SubGD iter. 241/499: loss=2.1009694016942495, w0=73.31100000000005, w1=14.703291566752917\n",
      "SubGD iter. 242/499: loss=2.100982629986151, w0=73.30400000000004, w1=14.71110842639492\n",
      "SubGD iter. 243/499: loss=2.1009923452207575, w0=73.30400000000004, w1=14.706503179405608\n",
      "SubGD iter. 244/499: loss=2.1009771964351627, w0=73.30400000000004, w1=14.701897932416296\n",
      "SubGD iter. 245/499: loss=2.1009697108255914, w0=73.31100000000005, w1=14.702824467426444\n",
      "SubGD iter. 246/499: loss=2.1009852380217753, w0=73.30400000000004, w1=14.710641327068448\n",
      "SubGD iter. 247/499: loss=2.10099080871521, w0=73.30400000000004, w1=14.706036080079135\n",
      "SubGD iter. 248/499: loss=2.100975659929615, w0=73.30400000000004, w1=14.701430833089823\n",
      "SubGD iter. 249/499: loss=2.1009700199569337, w0=73.31100000000005, w1=14.702357368099971\n",
      "SubGD iter. 250/499: loss=2.100987846057399, w0=73.30400000000004, w1=14.710174227741975\n",
      "SubGD iter. 251/499: loss=2.100989272209662, w0=73.30400000000004, w1=14.705568980752663\n",
      "SubGD iter. 252/499: loss=2.100974123424067, w0=73.30400000000004, w1=14.70096373376335\n",
      "SubGD iter. 253/499: loss=2.1009719818243466, w0=73.30400000000004, w1=14.714312375404814\n",
      "SubGD iter. 254/499: loss=2.101002884489709, w0=73.30400000000004, w1=14.709707128415502\n",
      "SubGD iter. 255/499: loss=2.1009877357041136, w0=73.30400000000004, w1=14.70510188142619\n",
      "SubGD iter. 256/499: loss=2.100972586918519, w0=73.30400000000004, w1=14.700496634436877\n",
      "SubGD iter. 257/499: loss=2.1009764354968614, w0=73.30400000000004, w1=14.713845276078342\n",
      "SubGD iter. 258/499: loss=2.101001347984161, w0=73.30400000000004, w1=14.70924002908903\n",
      "SubGD iter. 259/499: loss=2.1009861991985663, w0=73.30400000000004, w1=14.704634782099717\n",
      "SubGD iter. 260/499: loss=2.1009710504129715, w0=73.30400000000004, w1=14.700029535110405\n",
      "SubGD iter. 261/499: loss=2.1009808891693758, w0=73.30400000000004, w1=14.713378176751869\n",
      "SubGD iter. 262/499: loss=2.100999811478613, w0=73.30400000000004, w1=14.708772929762556\n",
      "SubGD iter. 263/499: loss=2.100984662693018, w0=73.30400000000004, w1=14.704167682773244\n",
      "SubGD iter. 264/499: loss=2.100969513907424, w0=73.30400000000004, w1=14.699562435783932\n",
      "SubGD iter. 265/499: loss=2.1009853428418896, w0=73.30400000000004, w1=14.712911077425396\n",
      "SubGD iter. 266/499: loss=2.100998274973065, w0=73.30400000000004, w1=14.708305830436084\n",
      "SubGD iter. 267/499: loss=2.1009831261874705, w0=73.30400000000004, w1=14.703700583446771\n",
      "SubGD iter. 268/499: loss=2.100968517811812, w0=73.31100000000005, w1=14.70462711845692\n",
      "SubGD iter. 269/499: loss=2.1009751729717117, w0=73.30400000000004, w1=14.712443978098923\n",
      "SubGD iter. 270/499: loss=2.1009967384675177, w0=73.30400000000004, w1=14.70783873110961\n",
      "SubGD iter. 271/499: loss=2.1009815896819224, w0=73.30400000000004, w1=14.703233484120299\n",
      "SubGD iter. 272/499: loss=2.1009688269431543, w0=73.31100000000005, w1=14.704160019130446\n",
      "SubGD iter. 273/499: loss=2.100977781007336, w0=73.30400000000004, w1=14.71197687877245\n",
      "SubGD iter. 274/499: loss=2.10099520196197, w0=73.30400000000004, w1=14.707371631783138\n",
      "SubGD iter. 275/499: loss=2.1009800531763747, w0=73.30400000000004, w1=14.702766384793826\n",
      "SubGD iter. 276/499: loss=2.100969136074497, w0=73.31100000000005, w1=14.703692919803974\n",
      "SubGD iter. 277/499: loss=2.10098038904296, w0=73.30400000000004, w1=14.711509779445977\n",
      "SubGD iter. 278/499: loss=2.100993665456422, w0=73.30400000000004, w1=14.706904532456665\n",
      "SubGD iter. 279/499: loss=2.100978516670827, w0=73.30400000000004, w1=14.702299285467353\n",
      "SubGD iter. 280/499: loss=2.1009694452058394, w0=73.31100000000005, w1=14.7032258204775\n",
      "SubGD iter. 281/499: loss=2.1009829970785843, w0=73.30400000000004, w1=14.711042680119505\n",
      "SubGD iter. 282/499: loss=2.1009921289508737, w0=73.30400000000004, w1=14.706437433130192\n",
      "SubGD iter. 283/499: loss=2.100976980165279, w0=73.30400000000004, w1=14.70183218614088\n",
      "SubGD iter. 284/499: loss=2.1009697543371817, w0=73.31100000000005, w1=14.702758721151028\n",
      "SubGD iter. 285/499: loss=2.1009856051142086, w0=73.30400000000004, w1=14.710575580793032\n",
      "SubGD iter. 286/499: loss=2.100990592445326, w0=73.30400000000004, w1=14.70597033380372\n",
      "SubGD iter. 287/499: loss=2.100975443659731, w0=73.30400000000004, w1=14.701365086814407\n",
      "SubGD iter. 288/499: loss=2.1009700634685236, w0=73.31100000000005, w1=14.702291621824555\n",
      "SubGD iter. 289/499: loss=2.100988213149833, w0=73.30400000000004, w1=14.710108481466559\n",
      "SubGD iter. 290/499: loss=2.100989055939778, w0=73.30400000000004, w1=14.705503234477247\n",
      "SubGD iter. 291/499: loss=2.100973907154184, w0=73.30400000000004, w1=14.700897987487934\n",
      "SubGD iter. 292/499: loss=2.100972608698254, w0=73.30400000000004, w1=14.714246629129399\n",
      "SubGD iter. 293/499: loss=2.101002668219825, w0=73.30400000000004, w1=14.709641382140086\n",
      "SubGD iter. 294/499: loss=2.1009875194342307, w0=73.30400000000004, w1=14.705036135150774\n",
      "SubGD iter. 295/499: loss=2.1009723706486354, w0=73.30400000000004, w1=14.700430888161462\n",
      "SubGD iter. 296/499: loss=2.100977062370768, w0=73.30400000000004, w1=14.713779529802926\n",
      "SubGD iter. 297/499: loss=2.1010011317142774, w0=73.30400000000004, w1=14.709174282813613\n",
      "SubGD iter. 298/499: loss=2.1009859829286825, w0=73.30400000000004, w1=14.704569035824301\n",
      "SubGD iter. 299/499: loss=2.100970834143088, w0=73.30400000000004, w1=14.699963788834989\n",
      "SubGD iter. 300/499: loss=2.1009815160432828, w0=73.30400000000004, w1=14.713312430476453\n",
      "SubGD iter. 301/499: loss=2.1009995952087297, w0=73.30400000000004, w1=14.70870718348714\n",
      "SubGD iter. 302/499: loss=2.100984446423135, w0=73.30400000000004, w1=14.704101936497828\n",
      "SubGD iter. 303/499: loss=2.10096929763754, w0=73.30400000000004, w1=14.699496689508516\n",
      "SubGD iter. 304/499: loss=2.100985969715797, w0=73.30400000000004, w1=14.71284533114998\n",
      "SubGD iter. 305/499: loss=2.1009980587031816, w0=73.30400000000004, w1=14.708240084160668\n",
      "SubGD iter. 306/499: loss=2.1009829099175867, w0=73.30400000000004, w1=14.703634837171355\n",
      "SubGD iter. 307/499: loss=2.100968561323403, w0=73.31100000000005, w1=14.704561372181503\n",
      "SubGD iter. 308/499: loss=2.100975540064145, w0=73.30400000000004, w1=14.712378231823507\n",
      "SubGD iter. 309/499: loss=2.1009965221976334, w0=73.30400000000004, w1=14.707772984834195\n",
      "SubGD iter. 310/499: loss=2.1009813734120395, w0=73.30400000000004, w1=14.703167737844883\n",
      "SubGD iter. 311/499: loss=2.100968870454745, w0=73.31100000000005, w1=14.70409427285503\n",
      "SubGD iter. 312/499: loss=2.1009781480997693, w0=73.30400000000004, w1=14.711911132497034\n",
      "SubGD iter. 313/499: loss=2.100994985692086, w0=73.30400000000004, w1=14.707305885507722\n",
      "SubGD iter. 314/499: loss=2.1009798369064914, w0=73.30400000000004, w1=14.70270063851841\n",
      "SubGD iter. 315/499: loss=2.100969179586087, w0=73.31100000000005, w1=14.703627173528558\n",
      "SubGD iter. 316/499: loss=2.1009807561353937, w0=73.30400000000004, w1=14.711444033170562\n",
      "SubGD iter. 317/499: loss=2.1009934491865385, w0=73.30400000000004, w1=14.70683878618125\n",
      "SubGD iter. 318/499: loss=2.1009783004009432, w0=73.30400000000004, w1=14.702233539191937\n",
      "SubGD iter. 319/499: loss=2.1009694887174293, w0=73.31100000000005, w1=14.703160074202085\n",
      "SubGD iter. 320/499: loss=2.100983364171018, w0=73.30400000000004, w1=14.710976933844089\n",
      "SubGD iter. 321/499: loss=2.1009919126809904, w0=73.30400000000004, w1=14.706371686854776\n",
      "SubGD iter. 322/499: loss=2.1009767638953956, w0=73.30400000000004, w1=14.701766439865464\n",
      "SubGD iter. 323/499: loss=2.1009697978487716, w0=73.31100000000005, w1=14.702692974875612\n",
      "SubGD iter. 324/499: loss=2.1009859722066424, w0=73.30400000000004, w1=14.710509834517616\n",
      "SubGD iter. 325/499: loss=2.1009903761754423, w0=73.30400000000004, w1=14.705904587528304\n",
      "SubGD iter. 326/499: loss=2.100975227389848, w0=73.30400000000004, w1=14.701299340538991\n",
      "SubGD iter. 327/499: loss=2.100970106980114, w0=73.31100000000005, w1=14.70222587554914\n",
      "SubGD iter. 328/499: loss=2.1009885802422663, w0=73.30400000000004, w1=14.710042735191143\n",
      "SubGD iter. 329/499: loss=2.100988839669895, w0=73.30400000000004, w1=14.70543748820183\n",
      "SubGD iter. 330/499: loss=2.1009736908842997, w0=73.30400000000004, w1=14.700832241212519\n",
      "SubGD iter. 331/499: loss=2.100973235572161, w0=73.30400000000004, w1=14.714180882853983\n",
      "SubGD iter. 332/499: loss=2.1010024519499417, w0=73.30400000000004, w1=14.70957563586467\n",
      "SubGD iter. 333/499: loss=2.100987303164347, w0=73.30400000000004, w1=14.704970388875358\n",
      "SubGD iter. 334/499: loss=2.1009721543787525, w0=73.30400000000004, w1=14.700365141886046\n",
      "SubGD iter. 335/499: loss=2.100977689244675, w0=73.30400000000004, w1=14.71371378352751\n",
      "SubGD iter. 336/499: loss=2.101000915444394, w0=73.30400000000004, w1=14.709108536538197\n",
      "SubGD iter. 337/499: loss=2.100985766658799, w0=73.30400000000004, w1=14.704503289548885\n",
      "SubGD iter. 338/499: loss=2.1009706178732044, w0=73.30400000000004, w1=14.699898042559573\n",
      "SubGD iter. 339/499: loss=2.1009821429171898, w0=73.30400000000004, w1=14.713246684201037\n",
      "SubGD iter. 340/499: loss=2.100999378938846, w0=73.30400000000004, w1=14.708641437211725\n",
      "SubGD iter. 341/499: loss=2.100984230153251, w0=73.30400000000004, w1=14.704036190222412\n",
      "SubGD iter. 342/499: loss=2.1009690813676567, w0=73.30400000000004, w1=14.6994309432331\n",
      "SubGD iter. 343/499: loss=2.100986596589704, w0=73.30400000000004, w1=14.712779584874564\n",
      "SubGD iter. 344/499: loss=2.100997842433298, w0=73.30400000000004, w1=14.708174337885252\n",
      "SubGD iter. 345/499: loss=2.1009826936477034, w0=73.30400000000004, w1=14.70356909089594\n",
      "SubGD iter. 346/499: loss=2.1009686048349927, w0=73.31100000000005, w1=14.704495625906087\n",
      "SubGD iter. 347/499: loss=2.1009759071565783, w0=73.30400000000004, w1=14.712312485548091\n",
      "SubGD iter. 348/499: loss=2.1009963059277506, w0=73.30400000000004, w1=14.707707238558779\n",
      "SubGD iter. 349/499: loss=2.1009811571421557, w0=73.30400000000004, w1=14.703101991569467\n",
      "SubGD iter. 350/499: loss=2.100968913966334, w0=73.31100000000005, w1=14.704028526579615\n",
      "SubGD iter. 351/499: loss=2.1009785151922027, w0=73.30400000000004, w1=14.711845386221619\n",
      "SubGD iter. 352/499: loss=2.1009947694222024, w0=73.30400000000004, w1=14.707240139232306\n",
      "SubGD iter. 353/499: loss=2.100979620636608, w0=73.30400000000004, w1=14.702634892242994\n",
      "SubGD iter. 354/499: loss=2.1009692230976773, w0=73.31100000000005, w1=14.703561427253142\n",
      "SubGD iter. 355/499: loss=2.100981123227827, w0=73.30400000000004, w1=14.711378286895146\n",
      "SubGD iter. 356/499: loss=2.1009932329166547, w0=73.30400000000004, w1=14.706773039905833\n",
      "SubGD iter. 357/499: loss=2.10097808413106, w0=73.30400000000004, w1=14.702167792916521\n",
      "SubGD iter. 358/499: loss=2.100969532229019, w0=73.31100000000005, w1=14.703094327926669\n",
      "SubGD iter. 359/499: loss=2.100983731263452, w0=73.30400000000004, w1=14.710911187568673\n",
      "SubGD iter. 360/499: loss=2.1009916964111066, w0=73.30400000000004, w1=14.70630594057936\n",
      "SubGD iter. 361/499: loss=2.1009765476255122, w0=73.30400000000004, w1=14.701700693590048\n",
      "SubGD iter. 362/499: loss=2.1009698413603615, w0=73.31100000000005, w1=14.702627228600196\n",
      "SubGD iter. 363/499: loss=2.1009863392990757, w0=73.30400000000004, w1=14.7104440882422\n",
      "SubGD iter. 364/499: loss=2.100990159905559, w0=73.30400000000004, w1=14.705838841252888\n",
      "SubGD iter. 365/499: loss=2.1009750111199645, w0=73.30400000000004, w1=14.701233594263575\n",
      "SubGD iter. 366/499: loss=2.1009701504917038, w0=73.31100000000005, w1=14.702160129273723\n",
      "SubGD iter. 367/499: loss=2.1009889473346997, w0=73.30400000000004, w1=14.709976988915727\n",
      "SubGD iter. 368/499: loss=2.1009886234000112, w0=73.30400000000004, w1=14.705371741926415\n",
      "SubGD iter. 369/499: loss=2.1009734746144164, w0=73.30400000000004, w1=14.700766494937103\n",
      "SubGD iter. 370/499: loss=2.1009738624460677, w0=73.30400000000004, w1=14.714115136578567\n",
      "SubGD iter. 371/499: loss=2.1010022356800584, w0=73.30400000000004, w1=14.709509889589254\n",
      "SubGD iter. 372/499: loss=2.100987086894463, w0=73.30400000000004, w1=14.704904642599942\n",
      "SubGD iter. 373/499: loss=2.1009719381088687, w0=73.30400000000004, w1=14.70029939561063\n",
      "SubGD iter. 374/499: loss=2.1009783161185824, w0=73.30400000000004, w1=14.713648037252094\n",
      "SubGD iter. 375/499: loss=2.1010006991745103, w0=73.30400000000004, w1=14.709042790262782\n",
      "SubGD iter. 376/499: loss=2.1009855503889154, w0=73.30400000000004, w1=14.70443754327347\n",
      "SubGD iter. 377/499: loss=2.100970401603321, w0=73.30400000000004, w1=14.699832296284157\n",
      "SubGD iter. 378/499: loss=2.1009827697910963, w0=73.30400000000004, w1=14.713180937925621\n",
      "SubGD iter. 379/499: loss=2.1009991626689626, w0=73.30400000000004, w1=14.708575690936309\n",
      "SubGD iter. 380/499: loss=2.1009840138833678, w0=73.30400000000004, w1=14.703970443946996\n",
      "SubGD iter. 381/499: loss=2.100968865097773, w0=73.30400000000004, w1=14.699365196957684\n",
      "SubGD iter. 382/499: loss=2.100987223463611, w0=73.30400000000004, w1=14.712713838599148\n",
      "SubGD iter. 383/499: loss=2.100997626163415, w0=73.30400000000004, w1=14.708108591609836\n",
      "SubGD iter. 384/499: loss=2.10098247737782, w0=73.30400000000004, w1=14.703503344620524\n",
      "SubGD iter. 385/499: loss=2.100968648346582, w0=73.31100000000005, w1=14.704429879630672\n",
      "SubGD iter. 386/499: loss=2.100976274249012, w0=73.30400000000004, w1=14.712246739272675\n",
      "SubGD iter. 387/499: loss=2.1009960896578668, w0=73.30400000000004, w1=14.707641492283363\n",
      "SubGD iter. 388/499: loss=2.100980940872272, w0=73.30400000000004, w1=14.70303624529405\n",
      "SubGD iter. 389/499: loss=2.1009689574779244, w0=73.31100000000005, w1=14.703962780304199\n",
      "SubGD iter. 390/499: loss=2.1009788822846365, w0=73.30400000000004, w1=14.711779639946203\n",
      "SubGD iter. 391/499: loss=2.100994553152319, w0=73.30400000000004, w1=14.70717439295689\n",
      "SubGD iter. 392/499: loss=2.1009794043667243, w0=73.30400000000004, w1=14.702569145967578\n",
      "SubGD iter. 393/499: loss=2.1009692666092668, w0=73.31100000000005, w1=14.703495680977726\n",
      "SubGD iter. 394/499: loss=2.100981490320261, w0=73.30400000000004, w1=14.71131254061973\n",
      "SubGD iter. 395/499: loss=2.100993016646771, w0=73.30400000000004, w1=14.706707293630418\n",
      "SubGD iter. 396/499: loss=2.1009778678611766, w0=73.30400000000004, w1=14.702102046641105\n",
      "SubGD iter. 397/499: loss=2.100969575740609, w0=73.31100000000005, w1=14.703028581651253\n",
      "SubGD iter. 398/499: loss=2.1009840983558847, w0=73.30400000000004, w1=14.710845441293257\n",
      "SubGD iter. 399/499: loss=2.1009914801412233, w0=73.30400000000004, w1=14.706240194303945\n",
      "SubGD iter. 400/499: loss=2.1009763313556284, w0=73.30400000000004, w1=14.701634947314632\n",
      "SubGD iter. 401/499: loss=2.1009698848719514, w0=73.31100000000005, w1=14.70256148232478\n",
      "SubGD iter. 402/499: loss=2.100986706391509, w0=73.30400000000004, w1=14.710378341966784\n",
      "SubGD iter. 403/499: loss=2.1009899436356756, w0=73.30400000000004, w1=14.705773094977472\n",
      "SubGD iter. 404/499: loss=2.1009747948500808, w0=73.30400000000004, w1=14.70116784798816\n",
      "SubGD iter. 405/499: loss=2.1009701940032937, w0=73.31100000000005, w1=14.702094382998308\n",
      "SubGD iter. 406/499: loss=2.1009893144271334, w0=73.30400000000004, w1=14.709911242640311\n",
      "SubGD iter. 407/499: loss=2.100988407130128, w0=73.30400000000004, w1=14.705305995650999\n",
      "SubGD iter. 408/499: loss=2.100973258344533, w0=73.30400000000004, w1=14.700700748661687\n",
      "SubGD iter. 409/499: loss=2.100974489319975, w0=73.30400000000004, w1=14.71404939030315\n",
      "SubGD iter. 410/499: loss=2.1010020194101746, w0=73.30400000000004, w1=14.709444143313839\n",
      "SubGD iter. 411/499: loss=2.1009868706245802, w0=73.30400000000004, w1=14.704838896324526\n",
      "SubGD iter. 412/499: loss=2.1009717218389854, w0=73.30400000000004, w1=14.700233649335214\n",
      "SubGD iter. 413/499: loss=2.1009789429924894, w0=73.30400000000004, w1=14.713582290976678\n",
      "SubGD iter. 414/499: loss=2.1010004829046265, w0=73.30400000000004, w1=14.708977043987366\n",
      "SubGD iter. 415/499: loss=2.100985334119032, w0=73.30400000000004, w1=14.704371796998053\n",
      "SubGD iter. 416/499: loss=2.1009701853334373, w0=73.30400000000004, w1=14.699766550008741\n",
      "SubGD iter. 417/499: loss=2.1009833966650033, w0=73.30400000000004, w1=14.713115191650205\n",
      "SubGD iter. 418/499: loss=2.1009989463990792, w0=73.30400000000004, w1=14.708509944660893\n",
      "SubGD iter. 419/499: loss=2.1009837976134844, w0=73.30400000000004, w1=14.70390469767158\n",
      "SubGD iter. 420/499: loss=2.1009686488278896, w0=73.30400000000004, w1=14.699299450682268\n",
      "SubGD iter. 421/499: loss=2.1009878503375177, w0=73.30400000000004, w1=14.712648092323732\n",
      "SubGD iter. 422/499: loss=2.100997409893531, w0=73.30400000000004, w1=14.70804284533442\n",
      "SubGD iter. 423/499: loss=2.1009822611079363, w0=73.30400000000004, w1=14.703437598345108\n",
      "SubGD iter. 424/499: loss=2.1009686918581725, w0=73.31100000000005, w1=14.704364133355256\n",
      "SubGD iter. 425/499: loss=2.100976641341446, w0=73.30400000000004, w1=14.71218099299726\n",
      "SubGD iter. 426/499: loss=2.100995873387983, w0=73.30400000000004, w1=14.707575746007947\n",
      "SubGD iter. 427/499: loss=2.1009807246023886, w0=73.30400000000004, w1=14.702970499018635\n",
      "SubGD iter. 428/499: loss=2.1009690009895143, w0=73.31100000000005, w1=14.703897034028783\n",
      "SubGD iter. 429/499: loss=2.10097924937707, w0=73.30400000000004, w1=14.711713893670787\n",
      "SubGD iter. 430/499: loss=2.1009943368824353, w0=73.30400000000004, w1=14.707108646681474\n",
      "SubGD iter. 431/499: loss=2.100979188096841, w0=73.30400000000004, w1=14.702503399692162\n",
      "SubGD iter. 432/499: loss=2.100969310120857, w0=73.31100000000005, w1=14.70342993470231\n",
      "SubGD iter. 433/499: loss=2.1009818574126946, w0=73.30400000000004, w1=14.711246794344314\n",
      "SubGD iter. 434/499: loss=2.1009928003768876, w0=73.30400000000004, w1=14.706641547355002\n",
      "SubGD iter. 435/499: loss=2.1009776515912932, w0=73.30400000000004, w1=14.70203630036569\n",
      "SubGD iter. 436/499: loss=2.1009696192521994, w0=73.31100000000005, w1=14.702962835375837\n",
      "SubGD iter. 437/499: loss=2.1009844654483185, w0=73.30400000000004, w1=14.710779695017841\n",
      "SubGD iter. 438/499: loss=2.1009912638713395, w0=73.30400000000004, w1=14.706174448028529\n",
      "SubGD iter. 439/499: loss=2.100976115085745, w0=73.30400000000004, w1=14.701569201039216\n",
      "SubGD iter. 440/499: loss=2.1009699283835412, w0=73.31100000000005, w1=14.702495736049364\n",
      "SubGD iter. 441/499: loss=2.1009870734839424, w0=73.30400000000004, w1=14.710312595691368\n",
      "SubGD iter. 442/499: loss=2.100989727365792, w0=73.30400000000004, w1=14.705707348702056\n",
      "SubGD iter. 443/499: loss=2.1009745785801974, w0=73.30400000000004, w1=14.701102101712744\n",
      "SubGD iter. 444/499: loss=2.1009706625213678, w0=73.30400000000004, w1=14.714450743354208\n",
      "SubGD iter. 445/499: loss=2.101003339645839, w0=73.30400000000004, w1=14.709845496364895\n",
      "SubGD iter. 446/499: loss=2.1009881908602446, w0=73.30400000000004, w1=14.705240249375583\n",
      "SubGD iter. 447/499: loss=2.1009730420746493, w0=73.30400000000004, w1=14.70063500238627\n",
      "SubGD iter. 448/499: loss=2.100975116193882, w0=73.30400000000004, w1=14.713983644027735\n",
      "SubGD iter. 449/499: loss=2.1010018031402913, w0=73.30400000000004, w1=14.709378397038423\n",
      "SubGD iter. 450/499: loss=2.1009866543546964, w0=73.30400000000004, w1=14.70477315004911\n",
      "SubGD iter. 451/499: loss=2.100971505569102, w0=73.30400000000004, w1=14.700167903059798\n",
      "SubGD iter. 452/499: loss=2.100979569866396, w0=73.30400000000004, w1=14.713516544701262\n",
      "SubGD iter. 453/499: loss=2.101000266634743, w0=73.30400000000004, w1=14.70891129771195\n",
      "SubGD iter. 454/499: loss=2.1009851178491488, w0=73.30400000000004, w1=14.704306050722638\n",
      "SubGD iter. 455/499: loss=2.100969969063554, w0=73.30400000000004, w1=14.699700803733325\n",
      "SubGD iter. 456/499: loss=2.100984023538911, w0=73.30400000000004, w1=14.71304944537479\n",
      "SubGD iter. 457/499: loss=2.1009987301291955, w0=73.30400000000004, w1=14.708444198385477\n",
      "SubGD iter. 458/499: loss=2.1009835813436006, w0=73.30400000000004, w1=14.703838951396165\n",
      "SubGD iter. 459/499: loss=2.1009684325580062, w0=73.30400000000004, w1=14.699233704406852\n",
      "SubGD iter. 460/499: loss=2.1009884772114247, w0=73.30400000000004, w1=14.712582346048316\n",
      "SubGD iter. 461/499: loss=2.100997193623648, w0=73.30400000000004, w1=14.707977099059004\n",
      "SubGD iter. 462/499: loss=2.1009820448380525, w0=73.30400000000004, w1=14.703371852069692\n",
      "SubGD iter. 463/499: loss=2.1009687353697624, w0=73.31100000000005, w1=14.70429838707984\n",
      "SubGD iter. 464/499: loss=2.1009770084338792, w0=73.30400000000004, w1=14.712115246721844\n",
      "SubGD iter. 465/499: loss=2.1009956571181, w0=73.30400000000004, w1=14.707509999732531\n",
      "SubGD iter. 466/499: loss=2.100980508332505, w0=73.30400000000004, w1=14.702904752743219\n",
      "SubGD iter. 467/499: loss=2.1009690445011047, w0=73.31100000000005, w1=14.703831287753367\n",
      "SubGD iter. 468/499: loss=2.1009796164695036, w0=73.30400000000004, w1=14.71164814739537\n",
      "SubGD iter. 469/499: loss=2.100994120612552, w0=73.30400000000004, w1=14.707042900406059\n",
      "SubGD iter. 470/499: loss=2.1009789718269576, w0=73.30400000000004, w1=14.702437653416746\n",
      "SubGD iter. 471/499: loss=2.100969353632447, w0=73.31100000000005, w1=14.703364188426894\n",
      "SubGD iter. 472/499: loss=2.1009822245051275, w0=73.30400000000004, w1=14.711181048068898\n",
      "SubGD iter. 473/499: loss=2.1009925841070043, w0=73.30400000000004, w1=14.706575801079586\n",
      "SubGD iter. 474/499: loss=2.1009774353214095, w0=73.30400000000004, w1=14.701970554090273\n",
      "SubGD iter. 475/499: loss=2.1009696627637893, w0=73.31100000000005, w1=14.702897089100421\n",
      "SubGD iter. 476/499: loss=2.100984832540752, w0=73.30400000000004, w1=14.710713948742425\n",
      "SubGD iter. 477/499: loss=2.100991047601456, w0=73.30400000000004, w1=14.706108701753113\n",
      "SubGD iter. 478/499: loss=2.1009758988158618, w0=73.30400000000004, w1=14.7015034547638\n",
      "SubGD iter. 479/499: loss=2.1009699718951316, w0=73.31100000000005, w1=14.702429989773949\n",
      "SubGD iter. 480/499: loss=2.1009874405763758, w0=73.30400000000004, w1=14.710246849415952\n",
      "SubGD iter. 481/499: loss=2.100989511095909, w0=73.30400000000004, w1=14.70564160242664\n",
      "SubGD iter. 482/499: loss=2.100974362310314, w0=73.30400000000004, w1=14.701036355437328\n",
      "SubGD iter. 483/499: loss=2.1009712893952748, w0=73.30400000000004, w1=14.714384997078792\n",
      "SubGD iter. 484/499: loss=2.1010031233759556, w0=73.30400000000004, w1=14.70977975008948\n",
      "SubGD iter. 485/499: loss=2.100987974590361, w0=73.30400000000004, w1=14.705174503100167\n",
      "SubGD iter. 486/499: loss=2.100972825804766, w0=73.30400000000004, w1=14.700569256110855\n",
      "SubGD iter. 487/499: loss=2.1009757430677887, w0=73.30400000000004, w1=14.713917897752319\n",
      "SubGD iter. 488/499: loss=2.1010015868704075, w0=73.30400000000004, w1=14.709312650763007\n",
      "SubGD iter. 489/499: loss=2.1009864380848127, w0=73.30400000000004, w1=14.704707403773694\n",
      "SubGD iter. 490/499: loss=2.1009712892992183, w0=73.30400000000004, w1=14.700102156784382\n",
      "SubGD iter. 491/499: loss=2.100980196740303, w0=73.30400000000004, w1=14.713450798425846\n",
      "SubGD iter. 492/499: loss=2.10100005036486, w0=73.30400000000004, w1=14.708845551436534\n",
      "SubGD iter. 493/499: loss=2.100984901579265, w0=73.30400000000004, w1=14.704240304447222\n",
      "SubGD iter. 494/499: loss=2.10096975279367, w0=73.30400000000004, w1=14.69963505745791\n",
      "SubGD iter. 495/499: loss=2.100984650412818, w0=73.30400000000004, w1=14.712983699099373\n",
      "SubGD iter. 496/499: loss=2.100998513859312, w0=73.30400000000004, w1=14.708378452110061\n",
      "SubGD iter. 497/499: loss=2.100983365073717, w0=73.30400000000004, w1=14.703773205120749\n",
      "SubGD iter. 498/499: loss=2.10096846975001, w0=73.31100000000005, w1=14.704699740130897\n",
      "SubGD iter. 499/499: loss=2.1009747674906887, w0=73.30400000000004, w1=14.7125165997729\n",
      "SubGD: execution time=0.017 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da960577cbbc4c3fa2fda2a6b678bb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    batches = batch_iter(y, tx, batch_size, max_iters)\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        yb, txb = next(batches)\n",
    "\n",
    "        loss = compute_loss(yb, txb, w)\n",
    "        subgradient = compute_subgradient_mae(yb, txb, w)\n",
    "\n",
    "        w = w - gamma * subgradient\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=45.46976038672778, w0=0.7, w1=0.35170621708078426\n",
      "SubSGD iter. 1/499: loss=45.741672697964695, w0=1.4, w1=1.2414988861476066\n",
      "SubSGD iter. 2/499: loss=43.10793071642218, w0=2.0999999999999996, w1=1.47829292259873\n",
      "SubSGD iter. 3/499: loss=39.338643081455366, w0=2.8, w1=1.6276620790223326\n",
      "SubSGD iter. 4/499: loss=27.98255697990916, w0=3.5, w1=1.0507407942381344\n",
      "SubSGD iter. 5/499: loss=44.66150787449272, w0=4.2, w1=2.1895024917923815\n",
      "SubSGD iter. 6/499: loss=29.09067711798186, w0=4.9, w1=1.2088668887476404\n",
      "SubSGD iter. 7/499: loss=25.155294093681587, w0=5.6000000000000005, w1=0.39490115681098703\n",
      "SubSGD iter. 8/499: loss=25.84521231155447, w0=6.300000000000001, w1=0.2279345349317905\n",
      "SubSGD iter. 9/499: loss=33.35598010793885, w0=7.000000000000001, w1=0.15542251156314496\n",
      "SubSGD iter. 10/499: loss=42.571310605277645, w0=7.700000000000001, w1=1.2925056904898644\n",
      "SubSGD iter. 11/499: loss=44.11118843835417, w0=8.4, w1=2.3808511821727913\n",
      "SubSGD iter. 12/499: loss=28.34765878940971, w0=9.1, w1=2.3187524332439864\n",
      "SubSGD iter. 13/499: loss=24.1923856210242, w0=9.799999999999999, w1=1.201811936045015\n",
      "SubSGD iter. 14/499: loss=24.878785226355276, w0=10.499999999999998, w1=0.47925477645165093\n",
      "SubSGD iter. 15/499: loss=23.564912867205187, w0=11.199999999999998, w1=0.14423582900443943\n",
      "SubSGD iter. 16/499: loss=26.880012536274563, w0=11.899999999999997, w1=-0.5041060134828058\n",
      "SubSGD iter. 17/499: loss=27.320388272479804, w0=12.599999999999996, w1=-0.9296269397695407\n",
      "SubSGD iter. 18/499: loss=26.441141026360384, w0=13.299999999999995, w1=-1.3693435893072166\n",
      "SubSGD iter. 19/499: loss=23.654791799648844, w0=13.999999999999995, w1=-1.7166322258624096\n",
      "SubSGD iter. 20/499: loss=32.35290471808366, w0=14.699999999999994, w1=-1.7214486538558043\n",
      "SubSGD iter. 21/499: loss=34.295711386887696, w0=15.399999999999993, w1=-1.629319745639446\n",
      "SubSGD iter. 22/499: loss=23.803443013379507, w0=16.099999999999994, w1=-1.8649891570513317\n",
      "SubSGD iter. 23/499: loss=34.84506161314526, w0=16.799999999999994, w1=-1.313634795723352\n",
      "SubSGD iter. 24/499: loss=14.355010844180656, w0=17.499999999999993, w1=-2.8486978536804846\n",
      "SubSGD iter. 25/499: loss=36.99253421514684, w0=18.199999999999992, w1=-2.0557443745359674\n",
      "SubSGD iter. 26/499: loss=47.76828365614515, w0=18.89999999999999, w1=-0.3824698332579284\n",
      "SubSGD iter. 27/499: loss=24.4365244766998, w0=19.59999999999999, w1=-0.6436036490836337\n",
      "SubSGD iter. 28/499: loss=19.370422076116697, w0=20.29999999999999, w1=-0.987989029187665\n",
      "SubSGD iter. 29/499: loss=37.096455962924466, w0=20.99999999999999, w1=-0.22587965260249432\n",
      "SubSGD iter. 30/499: loss=27.962505226811736, w0=21.69999999999999, w1=-0.1617906008848659\n",
      "SubSGD iter. 31/499: loss=20.79996302065515, w0=22.399999999999988, w1=-0.6063267753732944\n",
      "SubSGD iter. 32/499: loss=12.736641007478429, w0=23.099999999999987, w1=-1.567220908657882\n",
      "SubSGD iter. 33/499: loss=20.021875038210887, w0=23.799999999999986, w1=-1.7680720320498746\n",
      "SubSGD iter. 34/499: loss=35.73357724120601, w0=24.499999999999986, w1=-0.6309888531231551\n",
      "SubSGD iter. 35/499: loss=23.055871447712157, w0=25.199999999999985, w1=-0.4446940451319725\n",
      "SubSGD iter. 36/499: loss=32.568064718696355, w0=25.899999999999984, w1=0.23757759963213854\n",
      "SubSGD iter. 37/499: loss=12.736862026539486, w0=26.599999999999984, w1=-0.7277384606235549\n",
      "SubSGD iter. 38/499: loss=26.049337160639972, w0=27.299999999999983, w1=-0.6028941897072082\n",
      "SubSGD iter. 39/499: loss=18.484015641339543, w0=27.999999999999982, w1=-1.2512360321944533\n",
      "SubSGD iter. 40/499: loss=29.059141348584152, w0=28.69999999999998, w1=-0.5082272530447104\n",
      "SubSGD iter. 41/499: loss=13.930175243499162, w0=29.39999999999998, w1=-1.1741439400728504\n",
      "SubSGD iter. 42/499: loss=18.11571292909047, w0=30.09999999999998, w1=-1.4123597554674345\n",
      "SubSGD iter. 43/499: loss=11.552496405222204, w0=30.79999999999998, w1=-2.1390903051146477\n",
      "SubSGD iter. 44/499: loss=40.7033624892803, w0=31.49999999999998, w1=-0.8640922417163168\n",
      "SubSGD iter. 45/499: loss=20.699419342833508, w0=32.19999999999998, w1=-0.9366042650849624\n",
      "SubSGD iter. 46/499: loss=24.726536966597635, w0=32.899999999999984, w1=-0.6711795793666598\n",
      "SubSGD iter. 47/499: loss=19.964121575936453, w0=33.59999999999999, w1=-0.7258303490030423\n",
      "SubSGD iter. 48/499: loss=32.04447039718867, w0=34.29999999999999, w1=0.4514103103385846\n",
      "SubSGD iter. 49/499: loss=29.616924697827905, w0=34.99999999999999, w1=0.7992377245675147\n",
      "SubSGD iter. 50/499: loss=12.702346697920209, w0=35.699999999999996, w1=-0.007056243404360618\n",
      "SubSGD iter. 51/499: loss=26.28304164275378, w0=36.4, w1=0.7858972357401564\n",
      "SubSGD iter. 52/499: loss=14.630987045960506, w0=37.1, w1=-0.06778763026299395\n",
      "SubSGD iter. 53/499: loss=11.154743852008494, w0=37.800000000000004, w1=-0.11709017555024162\n",
      "SubSGD iter. 54/499: loss=23.842000466071813, w0=38.50000000000001, w1=0.06652592969170035\n",
      "SubSGD iter. 55/499: loss=18.011737072071018, w0=39.20000000000001, w1=0.17916766315945237\n",
      "SubSGD iter. 56/499: loss=7.4353935660973605, w0=39.90000000000001, w1=-0.937772834039519\n",
      "SubSGD iter. 57/499: loss=29.744983850760452, w0=40.600000000000016, w1=0.1505726576434081\n",
      "SubSGD iter. 58/499: loss=17.279345005580193, w0=41.30000000000002, w1=0.08056814471830628\n",
      "SubSGD iter. 59/499: loss=25.36827804598016, w0=42.00000000000002, w1=0.5342192173804343\n",
      "SubSGD iter. 60/499: loss=9.627376402294388, w0=42.700000000000024, w1=0.012723013446826026\n",
      "SubSGD iter. 61/499: loss=21.75767737951251, w0=43.40000000000003, w1=0.2127684928912497\n",
      "SubSGD iter. 62/499: loss=15.549970632195606, w0=44.10000000000003, w1=0.32541022635900174\n",
      "SubSGD iter. 63/499: loss=3.575808944948406, w0=44.80000000000003, w1=-0.6414478414574774\n",
      "SubSGD iter. 64/499: loss=10.013600940655273, w0=45.500000000000036, w1=-0.7035465903862823\n",
      "SubSGD iter. 65/499: loss=25.103380387493228, w0=46.20000000000004, w1=0.21161602250830802\n",
      "SubSGD iter. 66/499: loss=23.493434349998413, w0=46.90000000000004, w1=0.9737253990934787\n",
      "SubSGD iter. 67/499: loss=23.965337447562213, w0=47.600000000000044, w1=2.1509660584351056\n",
      "SubSGD iter. 68/499: loss=5.9725419501571295, w0=48.30000000000005, w1=1.6611907464274311\n",
      "SubSGD iter. 69/499: loss=5.615631733949506, w0=49.00000000000005, w1=1.6118882011401834\n",
      "SubSGD iter. 70/499: loss=8.791948408039769, w0=49.70000000000005, w1=1.1614567202614643\n",
      "SubSGD iter. 71/499: loss=20.274227558254378, w0=50.400000000000055, w1=1.8401613751474388\n",
      "SubSGD iter. 72/499: loss=3.0908581687871113, w0=51.10000000000006, w1=1.1134308255002257\n",
      "SubSGD iter. 73/499: loss=5.905206753049555, w0=51.80000000000006, w1=0.6015548259244794\n",
      "SubSGD iter. 74/499: loss=4.752458733898138, w0=52.500000000000064, w1=0.0800586219908711\n",
      "SubSGD iter. 75/499: loss=6.609575691810285, w0=53.20000000000007, w1=-0.7152710684058168\n",
      "SubSGD iter. 76/499: loss=4.659122948935018, w0=53.90000000000007, w1=-0.68689908925899\n",
      "SubSGD iter. 77/499: loss=2.396444448942134, w0=54.60000000000007, w1=-1.4931930572308654\n",
      "SubSGD iter. 78/499: loss=2.300479356391758, w0=55.300000000000075, w1=-1.9120271096842152\n",
      "SubSGD iter. 79/499: loss=0.27389838384818077, w0=56.00000000000008, w1=-2.488948394468413\n",
      "SubSGD iter. 80/499: loss=19.91142610620248, w0=56.70000000000008, w1=-1.64146897983416\n",
      "SubSGD iter. 81/499: loss=0.44668448838617536, w0=57.400000000000084, w1=-2.4477629478060354\n",
      "SubSGD iter. 82/499: loss=16.815446551915635, w0=58.10000000000009, w1=-1.6548094686615185\n",
      "SubSGD iter. 83/499: loss=22.90461073424188, w0=58.80000000000009, w1=-0.5661979068016676\n",
      "SubSGD iter. 84/499: loss=12.983565741516806, w0=59.50000000000009, w1=-0.014843545473687825\n",
      "SubSGD iter. 85/499: loss=7.819720138190178, w0=60.200000000000095, w1=0.0733827316198659\n",
      "SubSGD iter. 86/499: loss=5.703503242266098, w0=60.9000000000001, w1=-0.07183882909473331\n",
      "SubSGD iter. 87/499: loss=5.987517599705544, w0=61.6000000000001, w1=-0.12648959873111584\n",
      "SubSGD iter. 88/499: loss=5.86402498628998, w0=62.300000000000104, w1=-0.5841715487592697\n",
      "SubSGD iter. 89/499: loss=7.328907075285105, w0=63.00000000000011, w1=-0.5200824970416413\n",
      "SubSGD iter. 90/499: loss=15.411354088647919, w0=63.70000000000011, w1=0.25732709983316016\n",
      "SubSGD iter. 91/499: loss=22.836832466578215, w0=64.4000000000001, w1=1.4706036095196025\n",
      "SubSGD iter. 92/499: loss=2.4410800024423516, w0=63.7000000000001, w1=1.5199061548068502\n",
      "SubSGD iter. 93/499: loss=7.283853838282969, w0=63.0000000000001, w1=2.802179077079497\n",
      "SubSGD iter. 94/499: loss=12.486710195975526, w0=63.7000000000001, w1=3.459330613001096\n",
      "SubSGD iter. 95/499: loss=4.304726553575005, w0=64.4000000000001, w1=3.314109052286497\n",
      "SubSGD iter. 96/499: loss=4.239552026177019, w0=65.10000000000011, w1=3.139246212248151\n",
      "SubSGD iter. 97/499: loss=0.6940710919845507, w0=64.4000000000001, w1=4.119881815292892\n",
      "SubSGD iter. 98/499: loss=1.4995597585160247, w0=63.7000000000001, w1=5.034580725303651\n",
      "SubSGD iter. 99/499: loss=1.900940309682401, w0=63.0000000000001, w1=5.761311274950864\n",
      "SubSGD iter. 100/499: loss=0.061477928457950526, w0=62.3000000000001, w1=6.0362178851523645\n",
      "SubSGD iter. 101/499: loss=10.037293484837726, w0=63.0000000000001, w1=6.805928849492535\n",
      "SubSGD iter. 102/499: loss=5.467449262528341, w0=63.7000000000001, w1=6.187429043628816\n",
      "SubSGD iter. 103/499: loss=0.021127538472089924, w0=63.0000000000001, w1=7.304369540827787\n",
      "SubSGD iter. 104/499: loss=8.365843229831313, w0=63.7000000000001, w1=7.834804469904476\n",
      "SubSGD iter. 105/499: loss=4.646621061486762, w0=64.4000000000001, w1=8.194337948959756\n",
      "SubSGD iter. 106/499: loss=0.7517953278008704, w0=65.10000000000011, w1=7.43205997783019\n",
      "SubSGD iter. 107/499: loss=6.379950817516129, w0=65.80000000000011, w1=6.955163840849145\n",
      "SubSGD iter. 108/499: loss=7.22443157024329, w0=66.50000000000011, w1=7.735135600859767\n",
      "SubSGD iter. 109/499: loss=11.009074595436282, w0=67.20000000000012, w1=9.214743926202853\n",
      "SubSGD iter. 110/499: loss=1.7232788087282103, w0=66.50000000000011, w1=10.180059986458547\n",
      "SubSGD iter. 111/499: loss=0.5554729466738308, w0=65.80000000000011, w1=10.702118088765365\n",
      "SubSGD iter. 112/499: loss=0.408663717238575, w0=66.50000000000011, w1=10.108197163889388\n",
      "SubSGD iter. 113/499: loss=6.5221745607505355, w0=67.20000000000012, w1=10.548093320321694\n",
      "SubSGD iter. 114/499: loss=2.806064261901085, w0=67.90000000000012, w1=10.807583240528858\n",
      "SubSGD iter. 115/499: loss=0.36573368785799687, w0=68.60000000000012, w1=10.683938320452846\n",
      "SubSGD iter. 116/499: loss=6.389844583572717, w0=69.30000000000013, w1=11.461347917327647\n",
      "SubSGD iter. 117/499: loss=7.105753178840949, w0=70.00000000000013, w1=12.549959479187498\n",
      "SubSGD iter. 118/499: loss=1.435659242095479, w0=69.30000000000013, w1=13.17769516077037\n",
      "SubSGD iter. 119/499: loss=1.2355944278901383, w0=70.00000000000013, w1=12.733158986281941\n",
      "SubSGD iter. 120/499: loss=3.309959418217101, w0=70.70000000000013, w1=12.084817143794696\n",
      "SubSGD iter. 121/499: loss=1.1061913596641517, w0=71.40000000000013, w1=11.928623653985538\n",
      "SubSGD iter. 122/499: loss=1.1170575334778263, w0=72.10000000000014, w1=12.016849931079092\n",
      "SubSGD iter. 123/499: loss=1.3946444779376677, w0=72.80000000000014, w1=12.207220014934562\n",
      "SubSGD iter. 124/499: loss=4.71775539975787, w0=73.50000000000014, w1=12.772876811280641\n",
      "SubSGD iter. 125/499: loss=1.9714880061361235, w0=72.80000000000014, w1=13.391119859851491\n",
      "SubSGD iter. 126/499: loss=5.352960865197417, w0=73.50000000000014, w1=13.627913896302614\n",
      "SubSGD iter. 127/499: loss=0.24265405948118257, w0=72.80000000000014, w1=12.975590051952423\n",
      "SubSGD iter. 128/499: loss=1.387394542439413, w0=72.10000000000014, w1=13.405112800473905\n",
      "SubSGD iter. 129/499: loss=1.3007526214753078, w0=72.80000000000014, w1=12.701718516687798\n",
      "SubSGD iter. 130/499: loss=1.52208222136872, w0=72.10000000000014, w1=13.943929179819456\n",
      "SubSGD iter. 131/499: loss=0.9248901636930071, w0=71.40000000000013, w1=13.60634553097298\n",
      "SubSGD iter. 132/499: loss=1.7278157114377777, w0=70.70000000000013, w1=14.128403633279799\n",
      "SubSGD iter. 133/499: loss=2.7516635492903774, w0=70.00000000000013, w1=14.641146447560235\n",
      "SubSGD iter. 134/499: loss=0.7576632786574464, w0=69.30000000000013, w1=14.87681585897212\n",
      "SubSGD iter. 135/499: loss=1.9812660889048317, w0=70.00000000000013, w1=14.965042136065675\n",
      "SubSGD iter. 136/499: loss=1.5515629468748244, w0=69.30000000000013, w1=14.270536463167666\n",
      "SubSGD iter. 137/499: loss=4.5346790143230145, w0=70.00000000000013, w1=13.601238562789767\n",
      "SubSGD iter. 138/499: loss=0.8410440362022129, w0=70.70000000000013, w1=14.904186436695703\n",
      "SubSGD iter. 139/499: loss=6.227788642101096, w0=71.40000000000013, w1=14.44650448666755\n",
      "SubSGD iter. 140/499: loss=0.5201444298426594, w0=72.10000000000014, w1=15.256498733773544\n",
      "SubSGD iter. 141/499: loss=0.06804258235241178, w0=72.80000000000014, w1=16.026209698113714\n",
      "SubSGD iter. 142/499: loss=0.38735829781870734, w0=72.10000000000014, w1=16.053137089976616\n",
      "SubSGD iter. 143/499: loss=4.765668576350677, w0=72.80000000000014, w1=16.25318256942104\n",
      "SubSGD iter. 144/499: loss=2.0418467732593264, w0=72.10000000000014, w1=16.557766460535916\n",
      "SubSGD iter. 145/499: loss=0.5175530280762395, w0=71.40000000000013, w1=17.203740709663958\n",
      "SubSGD iter. 146/499: loss=2.882930222837391, w0=70.70000000000013, w1=17.538759657111168\n",
      "SubSGD iter. 147/499: loss=3.785485667763659, w0=70.00000000000013, w1=16.248314075866823\n",
      "SubSGD iter. 148/499: loss=0.44993029383075367, w0=70.70000000000013, w1=15.74505336996136\n",
      "SubSGD iter. 149/499: loss=0.149854790541049, w0=70.00000000000013, w1=16.321974654745556\n",
      "SubSGD iter. 150/499: loss=2.8197339642125243, w0=70.70000000000013, w1=16.76187081117786\n",
      "SubSGD iter. 151/499: loss=0.9043837480861185, w0=70.00000000000013, w1=16.424287162331385\n",
      "SubSGD iter. 152/499: loss=3.7529029675988355, w0=69.30000000000013, w1=15.85038513528941\n",
      "SubSGD iter. 153/499: loss=1.2683124141168847, w0=70.00000000000013, w1=16.401739496617388\n",
      "SubSGD iter. 154/499: loss=2.18852490929833, w0=69.30000000000013, w1=14.925033574785715\n",
      "SubSGD iter. 155/499: loss=0.9299295622287538, w0=70.00000000000013, w1=14.111067842849062\n",
      "SubSGD iter. 156/499: loss=0.36097227301132406, w0=70.70000000000013, w1=13.68154509432758\n",
      "SubSGD iter. 157/499: loss=0.4752791541798018, w0=71.40000000000013, w1=13.941035014534744\n",
      "SubSGD iter. 158/499: loss=2.1786751850795874, w0=72.10000000000014, w1=12.594385367124831\n",
      "SubSGD iter. 159/499: loss=0.8904360197405587, w0=72.80000000000014, w1=11.47744486992586\n",
      "SubSGD iter. 160/499: loss=1.3284365583345625, w0=73.50000000000014, w1=10.829103027438615\n",
      "SubSGD iter. 161/499: loss=3.0646254016666106, w0=74.20000000000014, w1=10.407105063112361\n",
      "SubSGD iter. 162/499: loss=2.3077114754115513, w0=73.50000000000014, w1=10.829545364775331\n",
      "SubSGD iter. 163/499: loss=2.4160108932062663, w0=74.20000000000014, w1=10.213878848110623\n",
      "SubSGD iter. 164/499: loss=1.8676617397467155, w0=74.90000000000015, w1=9.74084236789929\n",
      "SubSGD iter. 165/499: loss=1.942321933345724, w0=75.60000000000015, w1=9.736025939905895\n",
      "SubSGD iter. 166/499: loss=6.75267989447725, w0=74.90000000000015, w1=9.707653960759068\n",
      "SubSGD iter. 167/499: loss=0.3086457854437583, w0=75.60000000000015, w1=9.898024044614537\n",
      "SubSGD iter. 168/499: loss=6.208394281557553, w0=74.90000000000015, w1=10.622504457060218\n",
      "SubSGD iter. 169/499: loss=1.4972979519337848, w0=74.20000000000014, w1=11.325898740846325\n",
      "SubSGD iter. 170/499: loss=2.8775205097219825, w0=74.90000000000015, w1=11.9732644230505\n",
      "SubSGD iter. 171/499: loss=2.393293433992028, w0=74.20000000000014, w1=12.60931110553828\n",
      "SubSGD iter. 172/499: loss=2.1010496556542506, w0=74.90000000000015, w1=12.758680261961883\n",
      "SubSGD iter. 173/499: loss=4.403083235127511, w0=74.20000000000014, w1=13.356462902019356\n",
      "SubSGD iter. 174/499: loss=1.0202867526692856, w0=73.50000000000014, w1=13.343592676160343\n",
      "SubSGD iter. 175/499: loss=3.904335808338544, w0=74.20000000000014, w1=13.4357215843767\n",
      "SubSGD iter. 176/499: loss=2.3849973837060503, w0=74.90000000000015, w1=13.982779790638416\n",
      "SubSGD iter. 177/499: loss=0.021776828651148605, w0=74.20000000000014, w1=13.092987121571593\n",
      "SubSGD iter. 178/499: loss=0.8937453098667589, w0=74.90000000000015, w1=13.982779790638414\n",
      "SubSGD iter. 179/499: loss=1.545553282382727, w0=75.60000000000015, w1=13.57583117303967\n",
      "SubSGD iter. 180/499: loss=4.0241870021078086, w0=74.90000000000015, w1=14.228625889962807\n",
      "SubSGD iter. 181/499: loss=1.3783045631269317, w0=74.20000000000014, w1=14.215755664103794\n",
      "SubSGD iter. 182/499: loss=0.3477581406983816, w0=73.50000000000014, w1=13.569217634102088\n",
      "SubSGD iter. 183/499: loss=4.610048459060806, w0=72.80000000000014, w1=13.919418228378483\n",
      "SubSGD iter. 184/499: loss=4.439478552210446, w0=73.50000000000014, w1=13.065733362375333\n",
      "SubSGD iter. 185/499: loss=1.1554888034470139, w0=72.80000000000014, w1=13.488173664038303\n",
      "SubSGD iter. 186/499: loss=0.9357942521923661, w0=72.10000000000014, w1=13.994257691060124\n",
      "SubSGD iter. 187/499: loss=1.0021433511136273, w0=72.80000000000014, w1=13.073504231960195\n",
      "SubSGD iter. 188/499: loss=2.441642888970332, w0=72.10000000000014, w1=13.492338284413545\n",
      "SubSGD iter. 189/499: loss=0.0649614135321741, w0=72.80000000000014, w1=13.735748938564264\n",
      "SubSGD iter. 190/499: loss=4.67724004187621, w0=73.50000000000014, w1=13.258852801583219\n",
      "SubSGD iter. 191/499: loss=6.570608724056349, w0=72.80000000000014, w1=13.425819423462414\n",
      "SubSGD iter. 192/499: loss=1.8775417387881106, w0=73.50000000000014, w1=14.273298838096668\n",
      "SubSGD iter. 193/499: loss=2.8547601740064046, w0=72.80000000000014, w1=14.913941639708579\n",
      "SubSGD iter. 194/499: loss=0.03689754768741338, w0=73.50000000000014, w1=14.46940546522015\n",
      "SubSGD iter. 195/499: loss=3.310698020483777, w0=74.20000000000014, w1=12.934342407263017\n",
      "SubSGD iter. 196/499: loss=1.6642248269114859, w0=74.90000000000015, w1=14.413950732606104\n",
      "SubSGD iter. 197/499: loss=3.445195711666841, w0=75.60000000000015, w1=13.99195276827985\n",
      "SubSGD iter. 198/499: loss=2.859352527884841, w0=74.90000000000015, w1=14.705360126279746\n",
      "SubSGD iter. 199/499: loss=0.912505652062908, w0=75.60000000000015, w1=13.816764847350278\n",
      "SubSGD iter. 200/499: loss=3.772159332668032, w0=76.30000000000015, w1=15.091762910748608\n",
      "SubSGD iter. 201/499: loss=1.399651921639986, w0=77.00000000000016, w1=15.227209000191369\n",
      "SubSGD iter. 202/499: loss=3.923397920838788, w0=76.30000000000015, w1=15.749267102498187\n",
      "SubSGD iter. 203/499: loss=0.875084802569507, w0=77.00000000000016, w1=14.860671823568719\n",
      "SubSGD iter. 204/499: loss=4.6869702884740505, w0=77.70000000000016, w1=15.20849923779765\n",
      "SubSGD iter. 205/499: loss=0.9360410432186903, w0=78.40000000000016, w1=14.526671327449504\n",
      "SubSGD iter. 206/499: loss=0.7580055761367817, w0=77.70000000000016, w1=15.873320974859418\n",
      "SubSGD iter. 207/499: loss=4.183512895171887, w0=77.00000000000016, w1=15.207658401431114\n",
      "SubSGD iter. 208/499: loss=0.31742091229739344, w0=76.30000000000015, w1=14.56029271922694\n",
      "SubSGD iter. 209/499: loss=6.743870420507747, w0=75.60000000000015, w1=13.92319035619406\n",
      "SubSGD iter. 210/499: loss=2.923756889156234, w0=76.30000000000015, w1=13.127860665797373\n",
      "SubSGD iter. 211/499: loss=0.8953542199457161, w0=75.60000000000015, w1=12.481322635795667\n",
      "SubSGD iter. 212/499: loss=0.6861412554536486, w0=74.90000000000015, w1=11.34256093824142\n",
      "SubSGD iter. 213/499: loss=3.7780536762417896, w0=74.20000000000014, w1=12.584771601373077\n",
      "SubSGD iter. 214/499: loss=1.6091315447322252, w0=73.50000000000014, w1=13.618383217676259\n",
      "SubSGD iter. 215/499: loss=0.970323604959269, w0=74.20000000000014, w1=13.557761054282295\n",
      "SubSGD iter. 216/499: loss=1.2887250468998772, w0=73.50000000000014, w1=12.081055132450622\n",
      "SubSGD iter. 217/499: loss=2.5538817127547517, w0=74.20000000000014, w1=13.28677121321174\n",
      "SubSGD iter. 218/499: loss=1.1065030339315207, w0=73.50000000000014, w1=14.366804992211796\n",
      "SubSGD iter. 219/499: loss=4.321230675889623, w0=74.20000000000014, w1=15.641803055610126\n",
      "SubSGD iter. 220/499: loss=6.087565418549005, w0=73.50000000000014, w1=14.613658666616972\n",
      "SubSGD iter. 221/499: loss=1.8527475014988681, w0=74.20000000000014, w1=15.292363321502947\n",
      "SubSGD iter. 222/499: loss=3.3229470914309545, w0=73.50000000000014, w1=14.155280142576228\n",
      "SubSGD iter. 223/499: loss=0.7429303614893925, w0=74.20000000000014, w1=15.828554683854266\n",
      "SubSGD iter. 224/499: loss=2.2991569305220345, w0=73.50000000000014, w1=16.350612786161086\n",
      "SubSGD iter. 225/499: loss=0.3235498281248894, w0=74.20000000000014, w1=17.039435941424802\n",
      "SubSGD iter. 226/499: loss=1.6017538443461135, w0=73.50000000000014, w1=16.796025287274084\n",
      "SubSGD iter. 227/499: loss=1.8076846766983365, w0=74.20000000000014, w1=15.513752365001437\n",
      "SubSGD iter. 228/499: loss=1.1443725082219984, w0=74.90000000000015, w1=15.276307032490196\n",
      "SubSGD iter. 229/499: loss=1.7099522046932378, w0=74.20000000000014, w1=14.466312785384202\n",
      "SubSGD iter. 230/499: loss=1.6971132621003342, w0=73.50000000000014, w1=15.132229472412343\n",
      "SubSGD iter. 231/499: loss=0.28379873270707634, w0=74.20000000000014, w1=13.849956550139696\n",
      "SubSGD iter. 232/499: loss=2.2317104899057973, w0=73.50000000000014, w1=14.563363908139593\n",
      "SubSGD iter. 233/499: loss=2.7441461754676126, w0=72.80000000000014, w1=15.287844320585274\n",
      "SubSGD iter. 234/499: loss=3.1306815929437093, w0=73.50000000000014, w1=15.423290410028034\n",
      "SubSGD iter. 235/499: loss=0.9864352671839463, w0=72.80000000000014, w1=15.852813158549516\n",
      "SubSGD iter. 236/499: loss=4.97505216811124, w0=73.50000000000014, w1=15.237146641884808\n",
      "SubSGD iter. 237/499: loss=4.838676302437481, w0=74.20000000000014, w1=14.760250504903762\n",
      "SubSGD iter. 238/499: loss=5.440163055255184, w0=73.50000000000014, w1=13.732106115910609\n",
      "SubSGD iter. 239/499: loss=1.5084654588101074, w0=74.20000000000014, w1=13.662101602985507\n",
      "SubSGD iter. 240/499: loss=1.9640519361247968, w0=74.90000000000015, w1=14.340806257871481\n",
      "SubSGD iter. 241/499: loss=0.9704294563727665, w0=75.60000000000015, w1=13.55473084107258\n",
      "SubSGD iter. 242/499: loss=0.6655999518129505, w0=74.90000000000015, w1=14.005162321951298\n",
      "SubSGD iter. 243/499: loss=4.67613446889062, w0=74.20000000000014, w1=14.349547702055329\n",
      "SubSGD iter. 244/499: loss=0.23104583404028034, w0=73.50000000000014, w1=14.002557981742058\n",
      "SubSGD iter. 245/499: loss=0.776280914076402, w0=72.80000000000014, w1=14.029485373604958\n",
      "SubSGD iter. 246/499: loss=2.6495280610859453, w0=73.50000000000014, w1=14.17885453002856\n",
      "SubSGD iter. 247/499: loss=2.444613829232992, w0=74.20000000000014, w1=14.725912736290276\n",
      "SubSGD iter. 248/499: loss=6.120450934811139, w0=74.90000000000015, w1=15.073740150519207\n",
      "SubSGD iter. 249/499: loss=2.7654929510084614, w0=75.60000000000015, w1=14.093104547474466\n",
      "SubSGD iter. 250/499: loss=3.059463945818898, w0=74.90000000000015, w1=12.802658966230121\n",
      "SubSGD iter. 251/499: loss=1.6508035608014424, w0=74.20000000000014, w1=11.665575787303402\n",
      "SubSGD iter. 252/499: loss=0.6394655635604778, w0=73.50000000000014, w1=12.471869755275277\n",
      "SubSGD iter. 253/499: loss=1.6860076468413325, w0=74.20000000000014, w1=12.936889955989942\n",
      "SubSGD iter. 254/499: loss=5.273472748751779, w0=74.90000000000015, w1=14.211888019388272\n",
      "SubSGD iter. 255/499: loss=0.6892066875695235, w0=75.60000000000015, w1=12.865238371978359\n",
      "SubSGD iter. 256/499: loss=2.864116478471324, w0=76.30000000000015, w1=13.95384993383821\n",
      "SubSGD iter. 257/499: loss=2.572892733621721, w0=75.60000000000015, w1=13.317713220337021\n",
      "SubSGD iter. 258/499: loss=1.6046274625617514, w0=76.30000000000015, w1=13.312896792343626\n",
      "SubSGD iter. 259/499: loss=0.9633776143394215, w0=75.60000000000015, w1=12.543185828003455\n",
      "SubSGD iter. 260/499: loss=3.2919941064225497, w0=76.30000000000015, w1=13.18870181283162\n",
      "SubSGD iter. 261/499: loss=0.7501339315650455, w0=75.60000000000015, w1=14.07729709176109\n",
      "SubSGD iter. 262/499: loss=2.4454531698347886, w0=74.90000000000015, w1=14.69554014033194\n",
      "SubSGD iter. 263/499: loss=5.494237667478657, w0=74.20000000000014, w1=14.121638113289963\n",
      "SubSGD iter. 264/499: loss=3.1659014610555154, w0=73.50000000000014, w1=14.53835816036772\n",
      "SubSGD iter. 265/499: loss=4.367624467463969, w0=72.80000000000014, w1=14.888558754644114\n",
      "SubSGD iter. 266/499: loss=0.41405251644042806, w0=72.10000000000014, w1=14.602781310577582\n",
      "SubSGD iter. 267/499: loss=2.4403066552385653, w0=72.80000000000014, w1=15.08598534749911\n",
      "SubSGD iter. 268/499: loss=0.32706301637141166, w0=73.50000000000014, w1=15.975778016565933\n",
      "SubSGD iter. 269/499: loss=1.2444281850548826, w0=74.20000000000014, w1=14.942166400262751\n",
      "SubSGD iter. 270/499: loss=1.949139432227632, w0=74.90000000000015, w1=16.030777962122603\n",
      "SubSGD iter. 271/499: loss=0.1255226407158645, w0=74.20000000000014, w1=16.103289985491248\n",
      "SubSGD iter. 272/499: loss=1.1285550011137602, w0=73.50000000000014, w1=15.990648252023496\n",
      "SubSGD iter. 273/499: loss=4.763606648128437, w0=72.80000000000014, w1=14.729478874528857\n",
      "SubSGD iter. 274/499: loss=1.1896465550992517, w0=72.10000000000014, w1=14.063816301100552\n",
      "SubSGD iter. 275/499: loss=0.15432419079004944, w0=71.40000000000013, w1=14.486256602763522\n",
      "SubSGD iter. 276/499: loss=4.604540970650035, w0=72.10000000000014, w1=15.187371378201899\n",
      "SubSGD iter. 277/499: loss=1.6474946736856921, w0=71.40000000000013, w1=15.355017287320122\n",
      "SubSGD iter. 278/499: loss=2.816410216522705, w0=72.10000000000014, w1=15.538827941647606\n",
      "SubSGD iter. 279/499: loss=5.591588703893397, w0=72.80000000000014, w1=14.743498251250918\n",
      "SubSGD iter. 280/499: loss=0.03870988722162494, w0=73.50000000000014, w1=14.231622251675171\n",
      "SubSGD iter. 281/499: loss=1.1524533128355756, w0=74.20000000000014, w1=15.319967743358099\n",
      "SubSGD iter. 282/499: loss=2.6816166464125644, w0=73.50000000000014, w1=15.487613652476321\n",
      "SubSGD iter. 283/499: loss=0.17286918934740214, w0=74.20000000000014, w1=14.725335681346754\n",
      "SubSGD iter. 284/499: loss=2.52291718809483, w0=74.90000000000015, w1=14.73261935167151\n",
      "SubSGD iter. 285/499: loss=2.1784078483759615, w0=74.20000000000014, w1=14.110023356517559\n",
      "SubSGD iter. 286/499: loss=2.9470700402669507, w0=73.50000000000014, w1=14.345692767929444\n",
      "SubSGD iter. 287/499: loss=2.5468842361226542, w0=72.80000000000014, w1=14.692981404484637\n",
      "SubSGD iter. 288/499: loss=3.9789465017649093, w0=72.10000000000014, w1=15.043181998761032\n",
      "SubSGD iter. 289/499: loss=1.9458856983487642, w0=72.80000000000014, w1=14.617661072474297\n",
      "SubSGD iter. 290/499: loss=0.26172287832839913, w0=73.50000000000014, w1=14.6414331314661\n",
      "SubSGD iter. 291/499: loss=5.380795240775619, w0=72.80000000000014, w1=14.00433076843322\n",
      "SubSGD iter. 292/499: loss=0.2029426991583705, w0=72.10000000000014, w1=13.211377289288704\n",
      "SubSGD iter. 293/499: loss=0.7076496500522396, w0=71.40000000000013, w1=12.695974645074957\n",
      "SubSGD iter. 294/499: loss=1.7923953377018407, w0=72.10000000000014, w1=11.318926159322444\n",
      "SubSGD iter. 295/499: loss=5.446260066802406, w0=71.40000000000013, w1=12.107498366428835\n",
      "SubSGD iter. 296/499: loss=3.4439710503593943, w0=72.10000000000014, w1=12.547394522861142\n",
      "SubSGD iter. 297/499: loss=2.2490376471824796, w0=71.40000000000013, w1=12.966228575314492\n",
      "SubSGD iter. 298/499: loss=2.3743087564389995, w0=72.10000000000014, w1=13.856021244381314\n",
      "SubSGD iter. 299/499: loss=2.143539431889131, w0=71.40000000000013, w1=14.50881596130445\n",
      "SubSGD iter. 300/499: loss=1.0729630009905193, w0=72.10000000000014, w1=15.449421453212121\n",
      "SubSGD iter. 301/499: loss=1.854240886580179, w0=71.40000000000013, w1=14.706412674062378\n",
      "SubSGD iter. 302/499: loss=1.4074028615660588, w0=70.70000000000013, w1=15.053701310617571\n",
      "SubSGD iter. 303/499: loss=0.4934954166928449, w0=71.40000000000013, w1=15.29711196476829\n",
      "SubSGD iter. 304/499: loss=1.3472411305525114, w0=70.70000000000013, w1=15.532781376180175\n",
      "SubSGD iter. 305/499: loss=1.9364815186925668, w0=70.00000000000013, w1=14.24233579493583\n",
      "SubSGD iter. 306/499: loss=1.9262102428111731, w0=69.30000000000013, w1=14.304434543864634\n",
      "SubSGD iter. 307/499: loss=2.061288810570673, w0=70.00000000000013, w1=14.950972573866341\n",
      "SubSGD iter. 308/499: loss=3.3194127107457803, w0=70.70000000000013, w1=14.880968060941239\n",
      "SubSGD iter. 309/499: loss=2.4776982784104007, w0=71.40000000000013, w1=15.146392746659542\n",
      "SubSGD iter. 310/499: loss=4.815988756184442, w0=72.10000000000014, w1=14.635269599770291\n",
      "SubSGD iter. 311/499: loss=4.789623024024703, w0=72.80000000000014, w1=14.019603083105583\n",
      "SubSGD iter. 312/499: loss=3.7543464861381644, w0=73.50000000000014, w1=13.401103277241864\n",
      "SubSGD iter. 313/499: loss=1.8833459397632382, w0=74.20000000000014, w1=14.316265890136455\n",
      "SubSGD iter. 314/499: loss=4.285588197664765, w0=74.90000000000015, w1=13.858583940108302\n",
      "SubSGD iter. 315/499: loss=1.5377369009379969, w0=75.60000000000015, w1=13.189286039730403\n",
      "SubSGD iter. 316/499: loss=3.948996317640894, w0=74.90000000000015, w1=13.817021721313274\n",
      "SubSGD iter. 317/499: loss=0.4703131728286323, w0=74.20000000000014, w1=13.871672490949656\n",
      "SubSGD iter. 318/499: loss=0.907647955468839, w0=74.90000000000015, w1=14.71915190558391\n",
      "SubSGD iter. 319/499: loss=1.528045497785456, w0=75.60000000000015, w1=14.401924259087147\n",
      "SubSGD iter. 320/499: loss=3.2516097637935744, w0=76.30000000000015, w1=14.60196973853157\n",
      "SubSGD iter. 321/499: loss=2.0965110963487277, w0=75.60000000000015, w1=13.94964589418138\n",
      "SubSGD iter. 322/499: loss=0.40079978071354816, w0=76.30000000000015, w1=13.163570477382478\n",
      "SubSGD iter. 323/499: loss=0.9871016158351793, w0=75.60000000000015, w1=12.816580757069207\n",
      "SubSGD iter. 324/499: loss=0.6419997427474868, w0=74.90000000000015, w1=12.889092780437853\n",
      "SubSGD iter. 325/499: loss=0.32878805414193124, w0=74.20000000000014, w1=12.079098533331859\n",
      "SubSGD iter. 326/499: loss=4.042417130699832, w0=74.90000000000015, w1=12.2627146385738\n",
      "SubSGD iter. 327/499: loss=3.899333653546254, w0=74.20000000000014, w1=12.908688887701844\n",
      "SubSGD iter. 328/499: loss=6.57193684361804, w0=74.90000000000015, w1=13.256516301930775\n",
      "SubSGD iter. 329/499: loss=2.275095974125854, w0=75.60000000000015, w1=12.07226466973919\n",
      "SubSGD iter. 330/499: loss=1.095056183497789, w0=74.90000000000015, w1=12.048492610747388\n",
      "SubSGD iter. 331/499: loss=1.5005348339161344, w0=75.60000000000015, w1=12.232303265074872\n",
      "SubSGD iter. 332/499: loss=4.891410010583023, w0=74.90000000000015, w1=11.977328587526909\n",
      "SubSGD iter. 333/499: loss=3.9045370907872794, w0=75.60000000000015, w1=13.06594014938676\n",
      "SubSGD iter. 334/499: loss=0.8612386059222032, w0=76.30000000000015, w1=13.048856973638442\n",
      "SubSGD iter. 335/499: loss=0.31050746501448145, w0=75.60000000000015, w1=14.425905459390954\n",
      "SubSGD iter. 336/499: loss=1.2072331083693513, w0=76.30000000000015, w1=14.575274615814557\n",
      "SubSGD iter. 337/499: loss=0.3249959168386951, w0=77.00000000000016, w1=15.222640298018732\n",
      "SubSGD iter. 338/499: loss=2.5307721859146355, w0=76.30000000000015, w1=16.070539910767483\n",
      "SubSGD iter. 339/499: loss=1.4008185469299477, w0=75.60000000000015, w1=15.68494046297775\n",
      "SubSGD iter. 340/499: loss=2.632360233065448, w0=76.30000000000015, w1=14.307891977225237\n",
      "SubSGD iter. 341/499: loss=2.1248783539047693, w0=75.60000000000015, w1=13.51493849808072\n",
      "SubSGD iter. 342/499: loss=5.959321283368499, w0=74.90000000000015, w1=14.303510705187112\n",
      "SubSGD iter. 343/499: loss=3.931418327721488, w0=75.60000000000015, w1=13.845828755158959\n",
      "SubSGD iter. 344/499: loss=0.40236517901701063, w0=76.30000000000015, w1=14.934174246841886\n",
      "SubSGD iter. 345/499: loss=3.441888298171044, w0=75.60000000000015, w1=14.418771602628139\n",
      "SubSGD iter. 346/499: loss=1.4196639155833637, w0=74.90000000000015, w1=15.701044524900786\n",
      "SubSGD iter. 347/499: loss=3.3877824232239746, w0=74.20000000000014, w1=14.958035745751042\n",
      "SubSGD iter. 348/499: loss=6.86610519265292, w0=73.50000000000014, w1=15.00733829103829\n",
      "SubSGD iter. 349/499: loss=0.5494197026448759, w0=74.20000000000014, w1=16.095683782721217\n",
      "SubSGD iter. 350/499: loss=4.7811284780943595, w0=74.90000000000015, w1=15.618787645740172\n",
      "SubSGD iter. 351/499: loss=0.5206716201174402, w0=75.60000000000015, w1=16.27593918166177\n",
      "SubSGD iter. 352/499: loss=2.791983177723111, w0=76.30000000000015, w1=16.45955528690371\n",
      "SubSGD iter. 353/499: loss=1.0030571252310594, w0=75.60000000000015, w1=15.792663167295016\n",
      "SubSGD iter. 354/499: loss=1.775994333989928, w0=74.90000000000015, w1=15.14612513729331\n",
      "SubSGD iter. 355/499: loss=0.3401359985683925, w0=74.20000000000014, w1=14.996364123244726\n",
      "SubSGD iter. 356/499: loss=2.19017952736408, w0=74.90000000000015, w1=14.589415505645983\n",
      "SubSGD iter. 357/499: loss=2.0508665519341776, w0=74.20000000000014, w1=13.450653808091735\n",
      "SubSGD iter. 358/499: loss=3.407286040629131, w0=73.50000000000014, w1=13.911836920037759\n",
      "SubSGD iter. 359/499: loss=1.1508796639781878, w0=72.80000000000014, w1=13.246174346609454\n",
      "SubSGD iter. 360/499: loss=0.49402490254455245, w0=72.10000000000014, w1=12.98668442640229\n",
      "SubSGD iter. 361/499: loss=2.453728570934725, w0=71.40000000000013, w1=13.403404473480046\n",
      "SubSGD iter. 362/499: loss=5.387159488178508, w0=72.10000000000014, w1=12.945722523451893\n",
      "SubSGD iter. 363/499: loss=4.251870773520142, w0=71.40000000000013, w1=13.280741470899105\n",
      "SubSGD iter. 364/499: loss=1.0197268581171421, w0=70.70000000000013, w1=14.246057531154799\n",
      "SubSGD iter. 365/499: loss=1.3461171928338764, w0=70.00000000000013, w1=14.735832843162473\n",
      "SubSGD iter. 366/499: loss=0.12719479736671957, w0=70.70000000000013, w1=15.677056737036832\n",
      "SubSGD iter. 367/499: loss=1.899636489086106, w0=71.40000000000013, w1=14.954499577443467\n",
      "SubSGD iter. 368/499: loss=2.468053962731638, w0=70.70000000000013, w1=14.768204769452284\n",
      "SubSGD iter. 369/499: loss=6.170042654997211, w0=71.40000000000013, w1=15.004998805903407\n",
      "SubSGD iter. 370/499: loss=6.403973138987766, w0=72.10000000000014, w1=13.832478476659118\n",
      "SubSGD iter. 371/499: loss=0.005823023033997288, w0=72.80000000000014, w1=14.075889130809836\n",
      "SubSGD iter. 372/499: loss=3.051139273835453, w0=72.10000000000014, w1=13.889594322818652\n",
      "SubSGD iter. 373/499: loss=0.02481216033198308, w0=72.80000000000014, w1=13.902464548677665\n",
      "SubSGD iter. 374/499: loss=0.462481838323626, w0=73.50000000000014, w1=14.672175513017836\n",
      "SubSGD iter. 375/499: loss=1.1493687269811517, w0=74.20000000000014, w1=15.36099866828155\n",
      "SubSGD iter. 376/499: loss=2.5196100740702008, w0=74.90000000000015, w1=15.368282338606305\n",
      "SubSGD iter. 377/499: loss=3.7934920876813862, w0=74.20000000000014, w1=15.204612861297923\n",
      "SubSGD iter. 378/499: loss=1.1825870589136969, w0=74.90000000000015, w1=15.68781689821945\n",
      "SubSGD iter. 379/499: loss=1.0642932606845221, w0=74.20000000000014, w1=16.11025719988242\n",
      "SubSGD iter. 380/499: loss=4.218768036529717, w0=73.50000000000014, w1=14.819811618638074\n",
      "SubSGD iter. 381/499: loss=2.8230057037709813, w0=72.80000000000014, w1=15.417594258695546\n",
      "SubSGD iter. 382/499: loss=1.5095855234647289, w0=73.50000000000014, w1=15.542438529611893\n",
      "SubSGD iter. 383/499: loss=1.5538121530904405, w0=72.80000000000014, w1=16.045699235517354\n",
      "SubSGD iter. 384/499: loss=0.17620249685673528, w0=72.10000000000014, w1=16.663942284088204\n",
      "SubSGD iter. 385/499: loss=5.523404179150212, w0=72.80000000000014, w1=16.241944319761952\n",
      "SubSGD iter. 386/499: loss=4.60444379202773, w0=73.50000000000014, w1=15.76890783955062\n",
      "SubSGD iter. 387/499: loss=2.7237988793432777, w0=72.80000000000014, w1=15.025899060400876\n",
      "SubSGD iter. 388/499: loss=1.750121264468099, w0=72.10000000000014, w1=14.666365581345596\n",
      "SubSGD iter. 389/499: loss=4.803297848780943, w0=72.80000000000014, w1=14.050699064680888\n",
      "SubSGD iter. 390/499: loss=1.0705059231400504, w0=72.10000000000014, w1=15.070119989620038\n",
      "SubSGD iter. 391/499: loss=3.3606562775756075, w0=72.80000000000014, w1=15.065303561626642\n",
      "SubSGD iter. 392/499: loss=2.190965678727842, w0=73.50000000000014, w1=14.176708282697174\n",
      "SubSGD iter. 393/499: loss=6.606899766937069, w0=74.20000000000014, w1=14.524535696926105\n",
      "SubSGD iter. 394/499: loss=0.5795288641095908, w0=73.50000000000014, w1=13.754824732585934\n",
      "SubSGD iter. 395/499: loss=4.563620090352977, w0=72.80000000000014, w1=14.105025326862329\n",
      "SubSGD iter. 396/499: loss=1.888042603789735, w0=73.50000000000014, w1=13.318949910063427\n",
      "SubSGD iter. 397/499: loss=1.8312399659576606, w0=74.20000000000014, w1=12.670608067576183\n",
      "SubSGD iter. 398/499: loss=1.4020285188201385, w0=73.50000000000014, w1=13.393165227169547\n",
      "SubSGD iter. 399/499: loss=2.099430804492492, w0=72.80000000000014, w1=14.360023294986027\n",
      "SubSGD iter. 400/499: loss=2.972816343884471, w0=73.50000000000014, w1=13.678195384637881\n",
      "SubSGD iter. 401/499: loss=2.1570174231226957, w0=74.20000000000014, w1=13.271246767039138\n",
      "SubSGD iter. 402/499: loss=0.13441082270153615, w0=74.90000000000015, w1=11.924597119629224\n",
      "SubSGD iter. 403/499: loss=1.1484334987059306, w0=75.60000000000015, w1=10.74034548743764\n",
      "SubSGD iter. 404/499: loss=6.773033132519618, w0=74.90000000000015, w1=10.711973508290813\n",
      "SubSGD iter. 405/499: loss=2.966321935409802, w0=74.20000000000014, w1=11.348020190778593\n",
      "SubSGD iter. 406/499: loss=3.596161387048582, w0=73.50000000000014, w1=12.277956271206143\n",
      "SubSGD iter. 407/499: loss=3.0885562443833443, w0=74.20000000000014, w1=11.424271405202994\n",
      "SubSGD iter. 408/499: loss=1.9543246035677342, w0=74.90000000000015, w1=12.314064074269815\n",
      "SubSGD iter. 409/499: loss=0.18046752656024267, w0=75.60000000000015, w1=12.960602104271523\n",
      "SubSGD iter. 410/499: loss=0.6961697046706519, w0=74.90000000000015, w1=13.400318753809199\n",
      "SubSGD iter. 411/499: loss=2.8465388200354127, w0=75.60000000000015, w1=12.78465223714449\n",
      "SubSGD iter. 412/499: loss=3.3418928340385037, w0=74.90000000000015, w1=13.71458831757204\n",
      "SubSGD iter. 413/499: loss=3.413251583362282, w0=74.20000000000014, w1=12.453418940077402\n",
      "SubSGD iter. 414/499: loss=3.676594322874031, w0=74.90000000000015, w1=11.995736990049249\n",
      "SubSGD iter. 415/499: loss=3.764512779674156, w0=74.20000000000014, w1=12.962595057865729\n",
      "SubSGD iter. 416/499: loss=1.3301867493446373, w0=73.50000000000014, w1=13.99620667416891\n",
      "SubSGD iter. 417/499: loss=0.6045070171520699, w0=72.80000000000014, w1=14.440742848657338\n",
      "SubSGD iter. 418/499: loss=1.5287784389579073, w0=73.50000000000014, w1=14.683396706257204\n",
      "SubSGD iter. 419/499: loss=0.33205109708395497, w0=74.20000000000014, w1=14.873766790112674\n",
      "SubSGD iter. 420/499: loss=2.940362323933421, w0=74.90000000000015, w1=15.439423586458753\n",
      "SubSGD iter. 421/499: loss=2.79583121627563, w0=74.20000000000014, w1=14.498199692584395\n",
      "SubSGD iter. 422/499: loss=3.198559915837315, w0=74.90000000000015, w1=15.199314468022772\n",
      "SubSGD iter. 423/499: loss=6.513397257472125, w0=74.20000000000014, w1=15.170942488875944\n",
      "SubSGD iter. 424/499: loss=0.37642402739012937, w0=74.90000000000015, w1=16.086105101770535\n",
      "SubSGD iter. 425/499: loss=2.412622948209922, w0=74.20000000000014, w1=15.306133341759912\n",
      "SubSGD iter. 426/499: loss=0.9673478715809409, w0=73.50000000000014, w1=14.754778980431933\n",
      "SubSGD iter. 427/499: loss=2.496174298085851, w0=74.20000000000014, w1=14.106437137944688\n",
      "SubSGD iter. 428/499: loss=0.6875356973797082, w0=74.90000000000015, w1=13.931574297906343\n",
      "SubSGD iter. 429/499: loss=1.8221739609387626, w0=74.20000000000014, w1=13.308978302752392\n",
      "SubSGD iter. 430/499: loss=1.074454073910605, w0=73.50000000000014, w1=14.342589919055573\n",
      "SubSGD iter. 431/499: loss=0.1890981920368482, w0=72.80000000000014, w1=15.065147078648938\n",
      "SubSGD iter. 432/499: loss=0.5623265414353327, w0=72.10000000000014, w1=14.412823234298747\n",
      "SubSGD iter. 433/499: loss=0.05745721690333028, w0=72.80000000000014, w1=14.5254649677665\n",
      "SubSGD iter. 434/499: loss=1.2740230304628213, w0=73.50000000000014, w1=15.613810459449427\n",
      "SubSGD iter. 435/499: loss=6.493011362281248, w0=72.80000000000014, w1=15.663113004736674\n",
      "SubSGD iter. 436/499: loss=6.141275118729961, w0=72.10000000000014, w1=15.712415550023922\n",
      "SubSGD iter. 437/499: loss=1.0036759211021504, w0=72.80000000000014, w1=15.65776478038754\n",
      "SubSGD iter. 438/499: loss=0.8396796738007382, w0=73.50000000000014, w1=14.935207620794175\n",
      "SubSGD iter. 439/499: loss=2.579731038892941, w0=74.20000000000014, w1=14.28686577830693\n",
      "SubSGD iter. 440/499: loss=3.496662437787432, w0=74.90000000000015, w1=13.102614146115346\n",
      "SubSGD iter. 441/499: loss=2.445871873972436, w0=74.20000000000014, w1=13.575052585442421\n",
      "SubSGD iter. 442/499: loss=3.414473476782213, w0=74.90000000000015, w1=13.273846528151639\n",
      "SubSGD iter. 443/499: loss=0.6810297915220431, w0=75.60000000000015, w1=13.516500385751504\n",
      "SubSGD iter. 444/499: loss=1.0600163115016628, w0=76.30000000000015, w1=13.10955176815276\n",
      "SubSGD iter. 445/499: loss=2.1566111502595575, w0=75.60000000000015, w1=12.48695577299881\n",
      "SubSGD iter. 446/499: loss=4.352476390915019, w0=74.90000000000015, w1=12.903675820076566\n",
      "SubSGD iter. 447/499: loss=1.7951286961415391, w0=75.60000000000015, w1=13.560827355998166\n",
      "SubSGD iter. 448/499: loss=0.40341801418428247, w0=76.30000000000015, w1=15.234101897276204\n",
      "SubSGD iter. 449/499: loss=1.0228953730577963, w0=75.60000000000015, w1=16.51637481954885\n",
      "SubSGD iter. 450/499: loss=0.7074041794300854, w0=74.90000000000015, w1=16.051354618834186\n",
      "SubSGD iter. 451/499: loss=3.3504744708867342, w0=74.20000000000014, w1=16.252205742226177\n",
      "SubSGD iter. 452/499: loss=1.600118273853127, w0=74.90000000000015, w1=16.23512256647786\n",
      "SubSGD iter. 453/499: loss=1.249909820357665, w0=75.60000000000015, w1=16.21803939072954\n",
      "SubSGD iter. 454/499: loss=7.5217327735324595, w0=74.90000000000015, w1=16.267341936016788\n",
      "SubSGD iter. 455/499: loss=1.056370751797914, w0=74.20000000000014, w1=15.920352215703517\n",
      "SubSGD iter. 456/499: loss=2.814257319128206, w0=73.50000000000014, w1=16.224936106818394\n",
      "SubSGD iter. 457/499: loss=2.9658224551435666, w0=72.80000000000014, w1=15.48192732766865\n",
      "SubSGD iter. 458/499: loss=3.394640794406264, w0=73.50000000000014, w1=16.04758412401473\n",
      "SubSGD iter. 459/499: loss=1.0108754165937484, w0=72.80000000000014, w1=15.106978632107058\n",
      "SubSGD iter. 460/499: loss=5.417737194337342, w0=73.50000000000014, w1=16.3202551417935\n",
      "SubSGD iter. 461/499: loss=1.4951241581419659, w0=72.80000000000014, w1=16.947990823376372\n",
      "SubSGD iter. 462/499: loss=3.8618535889568832, w0=73.50000000000014, w1=16.299648980889128\n",
      "SubSGD iter. 463/499: loss=0.09217561430585164, w0=72.80000000000014, w1=17.266507048705606\n",
      "SubSGD iter. 464/499: loss=1.0393911524075108, w0=72.10000000000014, w1=16.715152687377625\n",
      "SubSGD iter. 465/499: loss=2.4540703527376238, w0=72.80000000000014, w1=16.28963176109089\n",
      "SubSGD iter. 466/499: loss=0.6085192914359219, w0=72.10000000000014, w1=17.016362310738106\n",
      "SubSGD iter. 467/499: loss=1.2197274317571924, w0=72.80000000000014, w1=16.50448631116236\n",
      "SubSGD iter. 468/499: loss=1.756629594486558, w0=72.10000000000014, w1=16.921206358240116\n",
      "SubSGD iter. 469/499: loss=1.4473375830282507, w0=72.80000000000014, w1=17.683315734825285\n",
      "SubSGD iter. 470/499: loss=1.7183944240173545, w0=73.50000000000014, w1=16.92103776369572\n",
      "SubSGD iter. 471/499: loss=3.771613172424182, w0=72.80000000000014, w1=17.271238357972113\n",
      "SubSGD iter. 472/499: loss=6.732833854935713, w0=73.50000000000014, w1=15.736175300014981\n",
      "SubSGD iter. 473/499: loss=2.6956916996401254, w0=72.80000000000014, w1=15.937026423406973\n",
      "SubSGD iter. 474/499: loss=6.822902071665908, w0=73.50000000000014, w1=15.216587171784699\n",
      "SubSGD iter. 475/499: loss=2.688438154760483, w0=72.80000000000014, w1=13.739881249953026\n",
      "SubSGD iter. 476/499: loss=2.3881329357768593, w0=73.50000000000014, w1=14.223085286874554\n",
      "SubSGD iter. 477/499: loss=2.9596107999156445, w0=72.80000000000014, w1=14.059415809566172\n",
      "SubSGD iter. 478/499: loss=2.2733612625682937, w0=73.50000000000014, w1=14.042332633817853\n",
      "SubSGD iter. 479/499: loss=3.6854011350491547, w0=72.80000000000014, w1=14.317239244019353\n",
      "SubSGD iter. 480/499: loss=3.262238753270161, w0=73.50000000000014, w1=14.896475249105878\n",
      "SubSGD iter. 481/499: loss=1.1866743652461658, w0=72.80000000000014, w1=15.710440981042531\n",
      "SubSGD iter. 482/499: loss=0.6535988413060565, w0=73.50000000000014, w1=15.65579021140615\n",
      "SubSGD iter. 483/499: loss=2.2914028871566714, w0=72.80000000000014, w1=15.823436120524372\n",
      "SubSGD iter. 484/499: loss=2.639064852112611, w0=73.50000000000014, w1=16.4026721256109\n",
      "SubSGD iter. 485/499: loss=2.4387431530673744, w0=74.20000000000014, w1=15.596378157639023\n",
      "SubSGD iter. 486/499: loss=1.8844223707495757, w0=73.50000000000014, w1=16.099638863544484\n",
      "SubSGD iter. 487/499: loss=5.369819884206322, w0=72.80000000000014, w1=15.525736836502508\n",
      "SubSGD iter. 488/499: loss=3.0440563086889014, w0=73.50000000000014, w1=15.118788218903765\n",
      "SubSGD iter. 489/499: loss=4.8979453293585955, w0=74.20000000000014, w1=14.661106268875612\n",
      "SubSGD iter. 490/499: loss=4.97095399560007, w0=73.50000000000014, w1=13.645403616398394\n",
      "SubSGD iter. 491/499: loss=0.3528527816340272, w0=72.80000000000014, w1=12.86543185638777\n",
      "SubSGD iter. 492/499: loss=4.543411990444362, w0=73.50000000000014, w1=13.510947841215936\n",
      "SubSGD iter. 493/499: loss=0.9033942422302736, w0=72.80000000000014, w1=14.273225812345503\n",
      "SubSGD iter. 494/499: loss=0.9531226369310275, w0=72.10000000000014, w1=15.203161892773053\n",
      "SubSGD iter. 495/499: loss=1.7061961971295077, w0=72.80000000000014, w1=15.267250944490682\n",
      "SubSGD iter. 496/499: loss=0.13659993503796386, w0=72.10000000000014, w1=14.326645452583012\n",
      "SubSGD iter. 497/499: loss=4.166708887182768, w0=72.80000000000014, w1=13.815522305693761\n",
      "SubSGD iter. 498/499: loss=0.6029975130782859, w0=73.50000000000014, w1=14.36870050563976\n",
      "SubSGD iter. 499/499: loss=0.7593200211675821, w0=72.80000000000014, w1=13.575747026495243\n",
      "SubSGD: execution time=0.016 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8722947fb94c460e879cbe829e6677a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=1, min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    print(n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
